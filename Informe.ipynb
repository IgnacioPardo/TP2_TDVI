{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis exploratorio buscando patrones interesantes en los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de variables auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Las nuevas columnas que agregamos en nuestro trabajo fueron: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* price_diff: Esta columna calcula la diferencia de precio absoluta entre las columnas \"price\" y \"original_price\".\n",
    "\n",
    "* discount: Calcula el porcentaje de descuento para cada artículo comparando la diferencia entre \"original_price\" y \"price\" sobre \"original_price\".\n",
    "\n",
    "* price_ratio: Calcula la proporción de precio dividiendo \"price\" sobre \"original_price\".\n",
    "\n",
    "* is_discount: Una columna binaria que indica si hay un descuento (1) o no (0) basándose en el valor de la columna \"discount\".\n",
    "\n",
    "* title_length: Guarda la longitud en caracteres de la columna \"title\" para cada artículo.\n",
    "\n",
    "* title_word_count: Cuenta el número de palabras en la columna \"title\" dividiendo el texto por espacios.\n",
    "\n",
    "* title_length_word_count: Calcula la proporción entre \"title_length\" y \"title_word_count\", lo que puede ayudar a identificar títulos con diferentes niveles de verbosidad.\n",
    "\n",
    "* domain_dominance: Calcula una medida de cuán dominante es el artículo dentro de su dominio dividiendo \"sold_quantity\" entre \"qty_items_dom\".\n",
    "\n",
    "* is_pdp_tvi: Calcula la proporción de \"is_pdp\" entre \"total_visits_item\", representando la proporción de visitas de artículo que resultan en una vista de Página de Detalles del Producto (PDP).\n",
    "\n",
    "* is_pdp_tvs: Calcula la proporción de \"is_pdp\" entre \"total_visits_seller\", representando la proporción de visitas a vendedores que resultan en una vista de PDP.\n",
    "\n",
    "* is_pdp_tvd: Calcula la proporción de \"is_pdp\" entre \"total_visits_domain\", representando la proporción de visitas a dominios que resultan en una vista de PDP.\n",
    "\n",
    "Estas columnas creadas son derivadas de columnas ya existentes en el dataset original. Estas pueden ser útiles para analizar y categorizar artículos en función de su precio, descuento, longitud del título, patrones de visita y dominancia en el dominio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Además, aplicamos One Hot Encoding (OHE) a la columnas \"category_id\" para crear representaciones binarias de los datos de categoría y Label Encoding a las columnas \"platform\", \"product_id\", \"domain_id\" y \"logistic_type\" para convertir los datos categóricos en valores numéricos en nuevas columnas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* platform (LabelEncoded): Si el indicador lab_enc es True, esta columna se codifica con etiquetas para convertir los datos categóricos de la plataforma en valores enteros.\n",
    "\n",
    "* product_id (LabelEncoded): Convierte la columna \"product_id\" en valores enteros.\n",
    "\n",
    "* domain_id (LabelEncoded): Convierte la columna \"domain_id\" en valores enteros.\n",
    "\n",
    "* logistic_type (LabelEncoded): Convierte la columna \"logistic_type\" en valores enteros.\n",
    "\n",
    "* One-Hot Encoding (OHE) for category_id: Si el indicador de ohe es True, se aplica la codificación one-hot a la columna \"category_id\". Crea columnas binarias para cada categoría única y usa 1 para indicar la presencia de una categoría y 0 en caso contrario. El número de columnas depende del número de categorías únicas en el conjunto de datos.\n",
    "\n",
    "* category_id_<category> (OHE): Columnas binarias creadas como resultado de la codificación one-hot para cada categoría única en la columna \"category_id\". **ESCRIBIR EJEMPLO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estas son algunas modificaciones y adiciones a las columnas que forman parte de los pasos de preprocesamiento de datos, que incluyen conversiones de tipo, manejo de valores faltantes y la creación de indicadores binarios para ciertas condiciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* free_shipping (Conversión de tipo): Convertimos la columna \"free_shipping\" a enteros. Probablemente representa una señal binaria donde 1 indica envío gratuito y 0 indica que no hay envío gratuito.\n",
    "\n",
    "* fulfillment (Conversión de tipo): Convertimos esta columna a enteros. Esta columna probablemente representa un método de cumplimiento, y la conversión a números enteros puede usarse para codificar diferentes opciones de cumplimiento\n",
    "\n",
    "* imp_is_pdp (Indicador Binario): Esta columna fue creada para indicar si la columna \"is_pdp\"  tiene valores faltantes (NaN). Si \"is_pdp\" tiene un NaN, esta nueva columna se establecerá en 1; de lo contrario, se establecerá en 0. Además, los valores faltantes en \"is_pdp\" se llenan con 0 y luego se convierten a números enteros.\n",
    "\n",
    "* imp_user_id (Indicador Binario):Al igual que con \"imp_is_pdp\", esta columna se crea para indicar si la columna \"user_id\" tenía valores faltantes. Si \"user_id\" tiene valores faltantes, esta columna se establecerá en 1; de lo contrario, se establecerá en 0. Los valores faltantes en \"user_id\" se llenan con 0 y luego se convierten a números enteros.\n",
    "\n",
    "* listing_type_id (Mapping): La columna \"listing_type_id\" se modifica aplicando una función lambda. Si el valor es \"gold_special,\" se establece en 0; de lo contrario, se establece en 1. Esto parece mapear diferentes tipos de listados a valores binarios para un análisis o modelado posterior. En otras palabras, se está creando una nueva columna que representa de manera binaria si un listado es \"gold_special\" (0) o cualquier otro tipo de listado (1) para su uso en análisis o modelos posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Columna \"tags\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, para cada etiqueta unica en la columna \"tags\", se crea una nueva columna con el nombre de la etiqueta. Estas nuevas columnas tienen valores booleanos (1 si el artículo contiene la etiqueta, 0 en caso contrario). Los nombres de estas columnas se basan en las etiquetas únicas encontradas en el conjunto de datos.\n",
    "\n",
    "Luego en otra columna llamada \"tag_counts\" se almacena la cantidad de etiquetas asociadas a cada artículo. Calcula la cantidad de etiquetas dividiendo la columna \"tags\" y contando los elementos.\n",
    "\n",
    "Una vez creadas las nuevas columnas relacionadas con las etiquetas, se elimina la columna original \"tags\" del DataFrame. Esto se hace para evitar que el modelo de aprendizaje automático se sobreajuste a los datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nuevas columnas con valores al cuadrado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por cada atributo especificado en la lista poly_attrs (por ejemplo, \"print_position,\" \"offset,\" \"discount,\" \"price,\" \"health,\" \"original_price\"), se crea una nueva columna elevando al cuadrado los valores de ese atributo. Los nombres de las columnas siguen el patrón <attribute_name>2, donde <attribute_name> es el nombre del atributo original. \n",
    "\n",
    "* Interaccion de columnas con suma de cuadrados: Para cada par de atributos especificados en la lista de polly_attrs, la combinacion de dos atributos tambien se crea (por ejemplo, \"print_position2 + offset2\"). Estas nuevas columnas representan la suma de cuadrados de los atributos correspondientes. El codigo esencialmente realiza la ingenieria de caracteristicas creando nuevas columnas con valores al cuadrado de los atributos especificados y tambien genera caracteristicas de interacción sumando los cuadrados de pares de atributos. Estas nuevas caracteristicas pueden capturar relaciones no lineales entre los atributos y pueden ser utiles para modelos de aprendizaje automático que se benefician de términos polinomiales o de interaccion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Worl2Vec y Reduccion de dimensionalidad con PCA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenized_title: Esta columna se crea tokenizando la columna \"title\". Primero usa sent_tokenize para dividir el texto en oraciones, luego word_tokenize para dividir las oraciones en palabras, elimina los caracteres no alfabéticos y convierte las palabras en minúsculas. El resultado es una lista de oraciones tokenizadas.\n",
    "\n",
    "\n",
    "Entrenamiento y carga del modelo Word2Vec (condicional):\n",
    "\n",
    "* Si RETRAIN_W2C es True, se entrena un modelo Word2Vec utilizando los títulos tokenizados. El modelo se configura con hiperparámetros específicos como el tamaño del vector, el tamaño de la ventana, el recuento mínimo de palabras y otros.\n",
    "\n",
    "* Si RETRAIN_W2C es False, se carga un modelo Word2Vec preentrenado del archivo \"title_w2c.model\". Esto le permite utilizar un modelo Word2Vec preexistente sin volver a entrenar.\n",
    "\n",
    "title_embs: Esta columna contiene los embeddings (representaciones vectoriales) de los títulos tokenizados. Se calcula tomando la media de los vectores de palabras para cada palabra en los títulos tokenizados.\n",
    "\n",
    "Columnas de incrustación: Se crea una serie de columnas con nombres como \"embeddings_0,\" \"embeddings_1,\" y así sucesivamente para almacenar los componentes individuales de los embeddings de palabras. Estas columnas representan los componentes vectoriales de los embeddings de palabras generados por el modelo Word2Vec.\n",
    "\n",
    "The code snippet essentially performs the following tasks: tokenizes the titles, trains or loads a Word2Vec model, calculates title embeddings, and stores the embeddings in new columns for further analysis or modeling. These embeddings can capture semantic information about the titles, making them useful for various natural language processing tasks.\n",
    "\n",
    "PaCMAP (Pairwise Controlled Manifold Approximation) es un algoritmo de reducción de dimensionalidad no lineal que se puede utilizar para reducir la dimensionalidad de los embeddings de palabras. Se instancia un modelo PaCMAP con un número especificado de dimensiones (dims) para la reducción de dimensionalidad: \n",
    "* Nuevas columnas con dimension reducida: Las nuevas columna con las dimensiones reducidas se llaman \"pacmap_0,\" \"pacmap_1,\" y así sucesivamente hasta el número de dimensiones especificado (dims). \n",
    "* Columnas romvidas: Las columnas que se borran son las columnas de embedding originales (\"embeddings_0,\" \"embeddings_1,\" etc.), así como las columnas \"title_embs\" y \"tokenized_title\". Esto se hace para eliminar los embeddings originales y los resultados intermedios, dejando solo los embeddings de dimensionalidad reducida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Procesamiento de Garantías:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna \"warranty\" se somete a un preprocesamiento para asegurar un formato consistente, creando nuevas variables booleanas representando distintosa aspectos de la garantia de cada artículo, teniendo en cuenta que:\n",
    "-  Todo el texto se convierte a minúsculas.\n",
    "_ Los caracteres acentuados como \"á\" e \"í\" se reemplazan por sus equivalentes sin acentos.\n",
    "\n",
    "* warranty_saler: Esta columna se crea como una variable booleana (0 o 1) que indica si el texto de \"warranty\" contiene la palabra \"vendedor\" (garantía del vendedor). Es de tipo flotante, donde 1.0 indica la presencia de \"vendedor\" y 0.0 indica lo contrario.\n",
    "\n",
    "* warranty_factory: Similar a \"warranty_saler\", esta columna se crea como una variable booleana que indica si el texto de \"warranty\" contiene la palabra \"fábrica\" (garantía de fábrica).\n",
    "\n",
    "* warranty_no: Se crea otra variable booleana para indicar si el texto de \"warranty\" contiene \"sin garantía\" (no hay garantía).\n",
    "\n",
    "* warranty_missing: Esta columna se crea como una variable booleana (0 o 1) que indica si el texto de \"warranty\" está ausente o no (NaN o no NaN).\n",
    "\n",
    "* warranty_days: Esta columna extrae valores numéricos del texto de \"warranty\", específicamente buscando patrones como \"X días\", \"X meses\" o \"X años\". Calcula la duración en días en base a estos patrones.\n",
    "\n",
    "* warranty_days_missing: Similar a \"warranty_missing\", esta columna se crea como una variable booleana que indica si la columna \"warranty_days\" está ausente o no (NaN o no NaN).\n",
    "\n",
    "###### Rellenando Valores Faltantes:\n",
    "Las columnas \"warranty_saler\", \"warranty_factory\", \"warranty_no\" y \"warranty_days\" se llenan con -1 en las filas donde la información correspondiente falta (NaN).\n",
    "\n",
    "###### Eliminación de la Columna \"warranty\":\n",
    "La columna original \"warranty\" se elimina del DataFrame después de procesarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Column Processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna \"date\" es convertida a un formato \"datetime\" usando pd.to_datetime. Esto sirve para poder capturar información sobre aspectos temporales de la misma, incluyendo día, mes, día de la semana y momento del día (mañana, tarde, noche). Estas pueden ser utilizadas para realizar análisis basados en el tiempo con el fin de capturar patrones temporales en los datos. \n",
    "\n",
    "* day: Esta columna se crea para extraer y almacenar el componente del día (día del mes) de la columna \"date\".\n",
    "* month: Esta columna se crea para extraer y almacenar el componente del mes de la columna \"date\".\n",
    "* dayofweek: Esta extrae y almacena el día de la semana (0 para lunes, 6 para domingo) de la columna \"date\".\n",
    "\n",
    "###### Columnas de Momento del Día (morning, afternoon, night): \n",
    "Estas columnas se crean en función del componente \"hour\" (hora) de la columna \"date\".\n",
    "\n",
    "* morning: se establece en 1 si la hora está entre las 6 AM (inclusive) y las 12 PM (exclusivas).\n",
    "* afternoon: se establece en 1 si la hora está entre las 12 PM (inclusive) y las 6 PM (exclusivas).\n",
    "* night: se establece en 1 si la hora está entre las 6 PM (inclusive) y las 12 AM (medianoche, exclusiva)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado de conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar todo esto, lo checkeabamos con 5 folds sobre el 80% de train, si mejoraba, reentrenabamos con todo el 80% de train. Otra opción, que nuestra validación tenga la misma cantidad de samples que los items de eval. Inicialmente nuestro holdout era 25/75, cuando planteamos esto lo cambiamos a 20/80. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación de modelos predictivos y búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB con RandomizedSearch CV (con holdout 20/80 sobre los 80 de train) en la busqueda de hiperparametros: 0.8923196517213106\n",
    "\n",
    "Con estos hiperparametros reentrenamos con los 80 de train enteros: 0.9008407660123985\n",
    "\n",
    "Baggear XGB: 0.9015660988341951\n",
    "\n",
    "Usamos RSCV porque cuando probamos con Hiperopt, no llegó a hiperparametros que mejoren la performance, esto porque nuestro espacio de hiperparametros no estaba bien definido\n",
    "\n",
    "Cambiamos a RSCV para poder cubrir mayor parte del espacio de hiperparametros, HiperOpt para hacer esto es mas lento\n",
    "\n",
    "Otra opción que contemplamos, fue tunear los hiperparametros para el modelo stack(xgb, agb, hgb) -> xgb, tambien con RSCV, el espacio de hiperparametros era muy grande:\n",
    "\n",
    "\"final_estimator__n_estimators\": [25, 50, 100],\n",
    "\"final_estimator__max_depth\": [5, 10, 25, 50, 100],\n",
    "\"final_estimator__learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "\"final_estimator__gamma\": [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\"final_estimator__min_child_weight\": [0, 1, 2, 3, 4, 5, 6],\n",
    "\"final_estimator__subsample\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "\"final_estimator__colsample_bytree\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "\"xgb__n_estimators\": [25, 50, 100],\n",
    "\"xgb__max_depth\": [5, 10, 25, 50, 100],\n",
    "\"xgb__learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "\"xgb__gamma\": [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\"xgb__min_child_weight\": [0, 1, 2, 3, 4, 5, 6],\n",
    "\"xgb__subsample\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "\"xgb__colsample_bytree\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "\"hgb__max_depth\": [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "\"hgb__learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "\"hgb__max_iter\": [100, 200, 300, 400, 500],\n",
    "\"hgb__max_leaf_nodes\": [10, 20, 30, 40, 50],\n",
    "\"hgb__min_samples_leaf\": [10, 20, 30, 40, 50],\n",
    "\"hgb__l2_regularization\": [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\"abc_adaboostclassifier_n_estimators\": [25, 50, 100],\n",
    "\"abc_adaboostclassifier_learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "\n",
    "No llegamos hacer una busqueda muy exhaustiva de hiperparametros, con lo que obtuvimos no mejoramos mucho su performance y en el leaderboard le iba cada vez peor\n",
    "\n",
    "Por lo que descartamos los stacks ya que no lo ibamos a poder optimizar, lo mismo para los votings y average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responder: Dada una persona que se encuentra diseñando un anuncio de venta de un producto para publicar en este destacado retailer online, ¿en qué aspectos le recomendarían enfocarse? ¿Ven alguna debilidad en este análisis?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
