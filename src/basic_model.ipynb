{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update xgboost \n",
    "!pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nColumns\\nThe following columns are available on the training set:\\n\\naccepts_mercadopago Whether the item accepts Mercado Pago\\navailable_quantity The available stock quantity at that moment\\navg_asp_item_bday Average selling price of this item over the last days\\navg_asp_item_domain Average price of items of the domain this item belongs to\\navg_asp_item_sel Average price of seller sales\\navg_gmv_item_bday average revenue generated by the item per day\\navg_gmv_item_domain_30days Average revenue generated by the items of this domain on the last month\\navg_gmv_item_sel Average revenue of items of this seller\\navg_gmv_seller_bday Average revenue this seller makes by day\\navg_orders_item_bday Average number of orders this item has by day\\navg_orders_seller_bday Average orders the seller has by day\\navg_qty_orders_item_domain_30days Average number of orders a random item of this domain made on the last month\\navg_qty_orders_item_sel_30days Average number of orders an item of this seller makes on the last 30 days\\navg_si_item_bday Average units sold this item has by day\\navg_si_item_sel_30day Average units sold of an item of this seller on the past month\\navg_visits_item Average visits this item had\\nbenefit Ignore, should be dropped\\nboosted Whether the item was boosted\\nbuy_server_timestamp Timestamp of the purchase\\ncategory_id Category of this item\\nconversion Target variable, it is True if this print has an attributed order\\ncus_cust_id Buyer id\\ncus_cust_id_sel Seller id\\ndate Print date\\ndeal_print_id Unique id for the print\\ndecimals Ignore, will be dropped\\ndomain_id Domain id for the item\\netl_version Ignore, should be dropped\\nfree_shipping Whether the item has free shipping\\nfulfillment Whether the item is fulfilled by MeLi\\nfull_name Category full name\\nhealth Item health\\nis_pdp Whether the click landed on a PDP\\nproduct_id Product_id of the item\\nitem_id ID of the item, useful for debugging\\nlisting_type_id Whether the item is gold or not\\nlogistic_type Logistic type for the item\\nmain_picture URL for the main item picture\\noffset On which page the item was rendered\\noriginal_price Price from which the discount was done\\nplatform Which platform the user is using\\nprice Item price\\nprint_position Position on the page\\nprint_server_timestamp Timestamp for the print\\nqty_items_dom Number of items this domain has\\nqty_items_sel Number of items the seller has\\nrn Leftover from the ETL, Discard\\nROW_ID Row of the submission file\\nsite_id Site ID\\nsold_quantity Number of items sold at the moment of the print\\ntags Tags the item had at the moment of the print\\ntitle Item title\\ntotal_asp_item_domain_30days Average selling price of the items of the domain\\ntotal_asp_item_sel_30days Average selling price of all the items the seller sold on the last 30 days\\ntotal_gmv_domain_30days Total revenue the domain made on the last 30 days\\ntotal_gmv_domain_bday total_gmv_domain_30days / 30\\ntotal_gmv_item_30days Total revenue made by the item on the lasts 30 days\\ntotal_gmv_seller Total revenue made by the seller on the last month\\ntotal_items_domain Number of items on the domain\\ntotal_items_seller Number of items the seller has\\ntotal_orders_domain_30days Total orders on the domain\\ntotal_orders_item_30days Total orders the Item had on the last 30 days\\ntotal_orders_sel_30days Total orders for the seller\\ntotal_si_domain_30days Total units sold of this domain\\ntotal_si_item_30days Total units sold of this item\\ntotal_si_sel_30days Same for the seller\\ntotal_visits_domain Total visits on this domain\\ntotal_visits_item Total visits this item had\\ntotal_visits_seller Total visits for this seller\\nuid session id\\nuser_id user id\\nwarranty Whether the item had warranty\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Columns\n",
    "The following columns are available on the training set:\n",
    "\n",
    "accepts_mercadopago Whether the item accepts Mercado Pago\n",
    "available_quantity The available stock quantity at that moment\n",
    "avg_asp_item_bday Average selling price of this item over the last days\n",
    "avg_asp_item_domain Average price of items of the domain this item belongs to\n",
    "avg_asp_item_sel Average price of seller sales\n",
    "avg_gmv_item_bday average revenue generated by the item per day\n",
    "avg_gmv_item_domain_30days Average revenue generated by the items of this domain on the last month\n",
    "avg_gmv_item_sel Average revenue of items of this seller\n",
    "avg_gmv_seller_bday Average revenue this seller makes by day\n",
    "avg_orders_item_bday Average number of orders this item has by day\n",
    "avg_orders_seller_bday Average orders the seller has by day\n",
    "avg_qty_orders_item_domain_30days Average number of orders a random item of this domain made on the last month\n",
    "avg_qty_orders_item_sel_30days Average number of orders an item of this seller makes on the last 30 days\n",
    "avg_si_item_bday Average units sold this item has by day\n",
    "avg_si_item_sel_30day Average units sold of an item of this seller on the past month\n",
    "avg_visits_item Average visits this item had\n",
    "benefit Ignore, should be dropped\n",
    "boosted Whether the item was boosted\n",
    "buy_server_timestamp Timestamp of the purchase\n",
    "category_id Category of this item\n",
    "conversion Target variable, it is True if this print has an attributed order\n",
    "cus_cust_id Buyer id\n",
    "cus_cust_id_sel Seller id\n",
    "date Print date\n",
    "deal_print_id Unique id for the print\n",
    "decimals Ignore, will be dropped\n",
    "domain_id Domain id for the item\n",
    "etl_version Ignore, should be dropped\n",
    "free_shipping Whether the item has free shipping\n",
    "fulfillment Whether the item is fulfilled by MeLi\n",
    "full_name Category full name\n",
    "health Item health\n",
    "is_pdp Whether the click landed on a PDP\n",
    "product_id Product_id of the item\n",
    "item_id ID of the item, useful for debugging\n",
    "listing_type_id Whether the item is gold or not\n",
    "logistic_type Logistic type for the item\n",
    "main_picture URL for the main item picture\n",
    "offset On which page the item was rendered\n",
    "original_price Price from which the discount was done\n",
    "platform Which platform the user is using\n",
    "price Item price\n",
    "print_position Position on the page\n",
    "print_server_timestamp Timestamp for the print\n",
    "qty_items_dom Number of items this domain has\n",
    "qty_items_sel Number of items the seller has\n",
    "rn Leftover from the ETL, Discard\n",
    "ROW_ID Row of the submission file\n",
    "site_id Site ID\n",
    "sold_quantity Number of items sold at the moment of the print\n",
    "tags Tags the item had at the moment of the print\n",
    "title Item title\n",
    "total_asp_item_domain_30days Average selling price of the items of the domain\n",
    "total_asp_item_sel_30days Average selling price of all the items the seller sold on the last 30 days\n",
    "total_gmv_domain_30days Total revenue the domain made on the last 30 days\n",
    "total_gmv_domain_bday total_gmv_domain_30days / 30\n",
    "total_gmv_item_30days Total revenue made by the item on the lasts 30 days\n",
    "total_gmv_seller Total revenue made by the seller on the last month\n",
    "total_items_domain Number of items on the domain\n",
    "total_items_seller Number of items the seller has\n",
    "total_orders_domain_30days Total orders on the domain\n",
    "total_orders_item_30days Total orders the Item had on the last 30 days\n",
    "total_orders_sel_30days Total orders for the seller\n",
    "total_si_domain_30days Total units sold of this domain\n",
    "total_si_item_30days Total units sold of this item\n",
    "total_si_sel_30days Same for the seller\n",
    "total_visits_domain Total visits on this domain\n",
    "total_visits_item Total visits this item had\n",
    "total_visits_seller Total visits for this seller\n",
    "uid session id\n",
    "user_id user id\n",
    "warranty Whether the item had warranty\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_comp():\n",
    "    # Load the competition data\n",
    "    comp_data = pd.read_csv(\"data/competition_data.csv\")\n",
    "    comp_data = comp_data.drop(\n",
    "        columns=[\n",
    "            \"benefit\", \n",
    "            \"etl_version\", \n",
    "            \"uid\",\n",
    "            \"date\",\n",
    "            \"deal_print_id\",\n",
    "            \"full_name\",\n",
    "            \"main_picture\",\n",
    "            \"warranty\",\n",
    "            \"tags\",\n",
    "            \"print_server_timestamp\",\n",
    "            \"print_position\",\n",
    "            \"title\",\n",
    "            \"accepts_mercadopago\"\n",
    "        ]\n",
    "    )\n",
    "    # OHE comp_data columns\n",
    "    comp_data = pd.get_dummies(comp_data, \n",
    "        sparse=True,\n",
    "        columns=[\n",
    "            #\"category_id\", \n",
    "            #\"domain_id\", \n",
    "            \"logistic_type\", \n",
    "            \"platform\", \n",
    "            \"site_id\"\n",
    "        ],\n",
    "        dtype=int\n",
    "    )\n",
    "    #comp_data[\"accepts_mercadopago\"] = comp_data[\"accepts_mercadopago\"].astype(int)\n",
    "    # todos aceptan mercadopago\n",
    "    comp_data[\"boosted\"] = comp_data[\"boosted\"].astype(int)\n",
    "    comp_data[\"free_shipping\"] = comp_data[\"free_shipping\"].astype(int)\n",
    "    comp_data[\"fulfillment\"] = comp_data[\"fulfillment\"].astype(int)\n",
    "\n",
    "    comp_data[\"is_pdp\"].fillna(0, inplace=True)\n",
    "    comp_data[\"is_pdp\"] = comp_data[\"is_pdp\"].astype(int)\n",
    "    #comp_data[\"warranty\"] = comp_data[\"warranty\"].astype(int)\n",
    "\n",
    "    # comp_data[\"listing_type_id\"] to 0 if gold_special, 1 if gold_pro.\n",
    "    comp_data[\"listing_type_id\"] = comp_data[\"listing_type_id\"].apply(lambda x: 0 if x == \"gold_special\" else 1)\n",
    "    \n",
    "    # Label encode category_id and domain_id\n",
    "    # comp_data[\"category_id\"] = comp_data[\"category_id\"].astype(\"category\")#.cat.codes\n",
    "    #comp_data[\"domain_id\"] = comp_data[\"domain_id\"].astype(\"category\")#.cat.codes\n",
    "\n",
    "    # sklearn LabelEncoder for category_id and domain_id\n",
    "    \n",
    "    comp_data[\"category_id\"] = LabelEncoder().fit_transform(comp_data[\"category_id\"]).astype(int)\n",
    "    comp_data[\"domain_id\"] = LabelEncoder().fit_transform(comp_data[\"domain_id\"]).astype(int)\n",
    "    comp_data[\"item_id\"] = LabelEncoder().fit_transform(comp_data[\"item_id\"]).astype(int)\n",
    "\n",
    "    comp_data[\"price_diff\"] = comp_data[\"price\"] - comp_data[\"original_price\"]\n",
    "    comp_data[\"cheaper_than_original\"] = comp_data[\"price_diff\"].apply(lambda x: 1 if x < 0 else 0)\n",
    "    comp_data[\"price_diff\"] = comp_data[\"price_diff\"].apply(lambda x: abs(x)).astype(int)\n",
    "\n",
    "    #comp_data[\"cheaper_than_avg\"] = comp_data[\"price\"] - comp_data[\"avg_asp_item_domain\"]\n",
    "    #comp_data[\"cheaper_than_avg\"] = comp_data[\"cheaper_than_avg\"].apply(lambda x: 1 if x < 0 else 0).astype(int)\n",
    "\n",
    "    # Drop useless columns\n",
    "    # comp_data = comp_data.drop(\n",
    "    #     columns=[\n",
    "    #     ]\n",
    "    # )\n",
    "\n",
    "    return comp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLA784334044    717\n",
       "MLA764888251    701\n",
       "MLA847531773    622\n",
       "MLA785891221    535\n",
       "MLA766402693    517\n",
       "               ... \n",
       "MLA833936427      1\n",
       "MLA663926326      1\n",
       "MLA784136287      1\n",
       "MLA812482695      1\n",
       "MLA762298064      1\n",
       "Name: item_id, Length: 27695, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data = load_comp()\n",
    "comp_data[\"item_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **available_quantity** (int64)\n",
       "- **avg_gmv_item_domain_30days** (float64)\n",
       "- **avg_gmv_item_sel** (float64)\n",
       "- **avg_gmv_seller_bday** (float64)\n",
       "- **avg_qty_orders_item_domain_30days** (float64)\n",
       "- **avg_qty_orders_item_sel_30days** (float64)\n",
       "- **avg_si_item_sel_30day** (float64)\n",
       "- **boosted** (int64)\n",
       "- **category_id** (int64)\n",
       "- **conversion** (float64)\n",
       "- **domain_id** (int64)\n",
       "- **free_shipping** (int64)\n",
       "- **fulfillment** (int64)\n",
       "- **health** (float64)\n",
       "- **is_pdp** (int64)\n",
       "- **product_id** (float64)\n",
       "- **item_id** (int64)\n",
       "- **listing_type_id** (int64)\n",
       "- **offset** (int64)\n",
       "- **original_price** (int64)\n",
       "- **price** (int64)\n",
       "- **qty_items_dom** (float64)\n",
       "- **qty_items_sel** (float64)\n",
       "- **sold_quantity** (int64)\n",
       "- **total_asp_item_domain_30days** (float64)\n",
       "- **total_asp_item_sel_30days** (float64)\n",
       "- **total_gmv_domain_bday** (float64)\n",
       "- **total_gmv_item_30days** (float64)\n",
       "- **total_items_domain** (int64)\n",
       "- **total_items_seller** (int64)\n",
       "- **total_orders_domain_30days** (float64)\n",
       "- **total_orders_item_30days** (float64)\n",
       "- **total_orders_sel_30days** (float64)\n",
       "- **total_si_domain_30days** (float64)\n",
       "- **total_si_item_30days** (float64)\n",
       "- **total_si_sel_30days** (float64)\n",
       "- **total_visits_domain** (int64)\n",
       "- **total_visits_item** (int64)\n",
       "- **total_visits_seller** (int64)\n",
       "- **user_id** (float64)\n",
       "- **ROW_ID** (float64)\n",
       "- **logistic_type_cross_docking** (Sparse[int64, 0])\n",
       "- **logistic_type_custom** (Sparse[int64, 0])\n",
       "- **logistic_type_default** (Sparse[int64, 0])\n",
       "- **logistic_type_drop_off** (Sparse[int64, 0])\n",
       "- **logistic_type_fulfillment** (Sparse[int64, 0])\n",
       "- **logistic_type_not_specified** (Sparse[int64, 0])\n",
       "- **logistic_type_xd_drop_off** (Sparse[int64, 0])\n",
       "- **platform_/mobile/android** (Sparse[int64, 0])\n",
       "- **platform_/mobile/ios** (Sparse[int64, 0])\n",
       "- **platform_/web/desktop** (Sparse[int64, 0])\n",
       "- **platform_/web/mobile** (Sparse[int64, 0])\n",
       "- **site_id_MLA** (Sparse[int64, 0])\n",
       "- **price_diff** (int64)\n",
       "- **cheaper_than_original** (int64)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 36\u001b[0m\n\u001b[1;32m     31\u001b[0m poly \u001b[39m=\u001b[39m PolynomialFeatures(\u001b[39m2\u001b[39m,\n\u001b[1;32m     32\u001b[0m                           interaction_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m                         )\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(full_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m---> 36\u001b[0m full_data \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39;49mfit_transform(full_data)\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(full_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m     39\u001b[0m train_data, test_data \u001b[39m=\u001b[39m train_test_split(full_data, test_size\u001b[39m=\u001b[39m\u001b[39m0.20\u001b[39m, train_size\u001b[39m=\u001b[39m\u001b[39m0.80\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_polynomial.py:322\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    305\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m    Compute number of output features.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39m        Fitted transformer.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     _, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mshape\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree, Integral):\n\u001b[1;32m    325\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Split into training and evaluation samples\n",
    "comp_data = load_comp()\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                #\"- **{}** ({}) \\n\\n {}\".format(col, dtype, comp_data[col].value_counts()) for col, dtype in\n",
    "                \"- **{}** ({})\".format(col, dtype) for col, dtype in\n",
    "                zip(comp_data.columns, comp_data.dtypes)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "full_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "\n",
    "# Get number column names for full_data\n",
    "#print(full_data.columns)\n",
    "#num_cols = full_data.select_dtypes(include='number').columns\n",
    "#print(num_cols)\n",
    "# difference between full_data_cols and num_cols\n",
    "# print(set(full_data.columns) - set(num_cols))\n",
    "\n",
    "del comp_data\n",
    "gc.collect()\n",
    "\n",
    "train_data, test_data = train_test_split(full_data, test_size=0.20, train_size=0.80, random_state=42)\n",
    "\n",
    "y_train = train_data[\"conversion\"]\n",
    "X_train = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_train = X_train.select_dtypes(include='number')\n",
    "\n",
    "y_test = test_data[\"conversion\"]\n",
    "X_test = test_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_test = X_test.select_dtypes(include='number')\n",
    "\n",
    "del train_data\n",
    "del test_data\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributes_to_poly = [\n",
    "                        \"available_quantity\", \n",
    "                        \"avg_gmv_item_domain_30days\", \n",
    "                        \"avg_gmv_item_sel\", \n",
    "                        \"avg_gmv_seller_bday\", \n",
    "                        \"avg_qty_orders_item_domain_30days\", \n",
    "                        \"avg_qty_orders_item_sel_30days\", \n",
    "                        \"avg_si_item_sel_30day\",\n",
    "                        \"original_price\",\n",
    "                        \"price\",\n",
    "                    ]\n",
    "\n",
    "imputed_poly_features = make_pipeline(\n",
    "  #SimpleImputer(),\n",
    "  #PolynomialFeatures(),\n",
    "  StandardScaler(),\n",
    "  xgb.XGBClassifier(\n",
    "        missing=np.nan,\n",
    "        n_jobs=-1,\n",
    "        tree_method='gpu_hist',\n",
    "    )\n",
    ")\n",
    "\n",
    "# Custom Layer Starts Here:\n",
    "pl = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "\n",
    "#Input X contains NaN.\n",
    "\n",
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "print(imputed_X_train_plus.shape[0] == X_train.shape[0])\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "cols_with_missing = (col for col in X_train.columns\n",
    "                        if X_train[col].isnull().any())\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "poly_X_train = imputed_X_train_plus[atributes_to_poly]\n",
    "poly_X_test = imputed_X_test_plus[atributes_to_poly]\n",
    "print(poly_X_train.shape[0] == X_train.shape[0])\n",
    "\n",
    "poly_X_train = my_imputer.fit_transform(poly_X_train)\n",
    "poly_X_test = my_imputer.transform(poly_X_test)\n",
    "print(poly_X_train.shape[0] == X_train.shape[0])\n",
    "\n",
    "poly_X_train = pl.fit_transform(poly_X_train)\n",
    "poly_X_test = pl.fit_transform(poly_X_test)\n",
    "print(poly_X_train.shape[0] == X_train.shape[0])\n",
    "\n",
    "new_X_train = np.concatenate((X_train.drop(atributes_to_poly, axis=1), poly_X_train), axis=1)\n",
    "new_X_test = np.concatenate((X_test.drop(atributes_to_poly, axis=1), poly_X_test), axis=1)\n",
    "print(new_X_train.shape[0] == X_train.shape[0])\n",
    "# Custom Layer Ends Here\n",
    "\n",
    "\n",
    "imputed_poly_features.fit(new_X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, imputed_poly_features.predict_proba(new_X_test)[:, imputed_poly_features.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC split 1:  0.7062813104270844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m X_train_kf, X_valid_kf \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39miloc[train_index], X_train\u001b[39m.\u001b[39miloc[valid_index]\n\u001b[1;32m     26\u001b[0m y_train_kf, y_valid_kf \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39miloc[train_index], y_train\u001b[39m.\u001b[39miloc[valid_index]\n\u001b[0;32m---> 28\u001b[0m dtc\u001b[39m.\u001b[39;49mfit(X_train_kf, y_train_kf)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Metric: roc_auc_score\u001b[39;00m\n\u001b[1;32m     30\u001b[0m roc_aucs\u001b[39m.\u001b[39mappend(roc_auc_score(y_valid_kf, dtc\u001b[39m.\u001b[39mpredict_proba(X_valid_kf)[:, dtc\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1805\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1806\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1807\u001b[0m         ParameterSampler(\n\u001b[1;32m   1808\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1809\u001b[0m         )\n\u001b[1;32m   1810\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with K-Fold Cross Validation and Randomized Search CV\n",
    "\n",
    "dtc = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RandomizedSearchCV(\n",
    "        DecisionTreeClassifier(random_state=2345),\n",
    "        param_distributions={\n",
    "            \"max_depth\": [2, 4, 8, 16, 32, 64, 128, 256, 512, None],\n",
    "            \"min_samples_split\": [2, 4, 8, 16, 32, 64, 128, 256, 512],\n",
    "            \"min_samples_leaf\": [2, 4, 8, 16, 32, 64, 128, 256, 512],\n",
    "            \"max_features\": [2, 4, 8, 16, 32, 64, 128, 256, 512, None],\n",
    "        },\n",
    "        n_iter=100,\n",
    "        cv=3,\n",
    "        random_state=2345,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=2345, shuffle=True)\n",
    "roc_aucs = []\n",
    "\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    X_train_kf, X_valid_kf = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_kf, y_valid_kf = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "    dtc.fit(X_train_kf, y_train_kf)\n",
    "    # Metric: roc_auc_score\n",
    "    roc_aucs.append(roc_auc_score(y_valid_kf, dtc.predict_proba(X_valid_kf)[:, dtc.classes_ == 1]))\n",
    "    print(f\"ROC-AUC split {len(roc_aucs)}: \", roc_aucs[-1])\n",
    "\n",
    "print(\"ROC-AUC mean: \", sum(roc_aucs) / len(roc_aucs))    \n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "print(\"ROC-AUC: \", roc_auc_score(y_test, dtc.predict_proba(X_test)[:, dtc.classes_ == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.719648\n",
       "std      0.005229\n",
       "min      0.714328\n",
       "25%      0.715559\n",
       "50%      0.717973\n",
       "75%      0.724961\n",
       "max      0.725421\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(roc_aucs).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=2345),\n",
    "        param_distributions={\n",
    "            \"max_depth\": [2, 4, 8, 16, 32, 64, 128, None],\n",
    "            \"min_samples_split\": [2, 4, 8, 16, 32, 64, 128],\n",
    "            \"min_samples_leaf\": [2, 4, 8, 16, 32, 64, 128],\n",
    "            \"max_features\": [2, 4, 8, 16, 32, 64, 128, None],\n",
    "        },\n",
    "        n_iter=100,\n",
    "        cv=3,\n",
    "        random_state=2345,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "    )\n",
    ")\n",
    "\n",
    "rfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [09:50<00:00,  5.90s/trial, best loss: 0.26513219216768746]\n",
      "{'max_depth': 2, 'max_features': 5, 'min_samples_leaf': 6, 'min_samples_split': 8}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [2, 4, 8, 16, 32, 64, 128, 256, 512, None]),\n",
    "    \"min_samples_split\": hp.choice(\"min_samples_split\", [2, 4, 8, 16, 32, 64, 128, 256, 512]),\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", [2, 4, 8, 16, 32, 64, 128, 256, 512]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [2, 4, 8, 16, 32, 64, 128, 256, 512, None]),\n",
    "}\n",
    "\n",
    "def objective_dct(params):\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    model = make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        DecisionTreeClassifier(**params),\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=\"roc_auc\", cv=kf, n_jobs=-1).mean()\n",
    "    # model.fit(X_train, y_train)\n",
    "\n",
    "    # y_pred = model.predict_proba(X_test)[:, model.classes_ == 1]\n",
    "    # score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return {\"loss\": 1 - score, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "trials_dct = Trials()\n",
    "\n",
    "best_dct = fmin(\n",
    "    fn=objective_dct,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials_dct,\n",
    ")\n",
    "\n",
    "print(best_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC:  0.6579065690644064\n"
     ]
    }
   ],
   "source": [
    "#best_dct = {'max_depth': 2, 'max_features': 6, 'min_samples_leaf': 6, 'min_samples_split': 6}\n",
    "\n",
    "hyper_dct = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    DecisionTreeClassifier(**best_dct)\n",
    ")\n",
    "\n",
    "hyper_dct.fit(X_train, y_train)\n",
    "\n",
    "# kf = KFold(n_splits=10, random_state=2345, shuffle=True)\n",
    "# roc_auc_scores_hdct = []\n",
    "\n",
    "# for train_index, valid_index in kf.split(X_train):\n",
    "\n",
    "#     X_train_kf, X_valid_kf = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "#     y_train_kf, y_valid_kf = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "#     hyper_dct.fit(X_train_kf, y_train_kf)\n",
    "#     # Metric: roc_auc_score\n",
    "#     roc_auc_scores_hdct.append(roc_auc_score(y_valid_kf, hyper_dct.predict_proba(X_valid_kf)[:, hyper_dct.classes_ == 1]))\n",
    "#     print(f\"ROC-AUC split {len(roc_auc_scores_hdct)}: \", roc_auc_scores_hdct[-1])\n",
    "\n",
    "print(\"ROC-AUC: \", roc_auc_score(y_test, hyper_dct.predict_proba(X_test)[:, hyper_dct.classes_ == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2, max_features=5, min_samples_leaf=6,\n",
       "                       min_samples_split=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, max_features=5, min_samples_leaf=6,\n",
       "                       min_samples_split=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, max_features=5, min_samples_leaf=6,\n",
       "                       min_samples_split=8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_dct.named_steps[\"decisiontreeclassifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.8333333333333334, 'total_visits_item <= 3133.5\\ngini = 0.167\\nsamples = 162684\\nvalue = [147685, 14999]'),\n",
       " Text(0.25, 0.5, 'total_gmv_item_30days <= 270.81\\ngini = 0.115\\nsamples = 106254\\nvalue = [99757, 6497]'),\n",
       " Text(0.125, 0.16666666666666666, 'gini = 0.089\\nsamples = 52476\\nvalue = [50015, 2461]'),\n",
       " Text(0.375, 0.16666666666666666, 'gini = 0.139\\nsamples = 53778\\nvalue = [49742, 4036]'),\n",
       " Text(0.75, 0.5, 'total_gmv_item_30days <= 3918.475\\ngini = 0.256\\nsamples = 56430\\nvalue = [47928, 8502]'),\n",
       " Text(0.625, 0.16666666666666666, 'gini = 0.214\\nsamples = 33062\\nvalue = [29031, 4031]'),\n",
       " Text(0.875, 0.16666666666666666, 'gini = 0.309\\nsamples = 23368\\nvalue = [18897, 4471]')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(hyper_dct.named_steps[\"decisiontreeclassifier\"], max_depth=2, filled=True, feature_names=list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [38:51<00:00, 23.32s/trial, best loss: 0.2121955631253214] \n",
      "{'max_depth': 3, 'max_features': 0, 'min_samples_leaf': 2, 'min_samples_split': 0}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [2, 4, 8, 16, 32, 64, 128, None]),\n",
    "    \"min_samples_split\": hp.choice(\"min_samples_split\", [2, 4, 8, 16, 32, 64, 128]),\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", [2, 4, 8, 16, 32, 64, 128]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [2, 4, 8, 16, 32, 64, 128, None]),\n",
    "}\n",
    "\n",
    "def objective_rfs(params):\n",
    "    model = make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        RandomForestClassifier(**params, n_estimators=100, n_jobs=-1),\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict_proba(X_test)[:, model.classes_ == 1]\n",
    "    score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return {\"loss\": 1 - score, \"status\": STATUS_OK}\n",
    "\n",
    "trials_rfs = Trials()\n",
    "\n",
    "best_rfs = fmin(\n",
    "    fn=objective_rfs,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials_rfs,\n",
    ")\n",
    "\n",
    "print(best_rfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'max_features': 1,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfs[\"max_features\"] = 1\n",
    "best_rfs[\"min_samples_split\"] = 2\n",
    "\n",
    "best_rfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC split 1:  0.7081469103022364\n",
      "ROC-AUC split 2:  0.7180935208870816\n",
      "ROC-AUC split 3:  0.7089286667318965\n",
      "ROC-AUC split 4:  0.7101126956253258\n",
      "ROC-AUC split 5:  0.7035800560823728\n",
      "ROC-AUC split 6:  0.7119053126906797\n",
      "ROC-AUC split 7:  0.7110893194102677\n",
      "ROC-AUC split 8:  0.7074769409294601\n",
      "ROC-AUC split 9:  0.7048135724185971\n",
      "ROC-AUC split 10:  0.7231767164494025\n",
      "ROC-AUC:  0.721804311959505\n"
     ]
    }
   ],
   "source": [
    "hyper_rfs_kf = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(**best_rfs, n_estimators=100, n_jobs=-1)\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=2345, shuffle=True)\n",
    "\n",
    "roc_auc_scores_hrfs = []\n",
    "\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    X_train_kf, X_valid_kf = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_kf, y_valid_kf = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "    hyper_rfs_kf.fit(X_train_kf, y_train_kf)\n",
    "    # Metric: roc_auc_score\n",
    "    roc_auc_scores_hrfs.append(roc_auc_score(y_valid_kf, hyper_rfs_kf.predict_proba(X_valid_kf)[:, hyper_rfs_kf.classes_ == 1]))\n",
    "    print(f\"ROC-AUC split {len(roc_auc_scores_hrfs)}: \", roc_auc_scores_hrfs[-1])\n",
    "\n",
    "print(\"ROC-AUC: \", roc_auc_score(y_test, hyper_rfs_kf.predict_proba(X_test)[:, hyper_rfs_kf.classes_ == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142635583841591"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfs = {\n",
    "    'max_depth': 3,\n",
    "    'max_features': 1,\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 2\n",
    "}\n",
    "\n",
    "hyper_rfs = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(**best_rfs, n_estimators=100, n_jobs=-1)\n",
    ")\n",
    "\n",
    "hyper_rfs.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, hyper_rfs.predict_proba(X_test)[:, hyper_rfs.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6994391273622476"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_cls = dtc.predict_proba(X_test)[:, dtc.classes_ == 1].squeeze()\n",
    "roc_auc_score(y_test, y_preds_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729350839606164"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cls.score(X_validation, y_validation)\n",
    "\n",
    "y_preds_rfs = rfs.predict_proba(X_test)[:, rfs.classes_ == 1].squeeze()\n",
    "roc_auc_score(y_test, y_preds_rfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.3min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m#xgb_model.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m#roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, xgb_model.classes_ == 1])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m cross_val_score(xgb_model, X_train, y_train, scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m\"\u001b[39;49m, cv\u001b[39m=\u001b[39;49mkf, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    missing=-999,\n",
    "    random_state=2020,\n",
    ")\n",
    "\n",
    "#xgb_model.fit(X_train, y_train)\n",
    "#roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, xgb_model.classes_ == 1])\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cross_val_score(xgb_model, X_train, y_train, scoring=\"roc_auc\", cv=kf, n_jobs=-1, verbose=2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_config(verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas hide UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7835950626541037                              \n",
      "{'colsample_bytree': 0.9865558697264714, 'gamma': 0.12929172488084684, 'learning_rate': 0.13214872804415695, 'max_depth': 4, 'min_child_weight': 64, 'n_estimators': 200, 'subsample': 0.5444889526426269}\n",
      "Score: 0.790444423930476                                                          \n",
      "{'colsample_bytree': 0.8378308377556504, 'gamma': 0.15657840294680325, 'learning_rate': 0.090944395149636, 'max_depth': 64, 'min_child_weight': 32, 'n_estimators': 200, 'subsample': 0.9100842750536129}\n",
      "Score: 0.786913381471421                                                          \n",
      "{'colsample_bytree': 0.7701622227291531, 'gamma': 0.9080241945183694, 'learning_rate': 0.0848206061070631, 'max_depth': 8, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.7093527339303067}\n",
      "Score: 0.7857134122233864                                                         \n",
      "{'colsample_bytree': 0.9204395835391892, 'gamma': 0.21033686310911281, 'learning_rate': 0.11598191691159458, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 200, 'subsample': 0.7412500229785695}\n",
      "Score: 0.7706975359604951                                                         \n",
      "{'colsample_bytree': 0.7528093029130206, 'gamma': 0.9884856073861183, 'learning_rate': 0.159431636290394, 'max_depth': 16, 'min_child_weight': 2, 'n_estimators': 10, 'subsample': 0.9857068898196975}\n",
      "Score: 0.7713850362352886                                                         \n",
      "{'colsample_bytree': 0.9379666644799673, 'gamma': 0.2267011141133809, 'learning_rate': 0.13389179519230263, 'max_depth': 32, 'min_child_weight': 4, 'n_estimators': 50, 'subsample': 0.5763116862735704}\n",
      "Score: 0.7471678945706708                                                         \n",
      "{'colsample_bytree': 0.8118393824101248, 'gamma': 0.8657429319981162, 'learning_rate': 0.09534636179729289, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 10, 'subsample': 0.9266136761880551}\n",
      "Score: 0.7935179828419484                                                         \n",
      "{'colsample_bytree': 0.518118348182461, 'gamma': 0.6429631778939885, 'learning_rate': 0.11405184314850203, 'max_depth': 64, 'min_child_weight': 32, 'n_estimators': 100, 'subsample': 0.9116889998094084}\n",
      "Score: 0.7841809226632747                                                         \n",
      "{'colsample_bytree': 0.9461799284779451, 'gamma': 0.6491497718896119, 'learning_rate': 0.1080873522844377, 'max_depth': None, 'min_child_weight': 8, 'n_estimators': 100, 'subsample': 0.7243228369520429}\n",
      "Score: 0.7838155828696315                                                        \n",
      "{'colsample_bytree': 0.9358548567846475, 'gamma': 0.35714428960263556, 'learning_rate': 0.16618816121312832, 'max_depth': 128, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.52606306022064}\n",
      "Score: 0.7758999466753513                                                         \n",
      "{'colsample_bytree': 0.8971026355420901, 'gamma': 0.8820627694578252, 'learning_rate': 0.07087756276024389, 'max_depth': 64, 'min_child_weight': 2, 'n_estimators': 200, 'subsample': 0.9977131967349301}\n",
      "Score: 0.7761263499220155                                                         \n",
      "{'colsample_bytree': 0.8509379576247587, 'gamma': 0.7974105721342394, 'learning_rate': 0.022230952446165776, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 100, 'subsample': 0.5913928970541735}\n",
      "Score: 0.7749597742183432                                                         \n",
      "{'colsample_bytree': 0.5540507902044068, 'gamma': 0.8378956592746589, 'learning_rate': 0.08184494228969498, 'max_depth': 32, 'min_child_weight': 16, 'n_estimators': 10, 'subsample': 0.7823317613212979}\n",
      "Score: 0.7936170776508311                                                         \n",
      "{'colsample_bytree': 0.8026984951481873, 'gamma': 0.3418442916901452, 'learning_rate': 0.04071215589522034, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 500, 'subsample': 0.6046506428505479}\n",
      "Score: 0.775207804947097                                                           \n",
      "{'colsample_bytree': 0.9494165045737254, 'gamma': 0.7869411616482838, 'learning_rate': 0.18478444180654877, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 50, 'subsample': 0.765941407288633}\n",
      "Score: 0.7866863062597783                                                          \n",
      "{'colsample_bytree': 0.9487483438179956, 'gamma': 0.16692938576505367, 'learning_rate': 0.19306115930749745, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 500, 'subsample': 0.9546407086926969}\n",
      "Score: 0.766324330029111                                                           \n",
      "{'colsample_bytree': 0.7820162704203792, 'gamma': 0.8784887799532302, 'learning_rate': 0.012138851573324509, 'max_depth': None, 'min_child_weight': 16, 'n_estimators': 200, 'subsample': 0.8344148955465605}\n",
      "Score: 0.7828251198416163                                                          \n",
      "{'colsample_bytree': 0.5863890567242929, 'gamma': 0.6293809167931501, 'learning_rate': 0.054580419407373446, 'max_depth': 128, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.992237926704446}\n",
      "Score: 0.7783477148375724                                                          \n",
      "{'colsample_bytree': 0.5717318474824258, 'gamma': 0.8702355268268616, 'learning_rate': 0.05892305934241703, 'max_depth': 4, 'min_child_weight': 32, 'n_estimators': 200, 'subsample': 0.6585422049616674}\n",
      "Score: 0.7934841086868731                                                          \n",
      "{'colsample_bytree': 0.7741527765109614, 'gamma': 0.6766991174598227, 'learning_rate': 0.02883687867242854, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.8990017626825968}\n",
      "Score: 0.734568693626922                                                             \n",
      "{'colsample_bytree': 0.6688834414736133, 'gamma': 0.444732088232986, 'learning_rate': 0.04180300913131698, 'max_depth': 2, 'min_child_weight': 128, 'n_estimators': 500, 'subsample': 0.8219731834044212}\n",
      "Score: 0.7895529934099548                                                            \n",
      "{'colsample_bytree': 0.6816888647733228, 'gamma': 0.009888880947395373, 'learning_rate': 0.12993074170699387, 'max_depth': 8, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.659996186744428}\n",
      "Score: 0.784007079538207                                                           \n",
      "{'colsample_bytree': 0.709043770172629, 'gamma': 0.521233974367165, 'learning_rate': 0.152241432769738, 'max_depth': 64, 'min_child_weight': 128, 'n_estimators': 100, 'subsample': 0.6426674635100538}\n",
      "Score: 0.7793729642909979                                                          \n",
      "{'colsample_bytree': 0.5001331869836549, 'gamma': 0.3316747797577532, 'learning_rate': 0.11661903020033056, 'max_depth': 2, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.8526643070153507}\n",
      "Score: 0.7857206703351741                                                          \n",
      "{'colsample_bytree': 0.6498924336533023, 'gamma': 0.5137570739358986, 'learning_rate': 0.06501072239503705, 'max_depth': 64, 'min_child_weight': 4, 'n_estimators': 50, 'subsample': 0.6179015296501221}\n",
      "Score: 0.7814474091816191                                                          \n",
      "{'colsample_bytree': 0.6186970839294359, 'gamma': 0.381640234699753, 'learning_rate': 0.04155887597717734, 'max_depth': 8, 'min_child_weight': 32, 'n_estimators': 100, 'subsample': 0.6998396276159952}\n",
      "Score: 0.7882084760398561                                                          \n",
      "{'colsample_bytree': 0.5219436501904694, 'gamma': 0.570652072270894, 'learning_rate': 0.1431841683644135, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 100, 'subsample': 0.5085082185371789}\n",
      "Score: 0.7856934757789913                                                          \n",
      "{'colsample_bytree': 0.8766514986119126, 'gamma': 0.7148267060753616, 'learning_rate': 0.17331063653163067, 'max_depth': 64, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.8654195520370662}\n",
      "Score: 0.7754886596075158                                                          \n",
      "{'colsample_bytree': 0.9950608297852517, 'gamma': 0.025673087868271494, 'learning_rate': 0.10013151635418356, 'max_depth': 32, 'min_child_weight': 4, 'n_estimators': 100, 'subsample': 0.560954733373179}\n",
      "Score: 0.7883570782022874                                                          \n",
      "{'colsample_bytree': 0.7200656365463789, 'gamma': 0.4338043605034342, 'learning_rate': 0.12513300552265347, 'max_depth': 64, 'min_child_weight': 16, 'n_estimators': 500, 'subsample': 0.8017589990160677}\n",
      "Score: 0.7473998381908332                                                          \n",
      "{'colsample_bytree': 0.8055075817754609, 'gamma': 0.29247399336186897, 'learning_rate': 0.07549750428551101, 'max_depth': 2, 'min_child_weight': 128, 'n_estimators': 50, 'subsample': 0.686419499009379}\n",
      "Score: 0.7779592656788076                                                          \n",
      "{'colsample_bytree': 0.8529692092712485, 'gamma': 0.05346817709531182, 'learning_rate': 0.0473442051405098, 'max_depth': 8, 'min_child_weight': 64, 'n_estimators': 100, 'subsample': 0.612413790541837}\n",
      "Score: 0.7580512974682514                                                          \n",
      "{'colsample_bytree': 0.7246746150394571, 'gamma': 0.5884592776116473, 'learning_rate': 0.08878393691752585, 'max_depth': None, 'min_child_weight': 32, 'n_estimators': 10, 'subsample': 0.8992151674526939}\n",
      "Score: 0.7867094690260903                                                          \n",
      "{'colsample_bytree': 0.623864488041471, 'gamma': 0.27608981119449255, 'learning_rate': 0.01297175263227214, 'max_depth': 128, 'min_child_weight': 4, 'n_estimators': 500, 'subsample': 0.9544025414139174}\n",
      "Score: 0.7879362234211817                                                          \n",
      "{'colsample_bytree': 0.7484259693319549, 'gamma': 0.07799128205228273, 'learning_rate': 0.14723012476994438, 'max_depth': 64, 'min_child_weight': 32, 'n_estimators': 100, 'subsample': 0.7347580058255397}\n",
      "Score: 0.7615069863976309                                                          \n",
      "{'colsample_bytree': 0.8128656160800487, 'gamma': 0.730032306976157, 'learning_rate': 0.11179990426991221, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 10, 'subsample': 0.502190211600867}\n",
      "Score: 0.7910379158597672                                                          \n",
      "{'colsample_bytree': 0.8998021757611939, 'gamma': 0.9618919065884866, 'learning_rate': 0.1381727601311674, 'max_depth': 16, 'min_child_weight': 128, 'n_estimators': 200, 'subsample': 0.7693110932524712}\n",
      "Score: 0.784155739551928                                                           \n",
      "{'colsample_bytree': 0.5342303310138155, 'gamma': 0.4466745227201912, 'learning_rate': 0.12092412322281376, 'max_depth': 64, 'min_child_weight': 8, 'n_estimators': 50, 'subsample': 0.5466484236421941}\n",
      "Score: 0.7758080610271652                                                          \n",
      "{'colsample_bytree': 0.9748898067763245, 'gamma': 0.18751445239559428, 'learning_rate': 0.10355092566022482, 'max_depth': 32, 'min_child_weight': 4, 'n_estimators': 500, 'subsample': 0.8747522609453168}\n",
      "Score: 0.7876330426130996                                                          \n",
      "{'colsample_bytree': 0.6935070856675076, 'gamma': 0.13289796827335798, 'learning_rate': 0.08055676874237502, 'max_depth': 8, 'min_child_weight': 32, 'n_estimators': 100, 'subsample': 0.9408628119994787}\n",
      "Score: 0.7544176223714533                                                          \n",
      "{'colsample_bytree': 0.8334443463153498, 'gamma': 0.2556055622453881, 'learning_rate': 0.09097539241325023, 'max_depth': None, 'min_child_weight': 2, 'n_estimators': 10, 'subsample': 0.6820169752406899}\n",
      "Score: 0.7849475190011671                                                          \n",
      "{'colsample_bytree': 0.7597220786640467, 'gamma': 0.39711889705975506, 'learning_rate': 0.024213647354454068, 'max_depth': 128, 'min_child_weight': 64, 'n_estimators': 200, 'subsample': 0.7260021053364273}\n",
      "Score: 0.7788750782928202                                                          \n",
      "{'colsample_bytree': 0.6423298376129307, 'gamma': 0.5623477969878348, 'learning_rate': 0.15932119004290735, 'max_depth': 4, 'min_child_weight': 16, 'n_estimators': 100, 'subsample': 0.9743697937828909}\n",
      "Score: 0.7773325849097171                                                          \n",
      "{'colsample_bytree': 0.8792738936922897, 'gamma': 0.48100430292506047, 'learning_rate': 0.03289632734373408, 'max_depth': 64, 'min_child_weight': 4, 'n_estimators': 50, 'subsample': 0.7977171311763801}\n",
      "Score: 0.7915831598135822                                                          \n",
      "{'colsample_bytree': 0.7392071409942651, 'gamma': 0.9418892207031899, 'learning_rate': 0.06779844387656489, 'max_depth': 16, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.600430479936445}\n",
      "Score: 0.7605817484735227                                                          \n",
      "{'colsample_bytree': 0.7933722147622286, 'gamma': 0.7767389003179894, 'learning_rate': 0.19780493112918474, 'max_depth': 8, 'min_child_weight': 2, 'n_estimators': 10, 'subsample': 0.5812623752787083}\n",
      "Score: 0.7932510258413166                                                          \n",
      "{'colsample_bytree': 0.595351085211501, 'gamma': 0.33239624685086294, 'learning_rate': 0.05604347324028101, 'max_depth': 32, 'min_child_weight': 16, 'n_estimators': 100, 'subsample': 0.7490847014764367}\n",
      "Score: 0.7699231430488125                                                          \n",
      "{'colsample_bytree': 0.9164080753966279, 'gamma': 0.6179258558786282, 'learning_rate': 0.09669004263481454, 'max_depth': 2, 'min_child_weight': 8, 'n_estimators': 200, 'subsample': 0.6340543661898639}\n",
      "Score: 0.7865067403071455                                                          \n",
      "{'colsample_bytree': 0.8265385347042742, 'gamma': 0.2213676199559662, 'learning_rate': 0.18069312119315922, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 500, 'subsample': 0.9192048450851361}\n",
      "Score: 0.7874627328667934                                                          \n",
      "{'colsample_bytree': 0.500542051957213, 'gamma': 0.7105982508468872, 'learning_rate': 0.10618878668992555, 'max_depth': None, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.5348535580149414}\n",
      "Score: 0.7924852483216762                                                          \n",
      "{'colsample_bytree': 0.5618567417134315, 'gamma': 0.8237702518638772, 'learning_rate': 0.1345087741851732, 'max_depth': 128, 'min_child_weight': 32, 'n_estimators': 100, 'subsample': 0.8263096072422217}\n",
      "Score: 0.7708871057361192                                                          \n",
      "{'colsample_bytree': 0.866620703909031, 'gamma': 0.09509042187072336, 'learning_rate': 0.018465575548954213, 'max_depth': 64, 'min_child_weight': 2, 'n_estimators': 50, 'subsample': 0.9744653922402886}\n",
      "Score: 0.787763145713176                                                           \n",
      "{'colsample_bytree': 0.6678199062434619, 'gamma': 0.6579731388890033, 'learning_rate': 0.08019071342515552, 'max_depth': 8, 'min_child_weight': 128, 'n_estimators': 200, 'subsample': 0.8817342758562068}\n",
      "Score: 0.7635619042529829                                                          \n",
      "{'colsample_bytree': 0.7790146634646036, 'gamma': 0.5345026333127347, 'learning_rate': 0.1629033529625909, 'max_depth': 16, 'min_child_weight': 4, 'n_estimators': 10, 'subsample': 0.5632975505229042}\n",
      "Score: 0.7920686033344095                                                          \n",
      "{'colsample_bytree': 0.9699927795664309, 'gamma': 0.4791454636289643, 'learning_rate': 0.0488599693040538, 'max_depth': 64, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.7606936464049421}\n",
      "Score: 0.7679335437494502                                                          \n",
      "{'colsample_bytree': 0.7024102268328838, 'gamma': 0.3927032154072624, 'learning_rate': 0.06231651259788859, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 100, 'subsample': 0.6745728282019349}\n",
      "Score: 0.7761650924856106                                                          \n",
      "{'colsample_bytree': 0.5951062797503011, 'gamma': 0.7658527382970082, 'learning_rate': 0.12210786386569533, 'max_depth': 2, 'min_child_weight': 16, 'n_estimators': 500, 'subsample': 0.715134288010773}\n",
      "Score: 0.7905956294009368                                                          \n",
      "{'colsample_bytree': 0.5412180811647447, 'gamma': 0.9979005450680625, 'learning_rate': 0.15098499738244936, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 100, 'subsample': 0.804506258263574}\n",
      "Score: 0.7740988802785008                                                          \n",
      "{'colsample_bytree': 0.9159315565178185, 'gamma': 0.9078117248918081, 'learning_rate': 0.03431519748803333, 'max_depth': 32, 'min_child_weight': 64, 'n_estimators': 50, 'subsample': 0.8475068218040699}\n",
      "Score: 0.7913004049608068                                                          \n",
      "{'colsample_bytree': 0.7314757794667317, 'gamma': 0.32353455051505947, 'learning_rate': 0.07075877932672496, 'max_depth': 64, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.6436864017545189}\n",
      "Score: 0.7854152822778913                                                          \n",
      "{'colsample_bytree': 0.8488830789477265, 'gamma': 0.6036596700303498, 'learning_rate': 0.11068260010658611, 'max_depth': None, 'min_child_weight': 128, 'n_estimators': 200, 'subsample': 0.5155675330734915}\n",
      "Score: 0.7744559695882357                                                          \n",
      "{'colsample_bytree': 0.6192342173707276, 'gamma': 0.6837277319557533, 'learning_rate': 0.12794221035281683, 'max_depth': 128, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.7012587102512664}\n",
      "Score: 0.7645912344473706                                                          \n",
      "{'colsample_bytree': 0.7628692602638838, 'gamma': 0.3628860857688485, 'learning_rate': 0.08753786379284398, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 10, 'subsample': 0.7789450877840999}\n",
      "Score: 0.7870530878855607                                                          \n",
      "{'colsample_bytree': 0.8002071195918317, 'gamma': 0.5524337632431529, 'learning_rate': 0.1382992747241173, 'max_depth': 16, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.6599990096801897}\n",
      "Score: 0.7782263250317208                                                          \n",
      "{'colsample_bytree': 0.6762106896961947, 'gamma': 0.25222924125642165, 'learning_rate': 0.17395985467559932, 'max_depth': 64, 'min_child_weight': 8, 'n_estimators': 100, 'subsample': 0.8942229980378845}\n",
      "Score: 0.7927664723403284                                                          \n",
      "{'colsample_bytree': 0.821172752005096, 'gamma': 0.6472996869740367, 'learning_rate': 0.0334745209130525, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.9406252482430476}\n",
      "Score: 0.792818418348236                                                           \n",
      "{'colsample_bytree': 0.7805919268415373, 'gamma': 0.8161474638039937, 'learning_rate': 0.027016989900209752, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.8486777725061501}\n",
      "Score: 0.7781889797992732                                                          \n",
      "{'colsample_bytree': 0.8970500163934341, 'gamma': 0.4209543029296949, 'learning_rate': 0.01716212870076713, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.8651897045222564}\n",
      "Score: 0.7925618256286303                                                          \n",
      "{'colsample_bytree': 0.7444571413911757, 'gamma': 0.7223936125102888, 'learning_rate': 0.04446242363863813, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.9954191508012138}\n",
      "Score: 0.7803504241291641                                                          \n",
      "{'colsample_bytree': 0.7105743696254355, 'gamma': 0.49753073834220174, 'learning_rate': 0.010182178776104552, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.9068672264760821}\n",
      "Score: 0.7746611903627298                                                          \n",
      "{'colsample_bytree': 0.7694500823772996, 'gamma': 0.7663068498382293, 'learning_rate': 0.07437358358225249, 'max_depth': 2, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.8146403760215123}\n",
      "Score: 0.7927763248599469                                                          \n",
      "{'colsample_bytree': 0.6445774904350042, 'gamma': 0.8478900526156105, 'learning_rate': 0.037656419120903555, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 500, 'subsample': 0.9277328279185904}\n",
      "Score: 0.7850918446182718                                                          \n",
      "{'colsample_bytree': 0.8449405830406502, 'gamma': 0.5780707162822025, 'learning_rate': 0.05265790274165777, 'max_depth': 32, 'min_child_weight': 16, 'n_estimators': 50, 'subsample': 0.8858958206967749}\n",
      "Score: 0.7889112579552866                                                          \n",
      "{'colsample_bytree': 0.8626350852761021, 'gamma': 0.6756958781845556, 'learning_rate': 0.09609621588681937, 'max_depth': 4, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.9714584108609399}\n",
      "Score: 0.7825328996278523                                                          \n",
      "{'colsample_bytree': 0.9318735398722321, 'gamma': 0.7477011410324641, 'learning_rate': 0.06257339688517177, 'max_depth': 64, 'min_child_weight': 128, 'n_estimators': 100, 'subsample': 0.8631656208171136}\n",
      "Score: 0.7822798758878016                                                          \n",
      "{'colsample_bytree': 0.6596320231216406, 'gamma': 0.45694831758250587, 'learning_rate': 0.029958772140180428, 'max_depth': 8, 'min_child_weight': 64, 'n_estimators': 200, 'subsample': 0.8340781826420033}\n",
      "Score: 0.7551258601084972                                                          \n",
      "{'colsample_bytree': 0.6875758552182237, 'gamma': 0.1942603109624387, 'learning_rate': 0.02095081624309509, 'max_depth': None, 'min_child_weight': 4, 'n_estimators': 10, 'subsample': 0.9558620692119817}\n",
      "Score: 0.788999094013205                                                           \n",
      "{'colsample_bytree': 0.7910024470234985, 'gamma': 0.6883337683437698, 'learning_rate': 0.117391543842817, 'max_depth': 128, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.7868306447670408}\n",
      "Score: 0.783572772107234                                                           \n",
      "{'colsample_bytree': 0.8101049608827173, 'gamma': 0.5378164294797585, 'learning_rate': 0.10327336349452623, 'max_depth': 16, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.612799059850158}\n",
      "Score: 0.7821536443740251                                                          \n",
      "{'colsample_bytree': 0.8874367709609242, 'gamma': 0.3107061352406082, 'learning_rate': 0.03967621080596861, 'max_depth': 64, 'min_child_weight': 8, 'n_estimators': 50, 'subsample': 0.9308250760734608}\n",
      "Score: 0.7932221535977371                                                          \n",
      "{'colsample_bytree': 0.720745580280663, 'gamma': 0.6309493295093129, 'learning_rate': 0.049707171815419525, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 500, 'subsample': 0.9142993634814569}\n",
      "Score: 0.7538108335457663                                                          \n",
      "{'colsample_bytree': 0.6331207406066979, 'gamma': 0.41720674869290575, 'learning_rate': 0.057632760776095596, 'max_depth': 2, 'min_child_weight': 16, 'n_estimators': 100, 'subsample': 0.9817022830315282}\n",
      "Score: 0.7911330144795727                                                          \n",
      "{'colsample_bytree': 0.8213008981889898, 'gamma': 0.14999458187265516, 'learning_rate': 0.08401942549085431, 'max_depth': 32, 'min_child_weight': 32, 'n_estimators': 200, 'subsample': 0.9514285560719272}\n",
      "Score: 0.7699718849852994                                                          \n",
      "{'colsample_bytree': 0.5801456334276336, 'gamma': 0.3645140420515509, 'learning_rate': 0.07688792464241546, 'max_depth': 16, 'min_child_weight': 64, 'n_estimators': 10, 'subsample': 0.7338839101186633}\n",
      "Score: 0.787335290926036                                                           \n",
      "{'colsample_bytree': 0.7376174849573418, 'gamma': 0.7968472067278294, 'learning_rate': 0.09366267013441504, 'max_depth': 4, 'min_child_weight': 128, 'n_estimators': 500, 'subsample': 0.7560217063820508}\n",
      "Score: 0.7879703734824073                                                          \n",
      "{'colsample_bytree': 0.511492874902531, 'gamma': 0.915222193817316, 'learning_rate': 0.02532359790895149, 'max_depth': 64, 'min_child_weight': 4, 'n_estimators': 100, 'subsample': 0.5692104241684436}\n",
      "Score: 0.7854634635018797                                                          \n",
      "{'colsample_bytree': 0.8400704370300819, 'gamma': 0.5150082084223748, 'learning_rate': 0.1560315487373105, 'max_depth': 8, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.5484090513363237}\n",
      "Score: 0.7618028957436279                                                          \n",
      "{'colsample_bytree': 0.6070683368523022, 'gamma': 0.47206909028118654, 'learning_rate': 0.016604249223840493, 'max_depth': None, 'min_child_weight': 2, 'n_estimators': 50, 'subsample': 0.8949339430863851}\n",
      "Score: 0.7914421005692869                                                          \n",
      "{'colsample_bytree': 0.7536476460894385, 'gamma': 0.607274541770118, 'learning_rate': 0.11321819707343261, 'max_depth': 128, 'min_child_weight': 64, 'n_estimators': 100, 'subsample': 0.8369335699218067}\n",
      "Score: 0.7784857880653074                                                          \n",
      "{'colsample_bytree': 0.7002855366866347, 'gamma': 0.2858103558896982, 'learning_rate': 0.14663602774946455, 'max_depth': 64, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.6254606415744232}\n",
      "Score: 0.7910262343493794                                                          \n",
      "{'colsample_bytree': 0.7948486662273254, 'gamma': 0.7404901715538119, 'learning_rate': 0.06645578918370264, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 200, 'subsample': 0.9657195975388709}\n",
      "Score: 0.7687388782008384                                                          \n",
      "{'colsample_bytree': 0.9640586682305833, 'gamma': 0.25140335471055963, 'learning_rate': 0.13476737482478257, 'max_depth': 16, 'min_child_weight': 16, 'n_estimators': 10, 'subsample': 0.5915727545901984}\n",
      "Score: 0.7820716913472432                                                          \n",
      "{'colsample_bytree': 0.9981437422885574, 'gamma': 0.7030986226760365, 'learning_rate': 0.1699805357554864, 'max_depth': 2, 'min_child_weight': 32, 'n_estimators': 500, 'subsample': 0.7723946066700667}\n",
      "Score: 0.786099391577098                                                           \n",
      "{'colsample_bytree': 0.865200077665843, 'gamma': 0.9684670675182951, 'learning_rate': 0.10059872784130386, 'max_depth': 32, 'min_child_weight': 128, 'n_estimators': 100, 'subsample': 0.7440678038570017}\n",
      "Score: 0.7554255253382152                                                          \n",
      "{'colsample_bytree': 0.7694980242899008, 'gamma': 0.8548215196820461, 'learning_rate': 0.04405373841577471, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 50, 'subsample': 0.8133151680484999}\n",
      "Score: 0.7888863641003877                                                          \n",
      "{'colsample_bytree': 0.8291591780412495, 'gamma': 0.5934946522788792, 'learning_rate': 0.013154418839053526, 'max_depth': 64, 'min_child_weight': 64, 'n_estimators': 500, 'subsample': 0.7888220805947936}\n",
      "Score: 0.7863151279359908                                                          \n",
      "{'colsample_bytree': 0.6603135974116338, 'gamma': 0.6508265714626934, 'learning_rate': 0.18500472053698058, 'max_depth': 8, 'min_child_weight': 32, 'n_estimators': 100, 'subsample': 0.6729432593313573}\n",
      "Score: 0.7841615246808821                                                          \n",
      "{'colsample_bytree': 0.9062086373268591, 'gamma': 0.4953897715677204, 'learning_rate': 0.120040534833934, 'max_depth': 16, 'min_child_weight': 2, 'n_estimators': 500, 'subsample': 0.7160222095985915}\n",
      "Score: 0.7899752010212159                                                          \n",
      "{'colsample_bytree': 0.7116168561917057, 'gamma': 0.5557482123660566, 'learning_rate': 0.14033316034159868, 'max_depth': None, 'min_child_weight': 8, 'n_estimators': 200, 'subsample': 0.99819024701624}\n",
      "Score: 0.7648514806984157                                                          \n",
      "{'colsample_bytree': 0.9548233965181082, 'gamma': 0.10023822285768133, 'learning_rate': 0.0706282432526214, 'max_depth': 128, 'min_child_weight': 64, 'n_estimators': 10, 'subsample': 0.6951123592420022}\n",
      "100%|| 100/100 [42:59<00:00, 25.80s/trial, best loss: 0.20638292234916888]\n",
      "{'colsample_bytree': 0.8026984951481873, 'gamma': 0.3418442916901452, 'learning_rate': 0.04071215589522034, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 4, 'subsample': 0.6046506428505479}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Hyperopt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "xgb_space = {\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [2, 4, 8, 16, 32, 64, 128, None]),\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.2),\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [10, 50, 100, 200, 500]),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 0, 1),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", [2, 4, 8, 16, 32, 64, 128]),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "}\n",
    "\n",
    "X_train_, X_eval, y_train_, y_eval = train_test_split(X_train, y_train, test_size=0.20, train_size=0.80, random_state=42)\n",
    "\n",
    "# best_score = 0\n",
    "def objective_xgb(params):\n",
    "    # global best_score\n",
    "\n",
    "    #kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    model =  xgb.XGBClassifier(\n",
    "        **params,\n",
    "        early_stopping_rounds=10,\n",
    "        eval_metric=\"auc\",\n",
    "    )\n",
    "\n",
    "    #score = cross_val_score(model, X_train, y_train, scoring=\"roc_auc\", cv=kf, n_jobs=-1).mean()\n",
    "    \n",
    "\n",
    "    model.fit(X_train_, y_train_, eval_set=[(X_eval, y_eval)], verbose=False)\n",
    "\n",
    "    score = roc_auc_score(y_test, model.predict_proba(X_test)[:, model.classes_ == 1])\n",
    "    \n",
    "    print(f\"Score: {score}\", params)\n",
    "\n",
    "    # if score > best_score:\n",
    "        # best_score = score\n",
    "        # print(f\"New best score: {best_score}\")\n",
    "        # print(params)\n",
    "        \n",
    "    return {\"loss\": 1 - score, \"status\": STATUS_OK}\n",
    "\n",
    "trials_xgb = Trials()\n",
    "\n",
    "best_xgb = fmin(\n",
    "    fn=objective_xgb,\n",
    "    space=xgb_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials_xgb,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(best_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8026984951481873,\n",
       " 'gamma': 0.3418442916901452,\n",
       " 'learning_rate': 0.04071215589522034,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 4,\n",
       " 'subsample': 0.6046506428505479}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_xgb = {'colsample_bytree': 0.6278514796444425,\n",
    "#  'learning_rate': 0.07068021279873352,\n",
    "#  'max_depth': 7,\n",
    "#  'n_estimators': 4,\n",
    "#  'subsample': 0.763643037745022}\n",
    "\n",
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    missing=-999,\n",
    "    random_state=2020,\n",
    ")\n",
    "\n",
    "#xgb_model.fit(X_train, y_train)\n",
    "#roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, xgb_model.classes_ == 1])\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cross_val_score(xgb_model, X_train, y_train, scoring=\"roc_auc\", cv=kf, n_jobs=-1, verbose=2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=-999, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=-999, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=-999, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_xgb =  xgb.XGBClassifier(\n",
    "    missing=-999,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "simple_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.791723253386352"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, simple_xgb.predict_proba(X_test)[:, simple_xgb.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144608, 53) (144608, 1485)\n"
     ]
    }
   ],
   "source": [
    "imputed_X_train = SimpleImputer().fit_transform(X_train)\n",
    "poly = PolynomialFeatures(2)\n",
    "poly_X_train = poly.fit_transform(imputed_X_train)\n",
    "\n",
    "print(imputed_X_train.shape, poly_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m atributes_to_poly \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mavailable_quantity\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mavg_gmv_item_domain_30days\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m                     ]\n\u001b[1;32m     13\u001b[0m imputed_poly_features \u001b[39m=\u001b[39m make_pipeline(\n\u001b[1;32m     14\u001b[0m     SimpleImputer(),\n\u001b[1;32m     15\u001b[0m     PolynomialFeatures(degree\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m imputed_poly_features\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     27\u001b[0m roc_auc_score(y_test, imputed_poly_features\u001b[39m.\u001b[39mpredict_proba(X_test)[:, imputed_poly_features\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "atributes_to_poly = [\n",
    "                        \"available_quantity\", \n",
    "                        \"avg_gmv_item_domain_30days\", \n",
    "                        \"avg_gmv_item_sel\", \n",
    "                        \"avg_gmv_seller_bday\", \n",
    "                        \"avg_qty_orders_item_domain_30days\", \n",
    "                        \"avg_qty_orders_item_sel_30days\", \n",
    "                        \"avg_si_item_sel_30day\",\n",
    "                        \"original_price\",\n",
    "                        \"price\",\n",
    "                    ]\n",
    "\n",
    "imputed_poly_features = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    PolynomialFeatures(degree=2,\n",
    "                       include_bias=False,\n",
    "                       interaction_only=False,\n",
    "                    ),\n",
    "    xgb.XGBClassifier(\n",
    "        missing=-999,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    ")\n",
    "\n",
    "imputed_poly_features.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, imputed_poly_features.predict_proba(X_test)[:, imputed_poly_features.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_bst = dask_xgboost.train(client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.753) total time=   3.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.761) total time=   4.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.756) total time=   4.1s\n",
      "[CV] END ................................ score: (test=0.750) total time=   4.2s\n",
      "[CV] END ................................ score: (test=0.750) total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    6.0s remaining:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.0s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.1s remaining:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.747) total time=   4.2s\n",
      "[CV] END ................................ score: (test=0.745) total time=   4.1s\n",
      "[CV] END ................................ score: (test=0.751) total time=   4.2s\n",
      "[CV] END ................................ score: (test=0.746) total time=   2.7s\n",
      "[CV] END ................................ score: (test=0.752) total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.751205010063007"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'colsample_bytree': 0.6278514796444425,\n",
    "    'learning_rate': 0.07068021279873352,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 4,\n",
    "    'subsample': 0.763643037745022\n",
    "}\n",
    "\n",
    "xgb_kf = make_pipeline(\n",
    "    #SimpleImputer(),\n",
    "    xgb.XGBClassifier(\n",
    "        **params,\n",
    "        missing=-999,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    ")\n",
    "\n",
    "#xgb_kf.fit(X_train, y_train, verbose = True)\n",
    "#roc_auc_score(y_test, xgb_kf.predict_proba(X_test)[:, xgb_kf.classes_ == 1])\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "cross_val_score(\n",
    "    xgb_kf, \n",
    "    X_train, y_train, \n",
    "    scoring=\"roc_auc\", \n",
    "    cv=KFold(n_splits=10, shuffle=True), \n",
    "    n_jobs=-1, \n",
    "    verbose=10\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7556616698520179"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_colab1 = {\n",
    "  'colsample_bytree': 0.8337751225603421,\n",
    " 'gamma': 0.869242256759736,\n",
    " 'learning_rate': 0.1452990294484685,\n",
    " 'max_depth': 7,\n",
    " 'min_child_weight': 5,\n",
    " 'n_estimators': 4,\n",
    " 'subsample': 0.850647916320707\n",
    "}\n",
    "\n",
    "hyper_xgb_colab1 = xgb.XGBClassifier(\n",
    "        **params_colab1,\n",
    "        missing=-999,\n",
    "        n_jobs=-1,\n",
    "        #tree_method='gpu_hist',\n",
    "    )\n",
    "\n",
    "hyper_xgb_colab1.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, hyper_xgb_colab1.predict_proba(X_test)[:, hyper_xgb_colab1.classes_ == 1])\n",
    "\n",
    "# Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7434762707253941"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_xgb_kf = xgb.XGBClassifier(\n",
    "    **best_xgb,\n",
    "    missing=-999,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "#hyper_xgb.fit(X_train, y_train)\n",
    "cross_val_score(hyper_xgb_kf, X_train, y_train, scoring=\"roc_auc\", cv=kf, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8026984951481873,\n",
       " 'gamma': 0.3418442916901452,\n",
       " 'learning_rate': 0.04071215589522034,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 4,\n",
       " 'subsample': 0.6046506428505479}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7229693543206894"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_xgb2_params1 = {'colsample_bytree': 0.8026984951481873,\n",
    " 'gamma': 0.3418442916901452,\n",
    " 'learning_rate': 0.04071215589522034,\n",
    " 'max_depth': 2,\n",
    " 'min_child_weight': 1,\n",
    " 'n_estimators': 4,\n",
    " 'subsample': 0.6046506428505479}\n",
    "\n",
    "hyper_xgb2 = xgb.XGBClassifier(\n",
    "        **hyper_xgb2_params1,\n",
    "        missing=-999,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "#kf = KFold(n_splits=10, shuffle=True)\n",
    "#cross_val_score(hyper_xgb_kf, X_train, y_train, scoring=\"roc_auc\", cv=kf, n_jobs=-1).mean()\n",
    "hyper_xgb2.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, hyper_xgb2.predict_proba(X_test)[:, hyper_xgb2.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ...................... (1 of 2) Processing rfs, total=   1.0s\n",
      "[Voting] ...................... (2 of 2) Processing xgb, total=   2.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7429049409565275"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble best RFS and XGB\n",
    "\n",
    "best_rfs = {\n",
    "    'max_depth': 3, 'max_features': 1, 'min_samples_leaf': 2, 'min_samples_split': 2\n",
    "}\n",
    "\n",
    "hyper_rfs = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(**best_rfs, n_estimators=100, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# best_xgb = {'colsample_bytree': 0.6580566715010197, 'learning_rate': 0.04956976966729988, 'max_depth': None, 'n_estimators': 500, 'subsample': 0.7679968914163563}\n",
    "\n",
    "hyper_xgb = xgb.XGBClassifier(\n",
    "    **best_xgb,\n",
    "    missing=-999,\n",
    ")\n",
    "\n",
    "# Ensemble best RFS and XGB\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_rfs_xgb = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfs\", hyper_rfs),\n",
    "        (\"xgb\", hyper_xgb),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "voting_rfs_xgb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, voting_rfs_xgb.predict_proba(X_test)[:, voting_rfs_xgb.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ...................... (1 of 2) Processing rfs, total=   1.5s\n",
      "[Voting] ...................... (2 of 2) Processing xgb, total=   3.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;rfs&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                               SimpleImputer()),\n",
       "                                              (&#x27;randomforestclassifier&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=3,\n",
       "                                                                      max_features=1,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      n_jobs=-1))])),\n",
       "                             (&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.6278514796444425,\n",
       "                                            early_st...\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.07068021279873352,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=7,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=-999,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=4, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))],\n",
       "                 n_jobs=-1, verbose=True, voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rfs&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                               SimpleImputer()),\n",
       "                                              (&#x27;randomforestclassifier&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=3,\n",
       "                                                                      max_features=1,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      n_jobs=-1))])),\n",
       "                             (&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.6278514796444425,\n",
       "                                            early_st...\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.07068021279873352,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=7,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=-999,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=4, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))],\n",
       "                 n_jobs=-1, verbose=True, voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rfs</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, max_features=1, min_samples_leaf=2,\n",
       "                       n_jobs=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6278514796444425, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.07068021279873352,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=-999, monotone_constraints=None,\n",
       "              n_estimators=4, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('rfs',\n",
       "                              Pipeline(steps=[('simpleimputer',\n",
       "                                               SimpleImputer()),\n",
       "                                              ('randomforestclassifier',\n",
       "                                               RandomForestClassifier(max_depth=3,\n",
       "                                                                      max_features=1,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      n_jobs=-1))])),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.6278514796444425,\n",
       "                                            early_st...\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.07068021279873352,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=7,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=-999,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=4, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))],\n",
       "                 n_jobs=-1, verbose=True, voting='soft')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_rfs = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(**best_rfs, n_estimators=100, n_jobs=-1)\n",
    ")\n",
    "\n",
    "hyper_xgb = xgb.XGBClassifier(\n",
    "    **best_xgb,\n",
    "    missing=-999,\n",
    ")\n",
    "\n",
    "voting_rfs_xgb = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfs\", hyper_rfs),\n",
    "        (\"xgb\", hyper_xgb),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "voting_rfs_xgb.fit(pd.concat([X_train, X_test]), pd.concat([y_train, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_xgb = xgb.XGBClassifier(\n",
    "    **best_xgb,\n",
    "    missing=-999,\n",
    ")\n",
    "\n",
    "hyper_xgb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, hyper_xgb.predict_proba(X_test)[:, hyper_xgb.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model = xgb_kf\n",
    "\n",
    "    comp_data = load_comp()#pd.read_csv(\"data/competition_data.csv\")\n",
    "    eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "    del comp_data\n",
    "\n",
    "    # Predict on the evaluation set\n",
    "    eval_data = eval_data.drop(columns=[\"conversion\"])\n",
    "    eval_data = eval_data.select_dtypes(include='number')\n",
    "    y_preds = model.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, model.classes_ == 1].squeeze()\n",
    "\n",
    "    # Make the submission file\n",
    "    submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "    submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "    submission_df.to_csv(\"los_simuladores_XGB_HP_KF.csv\", sep=\",\", index=False)\n",
    "\n",
    "    del eval_data\n",
    "    del submission_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Keras\n",
    "\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n",
    "# LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Imputer\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3747596414.py, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 55\u001b[0;36m\u001b[0m\n\u001b[0;31m    Dense(48, activation='relu'),\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "nn = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    # Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nn.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam', \n",
    "    metrics=[AUC(curve='ROC'), 'accuracy'],\n",
    ")\n",
    "\n",
    "imputed_X_train = SimpleImputer().fit_transform(X_train)\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=10)\n",
    "\n",
    "nn.fit(\n",
    "    imputed_X_train, y_train, \n",
    "    epochs=100, \n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping_monitor],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "si = SimpleImputer()\n",
    "\n",
    "pre_test = si.fit_transform(X_test)\n",
    "\n",
    "roc_auc_score(y_test, nn.predict(pre_test))\n",
    "\n",
    "#Epoch 22/100 66/66 [==============================] - 0s 6ms/step - loss: 0.2585 - auc_2: 0.7976 - accuracy: 0.9060 - val_loss: 0.3086 - val_auc_2: 0.6831 - val_accuracy: 0.9019\n",
    "# roc_auc_score: 0.6979974555991236\n",
    "\n",
    "# Ideas to improve the model\n",
    "\n",
    "# - Add more layers: done\n",
    "# - Add more neurons: done\n",
    "# - Add more epochs: okay?\n",
    "# - Add more data: not possible\n",
    "# - Add more features\n",
    "# - Add more models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = load_model(\"nn.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>avg_gmv_item_domain_30days</th>\n",
       "      <th>avg_gmv_item_sel</th>\n",
       "      <th>avg_gmv_seller_bday</th>\n",
       "      <th>avg_qty_orders_item_domain_30days</th>\n",
       "      <th>avg_qty_orders_item_sel_30days</th>\n",
       "      <th>avg_si_item_sel_30day</th>\n",
       "      <th>boosted</th>\n",
       "      <th>category_id</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>...</th>\n",
       "      <th>logistic_type_fulfillment</th>\n",
       "      <th>logistic_type_not_specified</th>\n",
       "      <th>logistic_type_xd_drop_off</th>\n",
       "      <th>platform_/mobile/android</th>\n",
       "      <th>platform_/mobile/ios</th>\n",
       "      <th>platform_/web/desktop</th>\n",
       "      <th>platform_/web/mobile</th>\n",
       "      <th>site_id_MLA</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>cheaper_than_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64710</th>\n",
       "      <td>5</td>\n",
       "      <td>249.776555</td>\n",
       "      <td>747.413341</td>\n",
       "      <td>11559.993000</td>\n",
       "      <td>2.966431</td>\n",
       "      <td>7.853448</td>\n",
       "      <td>11.338362</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>1616</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92879</th>\n",
       "      <td>37</td>\n",
       "      <td>56.508268</td>\n",
       "      <td>775.357073</td>\n",
       "      <td>2119.309333</td>\n",
       "      <td>4.696088</td>\n",
       "      <td>9.060976</td>\n",
       "      <td>9.085366</td>\n",
       "      <td>0</td>\n",
       "      <td>655</td>\n",
       "      <td>1635</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88940</th>\n",
       "      <td>14</td>\n",
       "      <td>176.602768</td>\n",
       "      <td>93.577761</td>\n",
       "      <td>208.990333</td>\n",
       "      <td>3.549203</td>\n",
       "      <td>1.820896</td>\n",
       "      <td>1.820896</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147968</th>\n",
       "      <td>5</td>\n",
       "      <td>126.115742</td>\n",
       "      <td>195.818268</td>\n",
       "      <td>6520.748333</td>\n",
       "      <td>2.901772</td>\n",
       "      <td>2.857858</td>\n",
       "      <td>5.436436</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>1651</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163934</th>\n",
       "      <td>18</td>\n",
       "      <td>1784.470739</td>\n",
       "      <td>11924.477619</td>\n",
       "      <td>16694.268667</td>\n",
       "      <td>2.904280</td>\n",
       "      <td>31.809524</td>\n",
       "      <td>32.595238</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>1110</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171941</th>\n",
       "      <td>4</td>\n",
       "      <td>25.834588</td>\n",
       "      <td>46.615930</td>\n",
       "      <td>400.897000</td>\n",
       "      <td>1.723025</td>\n",
       "      <td>4.248062</td>\n",
       "      <td>5.414729</td>\n",
       "      <td>0</td>\n",
       "      <td>1929</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113098</th>\n",
       "      <td>13</td>\n",
       "      <td>68.100506</td>\n",
       "      <td>21.902213</td>\n",
       "      <td>267.207000</td>\n",
       "      <td>1.838201</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.336066</td>\n",
       "      <td>0</td>\n",
       "      <td>1035</td>\n",
       "      <td>1615</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175470</th>\n",
       "      <td>66</td>\n",
       "      <td>169.890058</td>\n",
       "      <td>362.028750</td>\n",
       "      <td>7916.362000</td>\n",
       "      <td>6.477655</td>\n",
       "      <td>16.626524</td>\n",
       "      <td>48.038110</td>\n",
       "      <td>0</td>\n",
       "      <td>1548</td>\n",
       "      <td>1598</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23122</th>\n",
       "      <td>264</td>\n",
       "      <td>43.494263</td>\n",
       "      <td>171.187404</td>\n",
       "      <td>1934.417667</td>\n",
       "      <td>2.939330</td>\n",
       "      <td>2.412979</td>\n",
       "      <td>2.855457</td>\n",
       "      <td>0</td>\n",
       "      <td>1726</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74709</th>\n",
       "      <td>14</td>\n",
       "      <td>359.760683</td>\n",
       "      <td>451.145623</td>\n",
       "      <td>4225.730667</td>\n",
       "      <td>13.464075</td>\n",
       "      <td>7.245552</td>\n",
       "      <td>7.594306</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>586</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36153 rows  51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        available_quantity  avg_gmv_item_domain_30days  avg_gmv_item_sel  \\\n",
       "64710                    5                  249.776555        747.413341   \n",
       "92879                   37                   56.508268        775.357073   \n",
       "88940                   14                  176.602768         93.577761   \n",
       "147968                   5                  126.115742        195.818268   \n",
       "163934                  18                 1784.470739      11924.477619   \n",
       "...                    ...                         ...               ...   \n",
       "171941                   4                   25.834588         46.615930   \n",
       "113098                  13                   68.100506         21.902213   \n",
       "175470                  66                  169.890058        362.028750   \n",
       "23122                  264                   43.494263        171.187404   \n",
       "74709                   14                  359.760683        451.145623   \n",
       "\n",
       "        avg_gmv_seller_bday  avg_qty_orders_item_domain_30days  \\\n",
       "64710          11559.993000                           2.966431   \n",
       "92879           2119.309333                           4.696088   \n",
       "88940            208.990333                           3.549203   \n",
       "147968          6520.748333                           2.901772   \n",
       "163934         16694.268667                           2.904280   \n",
       "...                     ...                                ...   \n",
       "171941           400.897000                           1.723025   \n",
       "113098           267.207000                           1.838201   \n",
       "175470          7916.362000                           6.477655   \n",
       "23122           1934.417667                           2.939330   \n",
       "74709           4225.730667                          13.464075   \n",
       "\n",
       "        avg_qty_orders_item_sel_30days  avg_si_item_sel_30day  boosted  \\\n",
       "64710                         7.853448              11.338362        0   \n",
       "92879                         9.060976               9.085366        0   \n",
       "88940                         1.820896               1.820896        0   \n",
       "147968                        2.857858               5.436436        0   \n",
       "163934                       31.809524              32.595238        0   \n",
       "...                                ...                    ...      ...   \n",
       "171941                        4.248062               5.414729        0   \n",
       "113098                        2.000000               2.336066        0   \n",
       "175470                       16.626524              48.038110        0   \n",
       "23122                         2.412979               2.855457        0   \n",
       "74709                         7.245552               7.594306        0   \n",
       "\n",
       "        category_id  domain_id  ...  logistic_type_fulfillment  \\\n",
       "64710          1988       1616  ...                          0   \n",
       "92879           655       1635  ...                          1   \n",
       "88940            62       1380  ...                          0   \n",
       "147968          223       1651  ...                          1   \n",
       "163934          241       1110  ...                          1   \n",
       "...             ...        ...  ...                        ...   \n",
       "171941         1929        620  ...                          0   \n",
       "113098         1035       1615  ...                          0   \n",
       "175470         1548       1598  ...                          0   \n",
       "23122          1726         55  ...                          0   \n",
       "74709           148        586  ...                          0   \n",
       "\n",
       "        logistic_type_not_specified  logistic_type_xd_drop_off  \\\n",
       "64710                             0                          0   \n",
       "92879                             0                          0   \n",
       "88940                             0                          0   \n",
       "147968                            0                          0   \n",
       "163934                            0                          0   \n",
       "...                             ...                        ...   \n",
       "171941                            0                          0   \n",
       "113098                            0                          0   \n",
       "175470                            0                          0   \n",
       "23122                             0                          0   \n",
       "74709                             0                          0   \n",
       "\n",
       "        platform_/mobile/android  platform_/mobile/ios  platform_/web/desktop  \\\n",
       "64710                          1                     0                      0   \n",
       "92879                          1                     0                      0   \n",
       "88940                          0                     0                      1   \n",
       "147968                         0                     0                      0   \n",
       "163934                         1                     0                      0   \n",
       "...                          ...                   ...                    ...   \n",
       "171941                         1                     0                      0   \n",
       "113098                         0                     0                      0   \n",
       "175470                         1                     0                      0   \n",
       "23122                          0                     0                      1   \n",
       "74709                          1                     0                      0   \n",
       "\n",
       "        platform_/web/mobile  site_id_MLA  price_diff  cheaper_than_original  \n",
       "64710                      0            1         681                      1  \n",
       "92879                      0            1         189                      1  \n",
       "88940                      0            1         130                      1  \n",
       "147968                     1            1         619                      1  \n",
       "163934                     0            1        4900                      1  \n",
       "...                      ...          ...         ...                    ...  \n",
       "171941                     0            1         105                      1  \n",
       "113098                     1            1          30                      1  \n",
       "175470                     0            1          97                      1  \n",
       "23122                      0            1         200                      1  \n",
       "74709                      0            1         168                      1  \n",
       "\n",
       "[36153 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "2023-08-29 13:11:47.212001: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_29 is incompatible with the layer: expected axis 1 of input shape to have value 52 but received input with shape (None, 51)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m si \u001b[39m=\u001b[39m SimpleImputer()\n\u001b[1;32m      7\u001b[0m pre_test \u001b[39m=\u001b[39m si\u001b[39m.\u001b[39mfit_transform(X_test)\n\u001b[0;32m----> 9\u001b[0m roc_auc_score(y_test, nn\u001b[39m.\u001b[39;49mpredict(pre_test))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1629\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1628\u001b[0m   callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1629\u001b[0m   tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   1630\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1631\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    872\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2970\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3198\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3199\u001b[0m         args,\n\u001b[1;32m   3200\u001b[0m         kwargs,\n\u001b[1;32m   3201\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3202\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3203\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3204\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3205\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3206\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m    992\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[39m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/nacho/opt/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_29 is incompatible with the layer: expected axis 1 of input shape to have value 52 but received input with shape (None, 51)\n"
     ]
    }
   ],
   "source": [
    "# roc_auc_score(y_test, nn.predict_proba(X_test)[:, nn.classes_ == 1])\n",
    "# AttributeError: 'Sequential' object has no attribute 'predict_proba'\n",
    "\n",
    "\n",
    "si = SimpleImputer()\n",
    "\n",
    "pre_test = si.fit_transform(X_test)\n",
    "\n",
    "roc_auc_score(y_test, nn.predict(pre_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save(\"nn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
