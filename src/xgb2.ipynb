{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = True\n",
    "ohe = False\n",
    "new_features = True\n",
    "hp_tune = False\n",
    "balance_train = False\n",
    "add_tags = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Names and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Columns\n",
    "The following columns are available on the training set:\n",
    "\n",
    "accepts_mercadopago Whether the item accepts Mercado Pago\n",
    "available_quantity The available stock quantity at that moment\n",
    "avg_asp_item_bday Average selling price of this item over the last days\n",
    "avg_asp_item_domain Average price of items of the domain this item belongs to\n",
    "avg_asp_item_sel Average price of seller sales\n",
    "avg_gmv_item_bday average revenue generated by the item per day\n",
    "avg_gmv_item_domain_30days Average revenue generated by the items of this domain on the last month\n",
    "avg_gmv_item_sel Average revenue of items of this seller\n",
    "avg_gmv_seller_bday Average revenue this seller makes by day\n",
    "avg_orders_item_bday Average number of orders this item has by day\n",
    "avg_orders_seller_bday Average orders the seller has by day\n",
    "avg_qty_orders_item_domain_30days Average number of orders a random item of this domain made on the last month\n",
    "avg_qty_orders_item_sel_30days Average number of orders an item of this seller makes on the last 30 days\n",
    "avg_si_item_bday Average units sold this item has by day\n",
    "avg_si_item_sel_30day Average units sold of an item of this seller on the past month\n",
    "avg_visits_item Average visits this item had\n",
    "benefit Ignore, should be dropped\n",
    "boosted Whether the item was boosted\n",
    "buy_server_timestamp Timestamp of the purchase\n",
    "category_id Category of this item\n",
    "conversion Target variable, it is True if this print has an attributed order\n",
    "cus_cust_id Buyer id\n",
    "cus_cust_id_sel Seller id\n",
    "date Print date\n",
    "deal_print_id Unique id for the print\n",
    "decimals Ignore, will be dropped\n",
    "domain_id Domain id for the item\n",
    "etl_version Ignore, should be dropped\n",
    "free_shipping Whether the item has free shipping\n",
    "fulfillment Whether the item is fulfilled by MeLi\n",
    "full_name Category full name\n",
    "health Item health\n",
    "is_pdp Whether the click landed on a PDP\n",
    "product_id Product_id of the item\n",
    "item_id ID of the item, useful for debugging\n",
    "listing_type_id Whether the item is gold or not\n",
    "logistic_type Logistic type for the item\n",
    "main_picture URL for the main item picture\n",
    "offset On which page the item was rendered\n",
    "original_price Price from which the discount was done\n",
    "platform Which platform the user is using\n",
    "price Item price\n",
    "print_position Position on the page\n",
    "print_server_timestamp Timestamp for the print\n",
    "qty_items_dom Number of items this domain has\n",
    "qty_items_sel Number of items the seller has\n",
    "rn Leftover from the ETL, Discard\n",
    "ROW_ID Row of the submission file\n",
    "site_id Site ID\n",
    "sold_quantity Number of items sold at the moment of the print\n",
    "tags Tags the item had at the moment of the print\n",
    "title Item title\n",
    "total_asp_item_domain_30days Average selling price of the items of the domain\n",
    "total_asp_item_sel_30days Average selling price of all the items the seller sold on the last 30 days\n",
    "total_gmv_domain_30days Total revenue the domain made on the last 30 days\n",
    "total_gmv_domain_bday total_gmv_domain_30days / 30\n",
    "total_gmv_item_30days Total revenue made by the item on the lasts 30 days\n",
    "total_gmv_seller Total revenue made by the seller on the last month\n",
    "total_items_domain Number of items on the domain\n",
    "total_items_seller Number of items the seller has\n",
    "total_orders_domain_30days Total orders on the domain\n",
    "total_orders_item_30days Total orders the Item had on the last 30 days\n",
    "total_orders_sel_30days Total orders for the seller\n",
    "total_si_domain_30days Total units sold of this domain\n",
    "total_si_item_30days Total units sold of this item\n",
    "total_si_sel_30days Same for the seller\n",
    "total_visits_domain Total visits on this domain\n",
    "total_visits_item Total visits this item had\n",
    "total_visits_seller Total visits for this seller\n",
    "uid session id\n",
    "user_id user id\n",
    "warranty Whether the item had warranty\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(models, model_names, X_test, y_test, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, models[i].predict_proba(X_test)[:, models[i].classes_ == 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label=model_names[i] + ' (area = %0.5f)' % roc_auc)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "\n",
    "    plt.ylim([0.0, 1.05])\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "\n",
    "    # Show grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Comp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = pd.read_csv(\"data/competition_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                #\"- **{}** ({}) \\n\\n {}\".format(col, dtype, comp_data[col].value_counts()) for col, dtype in\n",
    "                #\"- **{}** ({})\".format(col, dtype) for col, dtype in\n",
    "                #zip(comp_data.columns, comp_data.dtypes)\n",
    "                \"- **{}**\".format(col) for col in comp_data.columns\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = pd.read_csv(\"data/competition_data.csv\")\n",
    "comp_data = comp_data.drop(\n",
    "        columns=[\n",
    "            \"accepts_mercadopago\", # Todos tienen mercadopago\n",
    "            \"boosted\", # Ninguno\n",
    "            \"avg_qty_orders_item_domain_30days\",\n",
    "            \"avg_qty_orders_item_sel_30days\",\n",
    "            \"avg_si_item_sel_30day\",\n",
    "            #\"date\",\n",
    "            \"deal_print_id\",\n",
    "            \"etl_version\",\n",
    "            \"full_name\",\n",
    "            \"main_picture\",\n",
    "            \"print_server_timestamp\",\n",
    "            #\"title\",\n",
    "            \"uid\",\n",
    "            #\"user_id\",\n",
    "            \"avg_gmv_item_domain_30days\",\n",
    "            #\"avg_gmv_item_sel\",\n",
    "            \"avg_gmv_seller_bday\",\n",
    "            #\"qty_items_dom\",\n",
    "            #\"category_id\",\n",
    "            #\"domain_id\",\n",
    "            #\"product_id\",\n",
    "            #\"listing_type_id\",\n",
    "            # \"logistic_type\",\n",
    "            \"site_id\",\n",
    "            #\"tags\",\n",
    "            \"total_asp_item_sel_30days\", \n",
    "            \"total_gmv_domain_bday\", \n",
    "            #\"total_items_domain\", \n",
    "            \"total_items_seller\", \n",
    "            \"total_orders_domain_30days\", \n",
    "            \"total_orders_item_30days\", \n",
    "            \"total_orders_sel_30days\", \n",
    "            \"total_si_sel_30days\", \n",
    "            #\"total_visits_domain\", \n",
    "            #\"total_visits_item\", \n",
    "            #\"total_visits_seller\",\n",
    "            \"total_asp_item_domain_30days\",\n",
    "            \"total_gmv_item_30days\",\n",
    "            \"total_si_domain_30days\",\n",
    "            \"total_si_item_30days\",\n",
    "            \"warranty\",\n",
    "            # \"offset\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                #\"- **{}** ({}) \\n\\n {}\".format(col, dtype, comp_data[col].value_counts()) for col, dtype in\n",
    "                #\"- **{}** ({})\".format(col, dtype) for col, dtype in\n",
    "                #zip(comp_data.columns, comp_data.dtypes)\n",
    "                \"- **{}**\".format(col) for col in comp_data.columns\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_tags:\n",
    "    if len(tags) == 0:\n",
    "        tags = comp_data[\"tags\"].str.replace(\"[\", \"\").str.replace(\"]\", \"\").str.split(\", \").apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For tag in tags, create a new column with the tag name and a boolean value\n",
    "\n",
    "if add_tags:\n",
    "    for tag in tags.index:\n",
    "        comp_data[tag] = comp_data[\"tags\"].str.contains(tag).astype(int)\n",
    "\n",
    "    comp_data[\"tags_count\"] = comp_data[\"tags\"].str.replace(\"[\", \"\").str.replace(\"]\", \"\").str.split(\", \").apply(len)\n",
    "\n",
    "    comp_data = comp_data.drop(\"tags\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data[\"domain_id\"] = LabelEncoder().fit_transform(comp_data[\"domain_id\"]).astype(int)\n",
    "# comp_data[\"product_id\"] = LabelEncoder().fit_transform(comp_data[\"product_id\"]).astype(int)\n",
    "\n",
    "# OneHotEncoder\n",
    "# comp_data = pd.get_dummies(comp_data, columns=[\"category_id\"], dtype=int, sparse=True, dummy_na = False)\n",
    "# Add category_id ohe category column if that category has more than 1000 ocurrences\n",
    "# ocurrences = comp_data[\"category_id\"].value_counts()\n",
    "# for category_id in ocurrences[ocurrences > 1000].index:\n",
    "#     comp_data[\"category_id_\" + str(category_id)] = comp_data[\"category_id\"] == category_id\n",
    "#     comp_data[\"category_id_\" + str(category_id)] = comp_data[\"category_id_\" + str(category_id)].astype(int)\n",
    "# comp_data = comp_data.drop(columns=[\"category_id\"])\n",
    "\n",
    "# comp_data = pd.get_dummies(comp_data, columns=[\"logistic_type\"], dtype=int, sparse=True, dummy_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data[\"date\"] = pd.to_datetime(comp_data[\"date\"])\n",
    "comp_data[\"day\"] = comp_data[\"date\"].dt.day\n",
    "comp_data[\"month\"] = comp_data[\"date\"].dt.month\n",
    "#comp_data[\"hour\"] = comp_data[\"date\"].dt.hour\n",
    "# comp_data[\"year\"] = comp_data[\"date\"].dt.year\n",
    "comp_data[\"dayofweek\"] = comp_data[\"date\"].dt.dayofweek\n",
    "# comp_data[\"weekofyear\"] = comp_data[\"date\"].dt.isocalendar().week\n",
    "#comp_data[\"quarter\"] = comp_data[\"date\"].dt.quarter\n",
    "# comp_data[\"hour\"] = comp_data[\"date\"].dt.hour\n",
    "# comp_data[\"minute\"] = comp_data[\"date\"].dt.minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data[\"date\"].min(), comp_data[\"date\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = comp_data.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse boolean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data[\"boosted\"] = comp_data[\"boosted\"].astype(int)\n",
    "comp_data[\"free_shipping\"] = comp_data[\"free_shipping\"].astype(int)\n",
    "comp_data[\"fulfillment\"] = comp_data[\"fulfillment\"].astype(int)\n",
    "\n",
    "comp_data[\"imp_is_pdp\"] = comp_data[\"is_pdp\"].isna().astype(int)\n",
    "comp_data[\"is_pdp\"].fillna(0, inplace=True)\n",
    "comp_data[\"is_pdp\"] = comp_data[\"is_pdp\"].astype(int)\n",
    "\n",
    "comp_data[\"imp_user_id\"] = comp_data[\"user_id\"].isna().astype(int)\n",
    "comp_data[\"user_id\"] = comp_data[\"user_id\"].fillna(0).astype(int)\n",
    "\n",
    "comp_data[\"listing_type_id\"] = comp_data[\"listing_type_id\"].apply(lambda x: 0 if x == \"gold_special\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lab_enc:\n",
    "    # LabelEncoder\n",
    "    comp_data[\"platform\"] = LabelEncoder().fit_transform(comp_data[\"platform\"]).astype(int)\n",
    "    #comp_data[\"category_id\"] = LabelEncoder().fit_transform(comp_data[\"category_id\"]).astype(int)\n",
    "    comp_data[\"product_id\"] = LabelEncoder().fit_transform(comp_data[\"product_id\"]).astype(int)\n",
    "    comp_data[\"domain_id\"] = LabelEncoder().fit_transform(comp_data[\"domain_id\"]).astype(int)\n",
    "    comp_data[\"logistic_type\"] = LabelEncoder().fit_transform(comp_data[\"logistic_type\"]).astype(int)\n",
    "\n",
    "if ohe:\n",
    "    # OHE\n",
    "    comp_data = pd.get_dummies(comp_data,\n",
    "                            columns = [\n",
    "                                # \"platform\",\n",
    "                                \"category_id\",\n",
    "                                # \"domain_id\"\n",
    "                                ],\n",
    "                            sparse = True,    # Devolver una matriz rala.\n",
    "                            dummy_na = False, # No agregar columna para NaNs.\n",
    "                            dtype = int       # XGBoost no trabaja con 'object'; necesitamos que sean numÃ©ricos.\n",
    "                        )\n",
    "\n",
    "\n",
    "# Encode category_id as a number, but number is based on ocurrences of category_id\n",
    "# ! Has data leakage\n",
    "#ocurrences = comp_data[\"category_id\"].value_counts()\n",
    "#for category_id in ocurrences.index:\n",
    "#    comp_data[\"category_id\"] = comp_data[\"category_id\"].replace(category_id, ocurrences[category_id])\n",
    "\n",
    "# comp_data[\"category_id\"] = comp_data[\"category_id\"].apply(lambda x: ocurrences[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_features:\n",
    "    comp_data[\"price_diff\"] = comp_data[\"price\"] - comp_data[\"original_price\"]\n",
    "    comp_data[\"price_diff\"] = comp_data[\"price_diff\"].apply(lambda x: abs(x)).astype(int)\n",
    "\n",
    "    comp_data[\"discount\"] = (comp_data[\"original_price\"] - comp_data[\"price\"]) / comp_data[\"original_price\"]\n",
    "    comp_data[\"discount\"] = comp_data[\"discount\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"price_ratio\"] = comp_data[\"price\"] / comp_data[\"original_price\"]\n",
    "    comp_data[\"price_ratio\"] = comp_data[\"price_ratio\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"is_discount\"] = comp_data[\"discount\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    comp_data[\"title_length\"] = comp_data[\"title\"].str.len()\n",
    "    comp_data[\"title_word_count\"] = comp_data[\"title\"].str.split(\" \").apply(len)\n",
    "\n",
    "    comp_data[\"title_length_word_count\"] = comp_data[\"title_length\"] / comp_data[\"title_word_count\"]\n",
    "    comp_data[\"title_length_word_count\"] = comp_data[\"title_length_word_count\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"domain_dominance\"] = comp_data[\"sold_quantity\"] / comp_data[\"qty_items_dom\"]\n",
    "\n",
    "    comp_data[\"is_pdp_tvi\"] = comp_data[\"is_pdp\"] / comp_data[\"total_visits_item\"]\n",
    "    comp_data[\"is_pdp_tvi\"] = comp_data[\"is_pdp_tvi\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"is_pdp_tvs\"] = comp_data[\"is_pdp\"] / comp_data[\"total_visits_seller\"]\n",
    "    comp_data[\"is_pdp_tvs\"] = comp_data[\"is_pdp_tvs\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"is_pdp_tvd\"] = comp_data[\"is_pdp\"] / comp_data[\"total_visits_domain\"]\n",
    "    comp_data[\"is_pdp_tvd\"] = comp_data[\"is_pdp_tvd\"].apply(lambda x: 1 if x == np.inf else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data = comp_data.dropna(subset=[\"avg_gmv_item_sel\"])\n",
    "\n",
    "# Fil nas for [\"avg_gmv_item_sel\", \"qty_items_dom\", \"qty_items_sel\", \"domain_dominance\"]\n",
    "\n",
    "comp_data[\"nan_imputed\"] = comp_data[\"avg_gmv_item_sel\"].isna().astype(int)\n",
    "\n",
    "comp_data[\"avg_gmv_item_sel\"] = comp_data[\"avg_gmv_item_sel\"].fillna(comp_data[\"avg_gmv_item_sel\"].median())\n",
    "comp_data[\"qty_items_dom\"] = comp_data[\"qty_items_dom\"].fillna(comp_data[\"qty_items_dom\"].median())\n",
    "comp_data[\"qty_items_sel\"] = comp_data[\"qty_items_sel\"].fillna(comp_data[\"qty_items_sel\"].median())\n",
    "comp_data[\"domain_dominance\"] = comp_data[\"domain_dominance\"].fillna(comp_data[\"domain_dominance\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                #\"- **{}** ({}) \\n\\n {}\".format(col, dtype, comp_data[col].value_counts()) for col, dtype in\n",
    "                #\"- **{}** ({})\".format(col, dtype) for col, dtype in\n",
    "                #zip(comp_data.columns, comp_data.dtypes)\n",
    "                \"- **{}**\".format(col) for col in comp_data.columns\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this columns for variance\n",
    "# accepts_mercadopago\n",
    "# available_quantity\n",
    "# avg_gmv_item_domain_30days\n",
    "# avg_gmv_item_sel\n",
    "# avg_gmv_seller_bday\n",
    "# avg_qty_orders_item_domain_30days\n",
    "# avg_qty_orders_item_sel_30days\n",
    "# avg_si_item_sel_30day\n",
    "# benefit\n",
    "# boosted\n",
    "# category_id\n",
    "# conversion\n",
    "# date\n",
    "# deal_print_id\n",
    "# domain_id\n",
    "# etl_version\n",
    "# free_shipping\n",
    "# fulfillment\n",
    "# full_name\n",
    "# health\n",
    "# is_pdp\n",
    "# product_id\n",
    "# item_id\n",
    "# listing_type_id\n",
    "# logistic_type\n",
    "# main_picture\n",
    "# offset\n",
    "# original_price\n",
    "# platform\n",
    "# price\n",
    "# print_position\n",
    "# print_server_timestamp\n",
    "# qty_items_dom\n",
    "# qty_items_sel\n",
    "# old_quantity\n",
    "# tags\n",
    "# title\n",
    "# total_asp_item_domain_30days\n",
    "# total_asp_item_sel_30days\n",
    "# total_gmv_domain_bday\n",
    "# total_gmv_item_30days\n",
    "# total_items_domain\n",
    "# total_items_seller\n",
    "# total_orders_domain_30days\n",
    "# total_orders_item_30days\n",
    "# total_orders_sel_30days\n",
    "# total_si_domain_30days\n",
    "# total_si_item_30days\n",
    "# total_si_sel_30days\n",
    "# total_visits_domain\n",
    "# total_visits_item\n",
    "# total_visits_seller\n",
    "# uid\n",
    "# user_id\n",
    "# warranty\n",
    "\n",
    "# for col in comp_data.columns:\n",
    "#     print()\n",
    "#     print(col)\n",
    "#     print(comp_data[col].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data.groupby(\"user_id\")[\"conversion\"].sum()\n",
    "# comp_data[comp_data[\"conversion\"] == True][\"user_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance conversion\n",
    "# comp_data = comp_data.drop(comp_data[comp_data[\"conversion\"] == False].sample(frac=.5).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data[\"conversion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 'offset' vs 'category_id' . Dot color depends on 'conversion'\n",
    "\n",
    "plt.scatter(full_data[\"offset\"], full_data[\"discount\"], c=full_data[\"conversion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(\n",
    "    new_train_data[\"offset\"],\n",
    "    new_train_data[\"discount\"],\n",
    "    new_train_data[\"is_pdp\"],\n",
    "    c=new_train_data[\"conversion\"],\n",
    "    # cmap=\"coolwarm\",\n",
    "    alpha=.5\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"offset\")\n",
    "ax.set_ylabel(\"discount\")\n",
    "ax.set_zlabel(\"is_pdp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot 'offset', 'discount', 'category_id' in 3D. Dot color depends on 'conversion'\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# ax.scatter(\n",
    "#     new_test_data[\"offset\"],\n",
    "#     new_test_data[\"discount\"],\n",
    "#     new_test_data[\"price_diff\"],\n",
    "#     c=new_test_data[\"conversion\"],\n",
    "#     # cmap=\"coolwarm\",\n",
    "#     alpha=.5\n",
    "# )\n",
    "\n",
    "# ax.set_xlabel(\"offset\")\n",
    "# ax.set_ylabel(\"discount\")\n",
    "# ax.set_zlabel(\"price_diff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# # ax = fig.add_subplot(111)\n",
    "# ax.scatter(\n",
    "#     new_test_data[\"offset\"],\n",
    "#     new_test_data[\"price_diff\"],\n",
    "#     new_test_data[\"offset\"] ** 2 + new_test_data[\"price_diff\"]**2,\n",
    "#     c=new_test_data[\"conversion\"],\n",
    "# )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot hist boosted\n",
    "# plot_data = comp_data.groupby(\"is_pdp\")[\"conversion\"].sum()\n",
    "# plot_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hour vs conversion\n",
    "#comp_data.groupby(\"dayofweek\")[\"conversion\"].mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Comp Data -> Full | Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "# del comp_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/competition_data.csv\")\n",
    "# print(df.isna().sum()[df.isna().sum() > 0])\n",
    "# del df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nan values per column\n",
    "\n",
    "full_data.isna().sum()[full_data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following cols have nan values\n",
    "# avg_gmv_item_sel\n",
    "# qty_items_dom\n",
    "# qty_items_sel\n",
    "# domain_dominance depends on qty_items_dom\n",
    "\n",
    "# For those columns, are the rows with nan values the same?\n",
    "\n",
    "# full_data[full_data[\"avg_gmv_item_sel\"].isna()][\"qty_items_dom\"].isna().sum(), full_data[full_data[\"avg_gmv_item_sel\"].isna()][\"qty_items_sel\"].isna().sum(), full_data[full_data[\"avg_gmv_item_sel\"].isna()][\"domain_dominance\"].isna().sum()\n",
    "\n",
    "# Yes, they are the same rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop those rows\n",
    "\n",
    "# full_data = full_data.dropna(subset=[\"avg_gmv_item_sel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nan values per column\n",
    "\n",
    "full_data.isna().sum()[full_data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "full_data = full_data.sample(frac=1, random_state=19092140).reset_index(drop=True)\n",
    "\n",
    "train_data, test_data = train_test_split(full_data, test_size=0.25, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_converts_test = test_data[test_data[\"conversion\"] == True].shape[0]\n",
    "count_not_converts_test = test_data[test_data[\"conversion\"] == False].shape[0]\n",
    "ratio = count_converts_test / count_not_converts_test\n",
    "\n",
    "# From test_data, keep ratio of count_not_converts_test entries\n",
    "\n",
    "not_converts = test_data[test_data[\"conversion\"] == False].sample(frac=ratio)\n",
    "\n",
    "new_test_data = pd.concat([test_data[test_data[\"conversion\"] == True], not_converts])\n",
    "new_test_data[\"conversion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance Train Data by conversion\n",
    "\n",
    "len(train_data[train_data[\"conversion\"] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance_train:\n",
    "\n",
    "    count_converts_train = len(train_data[train_data[\"conversion\"] == True])\n",
    "    count_not_converts_train = len(train_data[train_data[\"conversion\"] == False])\n",
    "\n",
    "    ratio = count_converts_train / count_not_converts_train\n",
    "\n",
    "    # From train_data, keep ratio of count_not_converts_train entries\n",
    "\n",
    "    not_converts = train_data[train_data[\"conversion\"] == False].sample(frac=ratio)\n",
    "\n",
    "    new_train_data = pd.concat([train_data[train_data[\"conversion\"] == True], not_converts])\n",
    "\n",
    "    train_data = new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Oversample, repeats into Validation\n",
    "# train_data = train_data.append(train_data[train_data[\"conversion\"] == True].sample(frac=1, replace=True))\n",
    "# train_data = train_data.append(train_data[train_data[\"conversion\"] == True].sample(frac=1, replace=True))\n",
    "# train_data[\"conversion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split X | y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"conversion\"]\n",
    "X_train = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_train = X_train.select_dtypes(include='number')\n",
    "\n",
    "y_test = test_data[\"conversion\"]\n",
    "X_test = test_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_test = X_test.select_dtypes(include='number')\n",
    "\n",
    "del train_data\n",
    "del test_data\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.25, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model (Default params) with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1_model = xgb.XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    seed = random_state,\n",
    "    eval_metric = 'auc',\n",
    "    n_jobs=-1,\n",
    "    #base_score=0.74\n",
    ")\n",
    "\n",
    "xgb1_model.fit(X_train_sub, y_train_sub, eval_set=[(X_val, y_val)], verbose=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, xgb1_model.predict_proba(X_test)[:, xgb1_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, xgb1_model.predict_proba(X_test)[:, xgb1_model.classes_ == 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.5f)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('Receiver operating characteristic example')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "xgb.plot_importance(xgb1_model, max_num_features=20, importance_type=\"gain\", xlabel=\"Gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "xgb.plot_importance(xgb1_model, max_num_features=20, importance_type=\"cover\", xlabel=\"Cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Importance from the classifier xgb1_model\n",
    "feature_importances = pd.DataFrame(\n",
    "    xgb1_model.feature_importances_,\n",
    "    index = X_train.columns,\n",
    "    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gain column\n",
    "gains = sorted(xgb1_model.get_booster().get_score(importance_type=\"gain\").items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "gains_pd = pd.DataFrame(gains, columns=[\"feature\", \"gain\"]).set_index(\"feature\").sort_values(\"gain\", ascending=False)\n",
    "\n",
    "gains_pd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model (Top 20 Gain params) with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2_model = xgb.XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    seed = random_state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "reduced_cols = gains_pd.head(20).index\n",
    "\n",
    "xgb2_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, xgb2_model.predict_proba(X_test)[:, xgb2_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers = sorted(xgb1_model.get_booster().get_score(importance_type=\"cover\").items(), key=lambda x: x[1], reverse=True)\n",
    "covers_pd = pd.DataFrame(covers, columns=[\"feature\", \"cover\"]).set_index(\"feature\").sort_values(\"cover\", ascending=False)\n",
    "\n",
    "\n",
    "xgb_model_covers = xgb.XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    seed = random_state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "reduced_cols = covers_pd.head(20).index\n",
    "\n",
    "xgb_model_covers.fit(X_train[reduced_cols], y_train)\n",
    "\n",
    "roc_auc_score(y_test, xgb_model_covers.predict_proba(X_test[reduced_cols])[:, xgb_model_covers.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, xgb2_model.predict_proba(X_test)[:, xgb2_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "xgb.plot_importance(xgb2_model, max_num_features=20, importance_type=\"gain\", xlabel=\"Gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "fig, ax = plt.subplots(figsize=(5, 20))\n",
    "\n",
    "xgb.plot_importance(xgb2_model, max_num_features=100, importance_type=\"gain\", xlabel=\"Gain\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Model with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del comp_data\n",
    "# del full_data\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'colsample_bytree': 0.9958188825321641, 'gamma': 0.9488078042954764, 'learning_rate': 0.07108927605766976, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 4, 'subsample': 0.8232243201689888}\n",
    "xgb4_model = xgb.XGBClassifier(\n",
    "        # **params,\n",
    "        objective = 'binary:logistic',\n",
    "        seed = random_state,\n",
    "        n_jobs=-1,\n",
    ")\n",
    "\n",
    "xgb4_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, xgb4_model.predict_proba(X_test)[:, xgb4_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC on Balanced X_test (Subsampled X_test for conversion == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = new_test_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "new_X_test = new_X_test.select_dtypes(include='number')\n",
    "\n",
    "new_y_test = new_test_data[\"conversion\"]\n",
    "\n",
    "roc_auc_score(new_y_test, xgb2_model.predict_proba(new_X_test)[:, xgb2_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for xgb2_model on new_test_data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mx = confusion_matrix(new_y_test, xgb2_model.predict(new_X_test))\n",
    "\n",
    "true_neg, false_pos, false_neg, true_pos = conf_mx.ravel()\n",
    "\n",
    "true_neg, false_pos, false_neg, true_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" xgb3_model = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    xgb.XGBClassifier(\n",
    "        objective = 'binary:logistic',\n",
    "        seed = random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    ")\n",
    "\n",
    "xgb3_model.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, xgb3_model.predict_proba(X_test)[:, xgb3_model.classes_ == 1]) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, rfc.predict_proba(X_test)[:, rfc.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier (XGBoost + Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_rfc_xgb = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model)\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_rfc_xgb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, voting_rfc_xgb.predict_proba(X_test)[:, voting_rfc_xgb.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    GradientBoostingClassifier()\n",
    ")\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, gbc.predict_proba(X_test)[:, gbc.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingClassifier()\n",
    "\n",
    "hgb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, hgb.predict_proba(X_test)[:, hgb.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, abc.predict_proba(X_test)[:, abc.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    ExtraTreesClassifier()\n",
    ")\n",
    "\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, etc.predict_proba(X_test)[:, etc.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier Alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_alt = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model),\n",
    "        (\"hgb\", hgb),\n",
    "        (\"abc\", abc),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_alt.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, voting_alt.predict_proba(X_test)[:, voting_alt.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average classifier\n",
    "from sklearn.utils._pprint import _EstimatorPrettyPrinter\n",
    "\n",
    "class AverageClassifier:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.classes_ = models[0].classes_\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.mean([model.predict_proba(X) for model in self.models], axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.mean([model.predict(X) for model in self.models], axis=0)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "\n",
    "    def __repr__(self, N_CHAR_MAX=700):\n",
    "        # N_CHAR_MAX is the (approximate) maximum number of non-blank\n",
    "        # characters to render. We pass it as an optional parameter to ease\n",
    "        # the tests.\n",
    "\n",
    "        # Using _EstimatorPrettyPrinter\n",
    "\n",
    "        pp = _EstimatorPrettyPrinter(\n",
    "            compact=True,\n",
    "            indent=1,\n",
    "            indent_at_name=True,\n",
    "            n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW,\n",
    "        )\n",
    "\n",
    "        repr_ = pp.pformat(self)\n",
    "\n",
    "        return repr_\n",
    "        \n",
    "\n",
    "\n",
    "average_classifier = AverageClassifier([rfc, xgb4_model, hgb, abc, voting_alt])\n",
    "\n",
    "# average_classifier.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, average_classifier.predict_proba(X_test)[:, average_classifier.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model),\n",
    "        (\"hgb\", hgb),\n",
    "        (\"abc\", abc),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, stacking_classifier.predict_proba(X_test)[:, stacking_classifier.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_classifier2 = AverageClassifier([voting_alt, stacking_classifier])\n",
    "\n",
    "average_classifier.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, average_classifier2.predict_proba(X_test)[:, average_classifier2.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logistic_regression = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    LogisticRegression(\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "best_score = 0\n",
    "best_cut = 0\n",
    "for i in range(1, 20):\n",
    "\n",
    "    logistic_regression.fit(X_train[reduced_cols[:i]], y_train)\n",
    "\n",
    "    score = roc_auc_score(y_test, logistic_regression.predict_proba(X_test[reduced_cols[:i]])[:, logistic_regression.classes_ == 1])\n",
    "\n",
    "    print(i, score)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_cut = i\n",
    "\n",
    "best_score, best_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=True),\n",
    "    LogisticRegression(\n",
    "        n_jobs=-1,\n",
    "        max_iter=1000\n",
    "    )\n",
    ")\n",
    "\n",
    "logistic_regression.fit(X_train[reduced_cols[:3]], y_train)\n",
    "\n",
    "roc_auc_score(y_test, logistic_regression.predict_proba(X_test[reduced_cols[:3]])[:, logistic_regression.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_classifier_rfc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(),\n",
    "        n_estimators=10,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "bagging_classifier_rfc.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, bagging_classifier_rfc.predict_proba(X_test)[:, bagging_classifier_rfc.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_classifier_logistic = BaggingClassifier(\n",
    "    estimator=LogisticRegression(\n",
    "        n_jobs=-1,\n",
    "        max_iter=1000\n",
    "    ),\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bagging_classifier_logistic.fit(X_train[reduced_cols[:best_cut]], y_train)\n",
    "\n",
    "roc_auc_score(y_test, bagging_classifier_logistic.predict_proba(X_test[reduced_cols[:best_cut]])[:, bagging_classifier_logistic.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_classifier_xgb = BaggingClassifier(\n",
    "    base_estimator=xgb.XGBClassifier(\n",
    "        objective = 'binary:logistic',\n",
    "        seed = random_state,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bagging_classifier_xgb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, bagging_classifier_xgb.predict_proba(X_test)[:, bagging_classifier_xgb.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier_2 = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model),\n",
    "        (\"hgb\", hgb),\n",
    "        (\"abc\", abc),\n",
    "        (\"bg_xgb\", bagging_classifier_xgb),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_classifier_2.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, stacking_classifier_2.predict_proba(X_test)[:, stacking_classifier_2.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_alt_2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model),\n",
    "        (\"hgb\", hgb),\n",
    "        (\"abc\", abc),\n",
    "        (\"bg_xgb\", bagging_classifier_xgb),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_alt_2.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, voting_alt_2.predict_proba(X_test)[:, voting_alt_2.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_classifier_3 = AverageClassifier([voting_alt_2, stacking_classifier_2])\n",
    "\n",
    "average_classifier_3.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, average_classifier_3.predict_proba(X_test)[:, average_classifier_3.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == True].shape[0], y_train[y_train == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #(logistic_regression, \"logistic_regression\"),\n",
    "    (rfc, \"RandomForestClassifier\"),\n",
    "    (xgb1_model, \"xgb1_model\"),\n",
    "    (xgb2_model, \"xgb2_model\"),\n",
    "    (xgb4_model, \"xgb4_model\"), \n",
    "    (voting_rfc_xgb, \"voting_rfc_xgb\"), \n",
    "    #(gbc, \"gbc\"), \n",
    "    (hgb, \"hgb\"),\n",
    "    (abc, \"abc\"), \n",
    "    # (etc, \"etc\"), \n",
    "    (voting_alt, \"voting_alt\"),\n",
    "    (voting_alt_2, \"voting_alt_2\"),\n",
    "    (stacking_classifier, \"stacking_classifier\"),\n",
    "    (stacking_classifier_2, \"stacking_classifier_2\"),\n",
    "    (average_classifier, \"average_classifier\"),\n",
    "    (average_classifier2, \"average_classifier2\"),\n",
    "    (average_classifier_3, \"average_classifier_3\"),\n",
    "    # (bagging_classifier_rfc, \"bagging_classifier_rfc\"),\n",
    "    # (bagging_classifier_logistic, \"bagging_classifier_logistic\"),\n",
    "    (bagging_classifier_xgb, \"bagging_classifier_xgb\"),\n",
    "]\n",
    "\n",
    "model_names = [model[1] for model in models]\n",
    "models = [model[0] for model in models]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# plot_roc_curves(models, model_names, new_X_test, new_y_test, ax=ax)\n",
    "plot_roc_curves(models, model_names, X_test, y_test, ax=ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with Hyperopt\n",
    "if hp_tune:\n",
    "\n",
    "    xgb_space = {\n",
    "        \"max_depth\": hp.choice(\"max_depth\", [2, 4, 8, 16, 32, 64, 128, None]),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.2),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", [10, 50, 100, 200, 500]),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 0, 1),\n",
    "        \"min_child_weight\": hp.choice(\"min_child_weight\", [2, 4, 8, 16, 32, 64, 128]),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    def objective_xgb(params):\n",
    "        global best_score\n",
    "\n",
    "        model = xgb.XGBClassifier(\n",
    "            **params,\n",
    "            objective = 'binary:logistic',\n",
    "            seed = random_state,\n",
    "            n_jobs=-1,\n",
    "            #eval_metric = 'auc',\n",
    "        )\n",
    "        \n",
    "        score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "\n",
    "        #model.fit(X_train_sub, y_train_sub, eval_set=[(X_val, y_val)], verbose=0)\n",
    "        #model.fit(X_train, y_train)\n",
    "        #score = roc_auc_score(y_test, model.predict_proba(X_test)[:, model.classes_ == 1])\n",
    "\n",
    "        # print(f\"Score: {score}\", params)\n",
    "\n",
    "        # if score > best_score:\n",
    "        #     best_score = score\n",
    "        #     print(f\"New best score: {best_score}\")\n",
    "        #     print(params)\n",
    "            \n",
    "        return {\"loss\": 1 - score, \"status\": STATUS_OK}\n",
    "\n",
    "    trials_xgb = Trials()\n",
    "\n",
    "    best_xgb = fmin(\n",
    "        fn=objective_xgb,\n",
    "        space=xgb_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=100,\n",
    "        trials=trials_xgb,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    print(best_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'colsample_bytree': 0.5261530316412195, 'gamma': 0.4666423706737293, 'learning_rate': 0.043284110571295886, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 4, 'subsample': 0.8142370483321494}\n",
    "model = xgb.XGBClassifier(\n",
    "    **p,\n",
    "    objective = 'binary:logistic',\n",
    "    seed = random_state,\n",
    "    n_jobs=-1,\n",
    "    #eval_metric = 'auc',\n",
    ")\n",
    "\n",
    "#score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, model.predict_proba(X_test)[:, model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"is_discount\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classifier = AverageClassifier([voting_alt_2, stacking_classifier_2])\n",
    "\n",
    "X_full = full_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_full = X_full.select_dtypes(include='number')\n",
    "\n",
    "y_full = full_data[\"conversion\"]\n",
    "\n",
    "final_classifier.fit(X_full, y_full)\n",
    "\n",
    "# Should be 1, full_data contains test_data \n",
    "roc_auc_score(y_test, final_classifier.predict_proba(X_test)[:, final_classifier.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_full, final_classifier.predict_proba(X_full)[:, final_classifier.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils._pprint import _EstimatorPrettyPrinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dif = set(X_full.columns)\n",
    "\n",
    "for model in models:\n",
    "    # if Pipeline, get last step\n",
    "    if isinstance(model, sklearn.pipeline.Pipeline):\n",
    "        model = model.steps[-1][1]\n",
    "    \n",
    "    # print feature names\n",
    "    if isinstance(model, xgb.XGBClassifier):\n",
    "        print(model.get_booster().feature_names)\n",
    "    elif isinstance(model, VotingClassifier):\n",
    "        for estimator in model.estimators_:\n",
    "            if isinstance(estimator, sklearn.pipeline.Pipeline):\n",
    "                estimator = estimator.steps[-1][1]\n",
    "            print(estimator)\n",
    "            if isinstance(estimator, xgb.XGBClassifier):\n",
    "                print(estimator.get_booster().feature_names)\n",
    "            #elif isinstance(estimator, HistGradientBoostingClassifier):\n",
    "             #   print(estimator.feature_names_)\n",
    "            #elif isinstance(estimator, GradientBoostingClassifier):\n",
    "             #   print(estimator.feature_names_)\n",
    "    elif isinstance(model, StackingClassifier):\n",
    "        for estimator in model.estimators_:\n",
    "            if isinstance(estimator, sklearn.pipeline.Pipeline):\n",
    "                estimator = estimator.steps[-1][1]\n",
    "            print(estimator)\n",
    "            if isinstance(estimator, xgb.XGBClassifier):\n",
    "                print(estimator.get_booster().feature_names)\n",
    "            #elif isinstance(estimator, HistGradientBoostingClassifier):\n",
    "             #   print(estimator.feature_names_)\n",
    "            #elif isinstance(estimator, GradientBoostingClassifier):\n",
    "              #  print(estimator.feature_names_)\n",
    "    #elif isinstance(model, BaggingClassifier):\n",
    "    #    print(model.base_estimator_.get_booster().feature_names)\n",
    "    elif isinstance(model, HistGradientBoostingClassifier):\n",
    "        #print(model.feature_names_)\n",
    "        pass\n",
    "    elif isinstance(model, GradientBoostingClassifier):\n",
    "        # print(model.feature_names_)\n",
    "        pass\n",
    "    elif isinstance(model, RandomForestClassifier):\n",
    "       pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = xgb4_model.get_booster().feature_names\n",
    "\n",
    "model = final_classifier\n",
    "\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "# del comp_data\n",
    "\n",
    "# Predict on the evaluation set\n",
    "eval_data = eval_data.drop(columns=[\"conversion\"])\n",
    "eval_data = eval_data.select_dtypes(include='number')\n",
    "y_preds = model.predict_proba(eval_data[feature_cols])[:, model.classes_ == 1].squeeze()\n",
    "\n",
    "# Make the submission file\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"los_simuladores_avg(stack(bagging_classifier_xgb(xgb), xgb, hgb, abc), voting(xgb, hgb, abc))_full_data.csv\", index=False)\n",
    "\n",
    "#del eval_data\n",
    "#del submission_df\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "\n",
    "pickle.dump(final_classifier, open(\"los_simuladores_avg(stack(bagging_classifier_xgb(xgb), xgb, hgb, abc), voting(xgb, hgb, abc))_full_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
