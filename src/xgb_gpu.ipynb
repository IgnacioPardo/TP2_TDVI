{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement py-xgboost-gpu (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for py-xgboost-gpu\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!SYSTEM_VERSION_COMPAT=0 pip install py-xgboost-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = False\n",
    "ohe = False\n",
    "new_features = True\n",
    "hp_tune = False\n",
    "balance_train = False\n",
    "add_tags = False\n",
    "tfidf_title = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Names and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nColumns\\nThe following columns are available on the training set:\\n\\naccepts_mercadopago Whether the item accepts Mercado Pago\\navailable_quantity The available stock quantity at that moment\\navg_asp_item_bday Average selling price of this item over the last days\\navg_asp_item_domain Average price of items of the domain this item belongs to\\navg_asp_item_sel Average price of seller sales\\navg_gmv_item_bday average revenue generated by the item per day\\navg_gmv_item_domain_30days Average revenue generated by the items of this domain on the last month\\navg_gmv_item_sel Average revenue of items of this seller\\navg_gmv_seller_bday Average revenue this seller makes by day\\navg_orders_item_bday Average number of orders this item has by day\\navg_orders_seller_bday Average orders the seller has by day\\navg_qty_orders_item_domain_30days Average number of orders a random item of this domain made on the last month\\navg_qty_orders_item_sel_30days Average number of orders an item of this seller makes on the last 30 days\\navg_si_item_bday Average units sold this item has by day\\navg_si_item_sel_30day Average units sold of an item of this seller on the past month\\navg_visits_item Average visits this item had\\nbenefit Ignore, should be dropped\\nboosted Whether the item was boosted\\nbuy_server_timestamp Timestamp of the purchase\\ncategory_id Category of this item\\nconversion Target variable, it is True if this print has an attributed order\\ncus_cust_id Buyer id\\ncus_cust_id_sel Seller id\\ndate Print date\\ndeal_print_id Unique id for the print\\ndecimals Ignore, will be dropped\\ndomain_id Domain id for the item\\netl_version Ignore, should be dropped\\nfree_shipping Whether the item has free shipping\\nfulfillment Whether the item is fulfilled by MeLi\\nfull_name Category full name\\nhealth Item health\\nis_pdp Whether the click landed on a PDP\\nproduct_id Product_id of the item\\nitem_id ID of the item, useful for debugging\\nlisting_type_id Whether the item is gold or not\\nlogistic_type Logistic type for the item\\nmain_picture URL for the main item picture\\noffset On which page the item was rendered\\noriginal_price Price from which the discount was done\\nplatform Which platform the user is using\\nprice Item price\\nprint_position Position on the page\\nprint_server_timestamp Timestamp for the print\\nqty_items_dom Number of items this domain has\\nqty_items_sel Number of items the seller has\\nrn Leftover from the ETL, Discard\\nROW_ID Row of the submission file\\nsite_id Site ID\\nsold_quantity Number of items sold at the moment of the print\\ntags Tags the item had at the moment of the print\\ntitle Item title\\ntotal_asp_item_domain_30days Average selling price of the items of the domain\\ntotal_asp_item_sel_30days Average selling price of all the items the seller sold on the last 30 days\\ntotal_gmv_domain_30days Total revenue the domain made on the last 30 days\\ntotal_gmv_domain_bday total_gmv_domain_30days / 30\\ntotal_gmv_item_30days Total revenue made by the item on the lasts 30 days\\ntotal_gmv_seller Total revenue made by the seller on the last month\\ntotal_items_domain Number of items on the domain\\ntotal_items_seller Number of items the seller has\\ntotal_orders_domain_30days Total orders on the domain\\ntotal_orders_item_30days Total orders the Item had on the last 30 days\\ntotal_orders_sel_30days Total orders for the seller\\ntotal_si_domain_30days Total units sold of this domain\\ntotal_si_item_30days Total units sold of this item\\ntotal_si_sel_30days Same for the seller\\ntotal_visits_domain Total visits on this domain\\ntotal_visits_item Total visits this item had\\ntotal_visits_seller Total visits for this seller\\nuid session id\\nuser_id user id\\nwarranty Whether the item had warranty\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Columns\n",
    "The following columns are available on the training set:\n",
    "\n",
    "accepts_mercadopago Whether the item accepts Mercado Pago\n",
    "available_quantity The available stock quantity at that moment\n",
    "avg_asp_item_bday Average selling price of this item over the last days\n",
    "avg_asp_item_domain Average price of items of the domain this item belongs to\n",
    "avg_asp_item_sel Average price of seller sales\n",
    "avg_gmv_item_bday average revenue generated by the item per day\n",
    "avg_gmv_item_domain_30days Average revenue generated by the items of this domain on the last month\n",
    "avg_gmv_item_sel Average revenue of items of this seller\n",
    "avg_gmv_seller_bday Average revenue this seller makes by day\n",
    "avg_orders_item_bday Average number of orders this item has by day\n",
    "avg_orders_seller_bday Average orders the seller has by day\n",
    "avg_qty_orders_item_domain_30days Average number of orders a random item of this domain made on the last month\n",
    "avg_qty_orders_item_sel_30days Average number of orders an item of this seller makes on the last 30 days\n",
    "avg_si_item_bday Average units sold this item has by day\n",
    "avg_si_item_sel_30day Average units sold of an item of this seller on the past month\n",
    "avg_visits_item Average visits this item had\n",
    "benefit Ignore, should be dropped\n",
    "boosted Whether the item was boosted\n",
    "buy_server_timestamp Timestamp of the purchase\n",
    "category_id Category of this item\n",
    "conversion Target variable, it is True if this print has an attributed order\n",
    "cus_cust_id Buyer id\n",
    "cus_cust_id_sel Seller id\n",
    "date Print date\n",
    "deal_print_id Unique id for the print\n",
    "decimals Ignore, will be dropped\n",
    "domain_id Domain id for the item\n",
    "etl_version Ignore, should be dropped\n",
    "free_shipping Whether the item has free shipping\n",
    "fulfillment Whether the item is fulfilled by MeLi\n",
    "full_name Category full name\n",
    "health Item health\n",
    "is_pdp Whether the click landed on a PDP\n",
    "product_id Product_id of the item\n",
    "item_id ID of the item, useful for debugging\n",
    "listing_type_id Whether the item is gold or not\n",
    "logistic_type Logistic type for the item\n",
    "main_picture URL for the main item picture\n",
    "offset On which page the item was rendered\n",
    "original_price Price from which the discount was done\n",
    "platform Which platform the user is using\n",
    "price Item price\n",
    "print_position Position on the page\n",
    "print_server_timestamp Timestamp for the print\n",
    "qty_items_dom Number of items this domain has\n",
    "qty_items_sel Number of items the seller has\n",
    "rn Leftover from the ETL, Discard\n",
    "ROW_ID Row of the submission file\n",
    "site_id Site ID\n",
    "sold_quantity Number of items sold at the moment of the print\n",
    "tags Tags the item had at the moment of the print\n",
    "title Item title\n",
    "total_asp_item_domain_30days Average selling price of the items of the domain\n",
    "total_asp_item_sel_30days Average selling price of all the items the seller sold on the last 30 days\n",
    "total_gmv_domain_30days Total revenue the domain made on the last 30 days\n",
    "total_gmv_domain_bday total_gmv_domain_30days / 30\n",
    "total_gmv_item_30days Total revenue made by the item on the lasts 30 days\n",
    "total_gmv_seller Total revenue made by the seller on the last month\n",
    "total_items_domain Number of items on the domain\n",
    "total_items_seller Number of items the seller has\n",
    "total_orders_domain_30days Total orders on the domain\n",
    "total_orders_item_30days Total orders the Item had on the last 30 days\n",
    "total_orders_sel_30days Total orders for the seller\n",
    "total_si_domain_30days Total units sold of this domain\n",
    "total_si_item_30days Total units sold of this item\n",
    "total_si_sel_30days Same for the seller\n",
    "total_visits_domain Total visits on this domain\n",
    "total_visits_item Total visits this item had\n",
    "total_visits_seller Total visits for this seller\n",
    "uid session id\n",
    "user_id user id\n",
    "warranty Whether the item had warranty\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier, HistGradientBoostingClassifier, StackingClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,  roc_curve, auc, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(models, model_names, X_test, y_test, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, models[i].predict_proba(X_test)[:, models[i].classes_ == 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label=model_names[i] + ' (area = %0.5f)' % roc_auc)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "\n",
    "    plt.ylim([0.0, 1.05])\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "\n",
    "    # Show grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notify(title, text):\n",
    "    os.system(\"\"\"\n",
    "              osascript -e 'display notification \"{}\" with title \"{}\"'\n",
    "              \"\"\".format(text, title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Comp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = pd.read_csv(\"data/competition_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accepts_mercadopago</th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>avg_gmv_item_domain_30days</th>\n",
       "      <th>avg_gmv_item_sel</th>\n",
       "      <th>avg_gmv_seller_bday</th>\n",
       "      <th>avg_qty_orders_item_domain_30days</th>\n",
       "      <th>avg_qty_orders_item_sel_30days</th>\n",
       "      <th>avg_si_item_sel_30day</th>\n",
       "      <th>benefit</th>\n",
       "      <th>boosted</th>\n",
       "      <th>...</th>\n",
       "      <th>total_si_domain_30days</th>\n",
       "      <th>total_si_item_30days</th>\n",
       "      <th>total_si_sel_30days</th>\n",
       "      <th>total_visits_domain</th>\n",
       "      <th>total_visits_item</th>\n",
       "      <th>total_visits_seller</th>\n",
       "      <th>uid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>warranty</th>\n",
       "      <th>ROW_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>59</td>\n",
       "      <td>938.031376</td>\n",
       "      <td>2153.933091</td>\n",
       "      <td>135195.200333</td>\n",
       "      <td>3.430563</td>\n",
       "      <td>12.407860</td>\n",
       "      <td>13.691450</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>56717.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25781.0</td>\n",
       "      <td>7993972</td>\n",
       "      <td>543</td>\n",
       "      <td>854813</td>\n",
       "      <td>cb5bfac7-229a-4e3e-96dd-80b2ad3972c1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garantía de fábrica: 12 meses</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "      <td>159.826531</td>\n",
       "      <td>240.325973</td>\n",
       "      <td>19338.230000</td>\n",
       "      <td>3.142739</td>\n",
       "      <td>4.429577</td>\n",
       "      <td>4.511599</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>81455.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10891.0</td>\n",
       "      <td>7821316</td>\n",
       "      <td>1789</td>\n",
       "      <td>1422288</td>\n",
       "      <td>b0f9aa19-00d5-4afd-aa77-45be7c849562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>67.635391</td>\n",
       "      <td>86.066296</td>\n",
       "      <td>154.919333</td>\n",
       "      <td>2.633771</td>\n",
       "      <td>2.592593</td>\n",
       "      <td>2.722222</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>16792.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1303909</td>\n",
       "      <td>1473</td>\n",
       "      <td>17801</td>\n",
       "      <td>fd59890a-f2c2-4282-b2ee-c68f25e20697</td>\n",
       "      <td>151157147.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>92.085756</td>\n",
       "      <td>332.848400</td>\n",
       "      <td>554.747333</td>\n",
       "      <td>3.280069</td>\n",
       "      <td>12.620000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>139419</td>\n",
       "      <td>7473</td>\n",
       "      <td>44336</td>\n",
       "      <td>72340acf-2a1c-4214-a604-132e0cb56939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garantía de fábrica: 90 días</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>156.905222</td>\n",
       "      <td>955.997475</td>\n",
       "      <td>3154.791667</td>\n",
       "      <td>2.737876</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8707.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>209373</td>\n",
       "      <td>416</td>\n",
       "      <td>46206</td>\n",
       "      <td>84da1314-814c-4d4f-be23-3de9ea1da4b6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garantía del vendedor: 90 días</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accepts_mercadopago  available_quantity  avg_gmv_item_domain_30days  \\\n",
       "0                 True                  59                  938.031376   \n",
       "1                 True                  37                  159.826531   \n",
       "2                 True                   9                   67.635391   \n",
       "3                 True                  12                   92.085756   \n",
       "4                 True                   5                  156.905222   \n",
       "\n",
       "   avg_gmv_item_sel  avg_gmv_seller_bday  avg_qty_orders_item_domain_30days  \\\n",
       "0       2153.933091        135195.200333                           3.430563   \n",
       "1        240.325973         19338.230000                           3.142739   \n",
       "2         86.066296           154.919333                           2.633771   \n",
       "3        332.848400           554.747333                           3.280069   \n",
       "4        955.997475          3154.791667                           2.737876   \n",
       "\n",
       "   avg_qty_orders_item_sel_30days  avg_si_item_sel_30day  benefit  boosted  \\\n",
       "0                       12.407860              13.691450    0.001    False   \n",
       "1                        4.429577               4.511599    0.001    False   \n",
       "2                        2.592593               2.722222    0.001    False   \n",
       "3                       12.620000              12.840000    0.001    False   \n",
       "4                        3.666667               4.363636    0.001    False   \n",
       "\n",
       "   ... total_si_domain_30days  total_si_item_30days total_si_sel_30days  \\\n",
       "0  ...                56717.0                  17.0             25781.0   \n",
       "1  ...                81455.0                   5.0             10891.0   \n",
       "2  ...                16792.0                   8.0               147.0   \n",
       "3  ...                 1988.0                  14.0               642.0   \n",
       "4  ...                 8707.0                  32.0               432.0   \n",
       "\n",
       "  total_visits_domain total_visits_item total_visits_seller  \\\n",
       "0             7993972               543              854813   \n",
       "1             7821316              1789             1422288   \n",
       "2             1303909              1473               17801   \n",
       "3              139419              7473               44336   \n",
       "4              209373               416               46206   \n",
       "\n",
       "                                    uid      user_id  \\\n",
       "0  cb5bfac7-229a-4e3e-96dd-80b2ad3972c1          NaN   \n",
       "1  b0f9aa19-00d5-4afd-aa77-45be7c849562          NaN   \n",
       "2  fd59890a-f2c2-4282-b2ee-c68f25e20697  151157147.0   \n",
       "3  72340acf-2a1c-4214-a604-132e0cb56939          NaN   \n",
       "4  84da1314-814c-4d4f-be23-3de9ea1da4b6          NaN   \n",
       "\n",
       "                         warranty  ROW_ID  \n",
       "0   Garantía de fábrica: 12 meses     NaN  \n",
       "1                             NaN     NaN  \n",
       "2                             NaN     NaN  \n",
       "3    Garantía de fábrica: 90 días     NaN  \n",
       "4  Garantía del vendedor: 90 días     NaN  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>avg_gmv_item_domain_30days</th>\n",
       "      <th>avg_gmv_item_sel</th>\n",
       "      <th>avg_gmv_seller_bday</th>\n",
       "      <th>avg_qty_orders_item_domain_30days</th>\n",
       "      <th>avg_qty_orders_item_sel_30days</th>\n",
       "      <th>avg_si_item_sel_30day</th>\n",
       "      <th>benefit</th>\n",
       "      <th>conversion</th>\n",
       "      <th>health</th>\n",
       "      <th>...</th>\n",
       "      <th>total_orders_item_30days</th>\n",
       "      <th>total_orders_sel_30days</th>\n",
       "      <th>total_si_domain_30days</th>\n",
       "      <th>total_si_item_30days</th>\n",
       "      <th>total_si_sel_30days</th>\n",
       "      <th>total_visits_domain</th>\n",
       "      <th>total_visits_item</th>\n",
       "      <th>total_visits_seller</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ROW_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199972.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>199971.000000</td>\n",
       "      <td>180761.000000</td>\n",
       "      <td>199972.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>195607.000000</td>\n",
       "      <td>1.999720e+05</td>\n",
       "      <td>199972.000000</td>\n",
       "      <td>1.999720e+05</td>\n",
       "      <td>1.783750e+05</td>\n",
       "      <td>19211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2142.683766</td>\n",
       "      <td>333.141264</td>\n",
       "      <td>1160.099822</td>\n",
       "      <td>10815.338962</td>\n",
       "      <td>4.385187</td>\n",
       "      <td>13.542561</td>\n",
       "      <td>18.286236</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.092631</td>\n",
       "      <td>0.809401</td>\n",
       "      <td>...</td>\n",
       "      <td>65.176297</td>\n",
       "      <td>3941.158614</td>\n",
       "      <td>29197.693135</td>\n",
       "      <td>88.487667</td>\n",
       "      <td>5238.731257</td>\n",
       "      <td>2.170257e+06</td>\n",
       "      <td>5571.603790</td>\n",
       "      <td>2.542803e+05</td>\n",
       "      <td>2.246094e+08</td>\n",
       "      <td>9605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11326.386712</td>\n",
       "      <td>492.836951</td>\n",
       "      <td>4284.246365</td>\n",
       "      <td>26377.753704</td>\n",
       "      <td>2.768258</td>\n",
       "      <td>25.645743</td>\n",
       "      <td>33.648431</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.289915</td>\n",
       "      <td>0.146368</td>\n",
       "      <td>...</td>\n",
       "      <td>129.610777</td>\n",
       "      <td>5145.727129</td>\n",
       "      <td>49694.994203</td>\n",
       "      <td>220.606860</td>\n",
       "      <td>6809.183739</td>\n",
       "      <td>3.545316e+06</td>\n",
       "      <td>12108.897095</td>\n",
       "      <td>3.458552e+05</td>\n",
       "      <td>1.474232e+08</td>\n",
       "      <td>5545.882346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.909057</td>\n",
       "      <td>4.773333</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.160000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.610000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>86.729688</td>\n",
       "      <td>143.184865</td>\n",
       "      <td>793.281667</td>\n",
       "      <td>2.876796</td>\n",
       "      <td>4.188679</td>\n",
       "      <td>4.916896</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>3938.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>943.000000</td>\n",
       "      <td>1.899680e+05</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>4.804600e+04</td>\n",
       "      <td>1.053200e+08</td>\n",
       "      <td>4802.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>169.234106</td>\n",
       "      <td>262.266733</td>\n",
       "      <td>2733.067000</td>\n",
       "      <td>3.639912</td>\n",
       "      <td>6.768293</td>\n",
       "      <td>8.875000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2102.000000</td>\n",
       "      <td>11660.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2713.000000</td>\n",
       "      <td>5.613990e+05</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>1.263900e+05</td>\n",
       "      <td>1.976426e+08</td>\n",
       "      <td>9605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>319.281502</td>\n",
       "      <td>675.989333</td>\n",
       "      <td>9217.855667</td>\n",
       "      <td>5.066384</td>\n",
       "      <td>13.403873</td>\n",
       "      <td>18.558559</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5017.000000</td>\n",
       "      <td>38725.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6455.000000</td>\n",
       "      <td>2.007145e+06</td>\n",
       "      <td>5248.000000</td>\n",
       "      <td>2.817150e+05</td>\n",
       "      <td>3.202613e+08</td>\n",
       "      <td>14407.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3778.257881</td>\n",
       "      <td>57282.961233</td>\n",
       "      <td>244988.442667</td>\n",
       "      <td>38.148629</td>\n",
       "      <td>258.363636</td>\n",
       "      <td>465.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1853.000000</td>\n",
       "      <td>36492.000000</td>\n",
       "      <td>505258.000000</td>\n",
       "      <td>8269.000000</td>\n",
       "      <td>56189.000000</td>\n",
       "      <td>1.591114e+07</td>\n",
       "      <td>195413.000000</td>\n",
       "      <td>2.938795e+06</td>\n",
       "      <td>1.000014e+09</td>\n",
       "      <td>19210.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       available_quantity  avg_gmv_item_domain_30days  avg_gmv_item_sel  \\\n",
       "count       199972.000000               195607.000000     195607.000000   \n",
       "mean          2142.683766                  333.141264       1160.099822   \n",
       "std          11326.386712                  492.836951       4284.246365   \n",
       "min              0.000000                    4.909057          4.773333   \n",
       "25%             19.000000                   86.729688        143.184865   \n",
       "50%             67.000000                  169.234106        262.266733   \n",
       "75%            371.000000                  319.281502        675.989333   \n",
       "max          99999.000000                 3778.257881      57282.961233   \n",
       "\n",
       "       avg_gmv_seller_bday  avg_qty_orders_item_domain_30days  \\\n",
       "count        195607.000000                      195607.000000   \n",
       "mean          10815.338962                           4.385187   \n",
       "std           26377.753704                           2.768258   \n",
       "min               0.660000                           1.000000   \n",
       "25%             793.281667                           2.876796   \n",
       "50%            2733.067000                           3.639912   \n",
       "75%            9217.855667                           5.066384   \n",
       "max          244988.442667                          38.148629   \n",
       "\n",
       "       avg_qty_orders_item_sel_30days  avg_si_item_sel_30day        benefit  \\\n",
       "count                   195607.000000          195607.000000  199971.000000   \n",
       "mean                        13.542561              18.286236       0.000976   \n",
       "std                         25.645743              33.648431       0.000154   \n",
       "min                          1.000000               1.000000       0.000000   \n",
       "25%                          4.188679               4.916896       0.001000   \n",
       "50%                          6.768293               8.875000       0.001000   \n",
       "75%                         13.403873              18.558559       0.001000   \n",
       "max                        258.363636             465.500000       0.001000   \n",
       "\n",
       "          conversion         health  ...  total_orders_item_30days  \\\n",
       "count  180761.000000  199972.000000  ...             195607.000000   \n",
       "mean        0.092631       0.809401  ...                 65.176297   \n",
       "std         0.289915       0.146368  ...                129.610777   \n",
       "min         0.000000       0.000000  ...                  1.000000   \n",
       "25%         0.000000       0.770000  ...                  6.000000   \n",
       "50%         0.000000       0.810000  ...                 20.000000   \n",
       "75%         0.000000       0.900000  ...                 63.000000   \n",
       "max         1.000000       1.000000  ...               1853.000000   \n",
       "\n",
       "       total_orders_sel_30days  total_si_domain_30days  total_si_item_30days  \\\n",
       "count            195607.000000           195607.000000         195607.000000   \n",
       "mean               3941.158614            29197.693135             88.487667   \n",
       "std                5145.727129            49694.994203            220.606860   \n",
       "min                   2.000000                4.000000              1.000000   \n",
       "25%                 718.000000             3938.000000              7.000000   \n",
       "50%                2102.000000            11660.000000             24.000000   \n",
       "75%                5017.000000            38725.000000             80.000000   \n",
       "max               36492.000000           505258.000000           8269.000000   \n",
       "\n",
       "       total_si_sel_30days  total_visits_domain  total_visits_item  \\\n",
       "count        195607.000000         1.999720e+05      199972.000000   \n",
       "mean           5238.731257         2.170257e+06        5571.603790   \n",
       "std            6809.183739         3.545316e+06       12108.897095   \n",
       "min               2.000000         3.160000e+02           1.000000   \n",
       "25%             943.000000         1.899680e+05         407.000000   \n",
       "50%            2713.000000         5.613990e+05        1496.000000   \n",
       "75%            6455.000000         2.007145e+06        5248.000000   \n",
       "max           56189.000000         1.591114e+07      195413.000000   \n",
       "\n",
       "       total_visits_seller       user_id        ROW_ID  \n",
       "count         1.999720e+05  1.783750e+05  19211.000000  \n",
       "mean          2.542803e+05  2.246094e+08   9605.000000  \n",
       "std           3.458552e+05  1.474232e+08   5545.882346  \n",
       "min           1.100000e+01  1.610000e+02      0.000000  \n",
       "25%           4.804600e+04  1.053200e+08   4802.500000  \n",
       "50%           1.263900e+05  1.976426e+08   9605.000000  \n",
       "75%           2.817150e+05  3.202613e+08  14407.500000  \n",
       "max           2.938795e+06  1.000014e+09  19210.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **accepts_mercadopago**\n",
       "- **available_quantity**\n",
       "- **avg_gmv_item_domain_30days**\n",
       "- **avg_gmv_item_sel**\n",
       "- **avg_gmv_seller_bday**\n",
       "- **avg_qty_orders_item_domain_30days**\n",
       "- **avg_qty_orders_item_sel_30days**\n",
       "- **avg_si_item_sel_30day**\n",
       "- **benefit**\n",
       "- **boosted**\n",
       "- **category_id**\n",
       "- **conversion**\n",
       "- **date**\n",
       "- **deal_print_id**\n",
       "- **domain_id**\n",
       "- **etl_version**\n",
       "- **free_shipping**\n",
       "- **fulfillment**\n",
       "- **full_name**\n",
       "- **health**\n",
       "- **is_pdp**\n",
       "- **product_id**\n",
       "- **item_id**\n",
       "- **listing_type_id**\n",
       "- **logistic_type**\n",
       "- **main_picture**\n",
       "- **offset**\n",
       "- **original_price**\n",
       "- **platform**\n",
       "- **price**\n",
       "- **print_position**\n",
       "- **print_server_timestamp**\n",
       "- **qty_items_dom**\n",
       "- **qty_items_sel**\n",
       "- **site_id**\n",
       "- **sold_quantity**\n",
       "- **tags**\n",
       "- **title**\n",
       "- **total_asp_item_domain_30days**\n",
       "- **total_asp_item_sel_30days**\n",
       "- **total_gmv_domain_bday**\n",
       "- **total_gmv_item_30days**\n",
       "- **total_items_domain**\n",
       "- **total_items_seller**\n",
       "- **total_orders_domain_30days**\n",
       "- **total_orders_item_30days**\n",
       "- **total_orders_sel_30days**\n",
       "- **total_si_domain_30days**\n",
       "- **total_si_item_30days**\n",
       "- **total_si_sel_30days**\n",
       "- **total_visits_domain**\n",
       "- **total_visits_item**\n",
       "- **total_visits_seller**\n",
       "- **uid**\n",
       "- **user_id**\n",
       "- **warranty**\n",
       "- **ROW_ID**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                #\"- **{}** ({}) \\n\\n {}\".format(col, dtype, comp_data[col].value_counts()) for col, dtype in\n",
    "                #\"- **{}** ({})\".format(col, dtype) for col, dtype in\n",
    "                #zip(comp_data.columns, comp_data.dtypes)\n",
    "                \"- **{}**\".format(col) for col in comp_data.columns\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = pd.read_csv(\"data/competition_data.csv\")\n",
    "comp_data = comp_data.drop(\n",
    "        columns=[\n",
    "            \"accepts_mercadopago\", # Todos tienen mercadopago\n",
    "            \"boosted\", # Ninguno\n",
    "            \"avg_qty_orders_item_domain_30days\",\n",
    "            \"avg_qty_orders_item_sel_30days\",\n",
    "            \"avg_si_item_sel_30day\",\n",
    "            #\"date\",\n",
    "            \"deal_print_id\",\n",
    "            \"etl_version\",\n",
    "            \"full_name\",\n",
    "            \"main_picture\",\n",
    "            \"print_server_timestamp\",\n",
    "            #\"title\",\n",
    "            \"uid\",\n",
    "            #\"user_id\",\n",
    "            \"avg_gmv_item_domain_30days\",\n",
    "            #\"avg_gmv_item_sel\",\n",
    "            \"avg_gmv_seller_bday\",\n",
    "            #\"qty_items_dom\",\n",
    "            #\"category_id\",\n",
    "            #\"domain_id\",\n",
    "            #\"product_id\",\n",
    "            #\"listing_type_id\",\n",
    "            # \"logistic_type\",\n",
    "            \"site_id\",\n",
    "            #\"tags\",\n",
    "            \"total_asp_item_sel_30days\", \n",
    "            \"total_gmv_domain_bday\", \n",
    "            #\"total_items_domain\", \n",
    "            \"total_items_seller\", \n",
    "            \"total_orders_domain_30days\", \n",
    "            \"total_orders_item_30days\", \n",
    "            \"total_orders_sel_30days\", \n",
    "            \"total_si_sel_30days\", \n",
    "            #\"total_visits_domain\", \n",
    "            #\"total_visits_item\", \n",
    "            #\"total_visits_seller\",\n",
    "            \"total_asp_item_domain_30days\",\n",
    "            \"total_gmv_item_30days\",\n",
    "            \"total_si_domain_30days\",\n",
    "            \"total_si_item_30days\",\n",
    "            \"warranty\",\n",
    "            # \"offset\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **available_quantity**\n",
       "- **avg_gmv_item_sel**\n",
       "- **benefit**\n",
       "- **category_id**\n",
       "- **conversion**\n",
       "- **date**\n",
       "- **domain_id**\n",
       "- **free_shipping**\n",
       "- **fulfillment**\n",
       "- **health**\n",
       "- **is_pdp**\n",
       "- **product_id**\n",
       "- **item_id**\n",
       "- **listing_type_id**\n",
       "- **logistic_type**\n",
       "- **offset**\n",
       "- **original_price**\n",
       "- **platform**\n",
       "- **price**\n",
       "- **print_position**\n",
       "- **qty_items_dom**\n",
       "- **qty_items_sel**\n",
       "- **sold_quantity**\n",
       "- **tags**\n",
       "- **title**\n",
       "- **total_items_domain**\n",
       "- **total_visits_domain**\n",
       "- **total_visits_item**\n",
       "- **total_visits_seller**\n",
       "- **user_id**\n",
       "- **ROW_ID**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                #\"- **{}** ({}) \\n\\n {}\".format(col, dtype, comp_data[col].value_counts()) for col, dtype in\n",
    "                #\"- **{}** ({})\".format(col, dtype) for col, dtype in\n",
    "                #zip(comp_data.columns, comp_data.dtypes)\n",
    "                \"- **{}**\".format(col) for col in comp_data.columns\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_tags:\n",
    "    if len(tags) == 0:\n",
    "        #tags = comp_data[\"tags\"].str.replace(\"[\", \"\").str.replace(\"]\", \"\").str.split(\", \").apply(pd.Series).stack().value_counts()\n",
    "        # more efficient\n",
    "        tags = comp_data[\"tags\"].str.replace(\"[\", \"\").str.replace(\"]\", \"\").str.split(\", \").explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For tag in tags, create a new column with the tag name and a boolean value\n",
    "\n",
    "if add_tags:\n",
    "    for tag in tags.index:\n",
    "        comp_data[tag] = comp_data[\"tags\"].str.contains(tag).astype(int)\n",
    "\n",
    "    comp_data[\"tags_count\"] = comp_data[\"tags\"].str.replace(\"[\", \"\").str.replace(\"]\", \"\").str.split(\", \").apply(len)\n",
    "\n",
    "    comp_data = comp_data.drop(\"tags\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data[\"domain_id\"] = LabelEncoder().fit_transform(comp_data[\"domain_id\"]).astype(int)\n",
    "# comp_data[\"product_id\"] = LabelEncoder().fit_transform(comp_data[\"product_id\"]).astype(int)\n",
    "\n",
    "# OneHotEncoder\n",
    "# comp_data = pd.get_dummies(comp_data, columns=[\"category_id\"], dtype=int, sparse=True, dummy_na = False)\n",
    "# Add category_id ohe category column if that category has more than 1000 ocurrences\n",
    "# ocurrences = comp_data[\"category_id\"].value_counts()\n",
    "# for category_id in ocurrences[ocurrences > 1000].index:\n",
    "#     comp_data[\"category_id_\" + str(category_id)] = comp_data[\"category_id\"] == category_id\n",
    "#     comp_data[\"category_id_\" + str(category_id)] = comp_data[\"category_id_\" + str(category_id)].astype(int)\n",
    "# comp_data = comp_data.drop(columns=[\"category_id\"])\n",
    "\n",
    "# comp_data = pd.get_dummies(comp_data, columns=[\"logistic_type\"], dtype=int, sparse=True, dummy_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data[\"date\"] = pd.to_datetime(comp_data[\"date\"])\n",
    "comp_data[\"day\"] = comp_data[\"date\"].dt.day\n",
    "comp_data[\"month\"] = comp_data[\"date\"].dt.month\n",
    "#comp_data[\"hour\"] = comp_data[\"date\"].dt.hour\n",
    "# comp_data[\"year\"] = comp_data[\"date\"].dt.year\n",
    "comp_data[\"dayofweek\"] = comp_data[\"date\"].dt.dayofweek\n",
    "# comp_data[\"weekofyear\"] = comp_data[\"date\"].dt.isocalendar().week\n",
    "#comp_data[\"quarter\"] = comp_data[\"date\"].dt.quarter\n",
    "# comp_data[\"hour\"] = comp_data[\"date\"].dt.hour\n",
    "# comp_data[\"minute\"] = comp_data[\"date\"].dt.minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-03-01 00:00:00'), Timestamp('2020-04-25 00:00:00'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data[\"date\"].min(), comp_data[\"date\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = comp_data.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse boolean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data[\"boosted\"] = comp_data[\"boosted\"].astype(int)\n",
    "comp_data[\"free_shipping\"] = comp_data[\"free_shipping\"].astype(int)\n",
    "comp_data[\"fulfillment\"] = comp_data[\"fulfillment\"].astype(int)\n",
    "\n",
    "comp_data[\"imp_is_pdp\"] = comp_data[\"is_pdp\"].isna().astype(int)\n",
    "comp_data[\"is_pdp\"].fillna(0, inplace=True)\n",
    "comp_data[\"is_pdp\"] = comp_data[\"is_pdp\"].astype(int)\n",
    "\n",
    "comp_data[\"imp_user_id\"] = comp_data[\"user_id\"].isna().astype(int)\n",
    "comp_data[\"user_id\"] = comp_data[\"user_id\"].fillna(0).astype(int)\n",
    "\n",
    "comp_data[\"listing_type_id\"] = comp_data[\"listing_type_id\"].apply(lambda x: 0 if x == \"gold_special\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lab_enc:\n",
    "    # LabelEncoder\n",
    "    comp_data[\"platform\"] = LabelEncoder().fit_transform(comp_data[\"platform\"]).astype(int)\n",
    "    #comp_data[\"category_id\"] = LabelEncoder().fit_transform(comp_data[\"category_id\"]).astype(int)\n",
    "    comp_data[\"product_id\"] = LabelEncoder().fit_transform(comp_data[\"product_id\"]).astype(int)\n",
    "    comp_data[\"domain_id\"] = LabelEncoder().fit_transform(comp_data[\"domain_id\"]).astype(int)\n",
    "    comp_data[\"logistic_type\"] = LabelEncoder().fit_transform(comp_data[\"logistic_type\"]).astype(int)\n",
    "\n",
    "if ohe:\n",
    "    # OHE\n",
    "    comp_data = pd.get_dummies(comp_data,\n",
    "                            columns = [\n",
    "                                # \"platform\",\n",
    "                                \"category_id\",\n",
    "                                # \"domain_id\"\n",
    "                                ],\n",
    "                            sparse = True,    # Devolver una matriz rala.\n",
    "                            dummy_na = False, # No agregar columna para NaNs.\n",
    "                            dtype = int       # XGBoost no trabaja con 'object'; necesitamos que sean numéricos.\n",
    "                        )\n",
    "\n",
    "\n",
    "# Encode category_id as a number, but number is based on ocurrences of category_id\n",
    "# ! Has data leakage\n",
    "#ocurrences = comp_data[\"category_id\"].value_counts()\n",
    "#for category_id in ocurrences.index:\n",
    "#    comp_data[\"category_id\"] = comp_data[\"category_id\"].replace(category_id, ocurrences[category_id])\n",
    "\n",
    "# comp_data[\"category_id\"] = comp_data[\"category_id\"].apply(lambda x: ocurrences[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_features:\n",
    "    comp_data[\"price_diff\"] = comp_data[\"price\"] - comp_data[\"original_price\"]\n",
    "    comp_data[\"price_diff\"] = comp_data[\"price_diff\"].apply(lambda x: abs(x)).astype(int)\n",
    "\n",
    "    comp_data[\"discount\"] = (comp_data[\"original_price\"] - comp_data[\"price\"]) / comp_data[\"original_price\"]\n",
    "    comp_data[\"discount\"] = comp_data[\"discount\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"price_ratio\"] = comp_data[\"price\"] / comp_data[\"original_price\"]\n",
    "    comp_data[\"price_ratio\"] = comp_data[\"price_ratio\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"is_discount\"] = comp_data[\"discount\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    comp_data[\"title_length\"] = comp_data[\"title\"].str.len()\n",
    "    comp_data[\"title_word_count\"] = comp_data[\"title\"].str.split(\" \").apply(len)\n",
    "\n",
    "    comp_data[\"title_length_word_count\"] = comp_data[\"title_length\"] / comp_data[\"title_word_count\"]\n",
    "    comp_data[\"title_length_word_count\"] = comp_data[\"title_length_word_count\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"domain_dominance\"] = comp_data[\"sold_quantity\"] / comp_data[\"qty_items_dom\"]\n",
    "\n",
    "    comp_data[\"is_pdp_tvi\"] = comp_data[\"is_pdp\"] / comp_data[\"total_visits_item\"]\n",
    "    comp_data[\"is_pdp_tvi\"] = comp_data[\"is_pdp_tvi\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"is_pdp_tvs\"] = comp_data[\"is_pdp\"] / comp_data[\"total_visits_seller\"]\n",
    "    comp_data[\"is_pdp_tvs\"] = comp_data[\"is_pdp_tvs\"].apply(lambda x: 1 if x == np.inf else x)\n",
    "\n",
    "    comp_data[\"is_pdp_tvd\"] = comp_data[\"is_pdp\"] / comp_data[\"total_visits_domain\"]\n",
    "    comp_data[\"is_pdp_tvd\"] = comp_data[\"is_pdp_tvd\"].apply(lambda x: 1 if x == np.inf else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data = comp_data.dropna(subset=[\"avg_gmv_item_sel\"])\n",
    "\n",
    "# Fil nas for [\"avg_gmv_item_sel\", \"qty_items_dom\", \"qty_items_sel\", \"domain_dominance\"]\n",
    "\n",
    "comp_data[\"nan_imputed\"] = comp_data[\"avg_gmv_item_sel\"].isna().astype(int)\n",
    "\n",
    "comp_data[\"avg_gmv_item_sel\"] = comp_data[\"avg_gmv_item_sel\"].fillna(comp_data[\"avg_gmv_item_sel\"].median())\n",
    "comp_data[\"qty_items_dom\"] = comp_data[\"qty_items_dom\"].fillna(comp_data[\"qty_items_dom\"].median())\n",
    "comp_data[\"qty_items_sel\"] = comp_data[\"qty_items_sel\"].fillna(comp_data[\"qty_items_sel\"].median())\n",
    "comp_data[\"domain_dominance\"] = comp_data[\"domain_dominance\"].fillna(comp_data[\"domain_dominance\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **available_quantity**\n",
       "- **avg_gmv_item_sel**\n",
       "- **benefit**\n",
       "- **category_id**\n",
       "- **conversion**\n",
       "- **domain_id**\n",
       "- **free_shipping**\n",
       "- **fulfillment**\n",
       "- **health**\n",
       "- **is_pdp**\n",
       "- **product_id**\n",
       "- **item_id**\n",
       "- **listing_type_id**\n",
       "- **logistic_type**\n",
       "- **offset**\n",
       "- **original_price**\n",
       "- **platform**\n",
       "- **price**\n",
       "- **print_position**\n",
       "- **qty_items_dom**\n",
       "- **qty_items_sel**\n",
       "- **sold_quantity**\n",
       "- **tags**\n",
       "- **title**\n",
       "- **total_items_domain**\n",
       "- **total_visits_domain**\n",
       "- **total_visits_item**\n",
       "- **total_visits_seller**\n",
       "- **user_id**\n",
       "- **ROW_ID**\n",
       "- **day**\n",
       "- **month**\n",
       "- **dayofweek**\n",
       "- **imp_is_pdp**\n",
       "- **imp_user_id**\n",
       "- **price_diff**\n",
       "- **discount**\n",
       "- **price_ratio**\n",
       "- **is_discount**\n",
       "- **title_length**\n",
       "- **title_word_count**\n",
       "- **title_length_word_count**\n",
       "- **domain_dominance**\n",
       "- **is_pdp_tvi**\n",
       "- **is_pdp_tvs**\n",
       "- **is_pdp_tvd**\n",
       "- **nan_imputed**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                #\"- **{}** ({}) \\n\\n {}\".format(col, dtype, comp_data[col].value_counts()) for col, dtype in\n",
    "                #\"- **{}** ({})\".format(col, dtype) for col, dtype in\n",
    "                #zip(comp_data.columns, comp_data.dtypes)\n",
    "                \"- **{}**\".format(col) for col in comp_data.columns\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this columns for variance\n",
    "# accepts_mercadopago\n",
    "# available_quantity\n",
    "# avg_gmv_item_domain_30days\n",
    "# avg_gmv_item_sel\n",
    "# avg_gmv_seller_bday\n",
    "# avg_qty_orders_item_domain_30days\n",
    "# avg_qty_orders_item_sel_30days\n",
    "# avg_si_item_sel_30day\n",
    "# benefit\n",
    "# boosted\n",
    "# category_id\n",
    "# conversion\n",
    "# date\n",
    "# deal_print_id\n",
    "# domain_id\n",
    "# etl_version\n",
    "# free_shipping\n",
    "# fulfillment\n",
    "# full_name\n",
    "# health\n",
    "# is_pdp\n",
    "# product_id\n",
    "# item_id\n",
    "# listing_type_id\n",
    "# logistic_type\n",
    "# main_picture\n",
    "# offset\n",
    "# original_price\n",
    "# platform\n",
    "# price\n",
    "# print_position\n",
    "# print_server_timestamp\n",
    "# qty_items_dom\n",
    "# qty_items_sel\n",
    "# old_quantity\n",
    "# tags\n",
    "# title\n",
    "# total_asp_item_domain_30days\n",
    "# total_asp_item_sel_30days\n",
    "# total_gmv_domain_bday\n",
    "# total_gmv_item_30days\n",
    "# total_items_domain\n",
    "# total_items_seller\n",
    "# total_orders_domain_30days\n",
    "# total_orders_item_30days\n",
    "# total_orders_sel_30days\n",
    "# total_si_domain_30days\n",
    "# total_si_item_30days\n",
    "# total_si_sel_30days\n",
    "# total_visits_domain\n",
    "# total_visits_item\n",
    "# total_visits_seller\n",
    "# uid\n",
    "# user_id\n",
    "# warranty\n",
    "\n",
    "# for col in comp_data.columns:\n",
    "#     print()\n",
    "#     print(col)\n",
    "#     print(comp_data[col].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data.groupby(\"user_id\")[\"conversion\"].sum()\n",
    "# comp_data[comp_data[\"conversion\"] == True][\"user_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance conversion\n",
    "# comp_data = comp_data.drop(comp_data[comp_data[\"conversion\"] == False].sample(frac=.5).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_data[\"conversion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 'offset' vs 'category_id' . Dot color depends on 'conversion'\n",
    "\n",
    "#plt.scatter(full_data[\"offset\"], full_data[\"discount\"], c=full_data[\"conversion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# ax.scatter(\n",
    "#     new_train_data[\"offset\"],\n",
    "#     new_train_data[\"discount\"],\n",
    "#     new_train_data[\"is_pdp\"],\n",
    "#     c=new_train_data[\"conversion\"],\n",
    "#     # cmap=\"coolwarm\",\n",
    "#     alpha=.5\n",
    "# )\n",
    "\n",
    "# ax.set_xlabel(\"offset\")\n",
    "# ax.set_ylabel(\"discount\")\n",
    "# ax.set_zlabel(\"is_pdp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot 'offset', 'discount', 'category_id' in 3D. Dot color depends on 'conversion'\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# ax.scatter(\n",
    "#     new_test_data[\"offset\"],\n",
    "#     new_test_data[\"discount\"],\n",
    "#     new_test_data[\"price_diff\"],\n",
    "#     c=new_test_data[\"conversion\"],\n",
    "#     # cmap=\"coolwarm\",\n",
    "#     alpha=.5\n",
    "# )\n",
    "\n",
    "# ax.set_xlabel(\"offset\")\n",
    "# ax.set_ylabel(\"discount\")\n",
    "# ax.set_zlabel(\"price_diff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# # ax = fig.add_subplot(111)\n",
    "# ax.scatter(\n",
    "#     new_test_data[\"offset\"],\n",
    "#     new_test_data[\"price_diff\"],\n",
    "#     new_test_data[\"offset\"] ** 2 + new_test_data[\"price_diff\"]**2,\n",
    "#     c=new_test_data[\"conversion\"],\n",
    "# )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot hist boosted\n",
    "# plot_data = comp_data.groupby(\"is_pdp\")[\"conversion\"].sum()\n",
    "# plot_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hour vs conversion\n",
    "#comp_data.groupby(\"dayofweek\")[\"conversion\"].mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Comp Data -> Full | Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',ngram_range=(1,1), sublinear_tf=True)\n",
    "\n",
    "if tfidf_title:\n",
    "    tfidf_title = pd.DataFrame(tfidf.fit_transform(comp_data[\"title\"]).toarray(), columns=tfidf.get_feature_names_out())\n",
    "    comp_data = pd.concat([comp_data, tfidf_title], axis=1)\n",
    "    comp_data = comp_data.drop(\"title\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "# del comp_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/competition_data.csv\")\n",
    "# print(df.isna().sum()[df.isna().sum() > 0])\n",
    "# del df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benefit            1\n",
       "product_id    137862\n",
       "ROW_ID        180761\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nan values per column\n",
    "\n",
    "full_data.isna().sum()[full_data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following cols have nan values\n",
    "# avg_gmv_item_sel\n",
    "# qty_items_dom\n",
    "# qty_items_sel\n",
    "# domain_dominance depends on qty_items_dom\n",
    "\n",
    "# For those columns, are the rows with nan values the same?\n",
    "\n",
    "# full_data[full_data[\"avg_gmv_item_sel\"].isna()][\"qty_items_dom\"].isna().sum(), full_data[full_data[\"avg_gmv_item_sel\"].isna()][\"qty_items_sel\"].isna().sum(), full_data[full_data[\"avg_gmv_item_sel\"].isna()][\"domain_dominance\"].isna().sum()\n",
    "\n",
    "# Yes, they are the same rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop those rows\n",
    "\n",
    "# full_data = full_data.dropna(subset=[\"avg_gmv_item_sel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benefit            1\n",
       "product_id    137862\n",
       "ROW_ID        180761\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nan values per column\n",
    "\n",
    "full_data.isna().sum()[full_data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "full_data = full_data.sample(frac=1, random_state=19092140).reset_index(drop=True)\n",
    "\n",
    "train_data, test_data = train_test_split(full_data, test_size=0.25, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_vect = tfidf.fit_transform(train_data[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tfidf_title:\n",
    "#     train_df = pd.DataFrame(train_vect.toarray())\n",
    "#     train_data[tfidf.get_feature_names_out()] = train_df\n",
    "\n",
    "#     test_vect = tfidf.transform(test_data[\"title\"])\n",
    "#     test_df = pd.DataFrame(test_vect.toarray())\n",
    "#     test_data[tfidf.get_feature_names_out()] = test_df\n",
    "\n",
    "#     eval_vect = tfidf.transform(eval_data[\"title\"])\n",
    "#     eval_df = pd.DataFrame(eval_vect.toarray())\n",
    "#     eval_data[tfidf.get_feature_names_out()] = eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversion\n",
       "1.0    4189\n",
       "0.0    4189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_converts_test = test_data[test_data[\"conversion\"] == True].shape[0]\n",
    "count_not_converts_test = test_data[test_data[\"conversion\"] == False].shape[0]\n",
    "ratio = count_converts_test / count_not_converts_test\n",
    "\n",
    "# From test_data, keep ratio of count_not_converts_test entries\n",
    "\n",
    "not_converts = test_data[test_data[\"conversion\"] == False].sample(frac=ratio)\n",
    "\n",
    "new_test_data = pd.concat([test_data[test_data[\"conversion\"] == True], not_converts])\n",
    "new_test_data[\"conversion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123015"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance Train Data by conversion\n",
    "\n",
    "len(train_data[train_data[\"conversion\"] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if NaN in conversion, drop those rows\n",
    "train_data = train_data.dropna(subset=[\"conversion\"])\n",
    "test_data = test_data.dropna(subset=[\"conversion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance_train:\n",
    "\n",
    "    count_converts_train = len(train_data[train_data[\"conversion\"] == True])\n",
    "    count_not_converts_train = len(train_data[train_data[\"conversion\"] == False])\n",
    "\n",
    "    ratio = count_converts_train / count_not_converts_train\n",
    "\n",
    "    # From train_data, keep ratio of count_not_converts_train entries\n",
    "\n",
    "    not_converts = train_data[train_data[\"conversion\"] == False].sample(frac=ratio)\n",
    "\n",
    "    new_train_data = pd.concat([train_data[train_data[\"conversion\"] == True], not_converts])\n",
    "\n",
    "    train_data = new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>avg_gmv_item_sel</th>\n",
       "      <th>benefit</th>\n",
       "      <th>category_id</th>\n",
       "      <th>conversion</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>free_shipping</th>\n",
       "      <th>fulfillment</th>\n",
       "      <th>health</th>\n",
       "      <th>is_pdp</th>\n",
       "      <th>...</th>\n",
       "      <th>xxg</th>\n",
       "      <th>yerba</th>\n",
       "      <th>yoga</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zapatilla</th>\n",
       "      <th>zapatillas</th>\n",
       "      <th>zapato</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zocalo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118476</th>\n",
       "      <td>47</td>\n",
       "      <td>40.225781</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA4447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-AUDIO_AND_VIDEO_CABLES_AND_ADAPTERS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155078</th>\n",
       "      <td>41</td>\n",
       "      <td>183.271212</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA109042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-T_SHIRTS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90038</th>\n",
       "      <td>18</td>\n",
       "      <td>111.338322</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA30091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-COMFORTERS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66671</th>\n",
       "      <td>24</td>\n",
       "      <td>19.147965</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA29907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-EYESHADOWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>15</td>\n",
       "      <td>194.121895</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA393384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-WAX_WARMERS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>916</td>\n",
       "      <td>135.827570</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA410901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-SALTY_SNACKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>103</td>\n",
       "      <td>117.069687</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA373653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-PRUNING_SHEARS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>24</td>\n",
       "      <td>136.340116</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA30064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-MATTRESS_COVERS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>12</td>\n",
       "      <td>161.031216</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA411026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLA-SHOWER_HEADS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>2506</td>\n",
       "      <td>5666.063060</td>\n",
       "      <td>0.001</td>\n",
       "      <td>MLA1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MLA-TELEVISIONS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135570 rows × 1046 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        available_quantity  avg_gmv_item_sel  benefit category_id  conversion  \\\n",
       "118476                  47         40.225781    0.001     MLA4447         0.0   \n",
       "155078                  41        183.271212    0.001   MLA109042         0.0   \n",
       "90038                   18        111.338322    0.001    MLA30091         0.0   \n",
       "66671                   24         19.147965    0.001    MLA29907         0.0   \n",
       "19204                   15        194.121895    0.001   MLA393384         0.0   \n",
       "...                    ...               ...      ...         ...         ...   \n",
       "119879                 916        135.827570    0.001   MLA410901         0.0   \n",
       "103694                 103        117.069687    0.001   MLA373653         0.0   \n",
       "131932                  24        136.340116    0.001    MLA30064         0.0   \n",
       "146867                  12        161.031216    0.001   MLA411026         0.0   \n",
       "121958                2506       5666.063060    0.001     MLA1002         1.0   \n",
       "\n",
       "                                      domain_id  free_shipping  fulfillment  \\\n",
       "118476  MLA-AUDIO_AND_VIDEO_CABLES_AND_ADAPTERS              0            0   \n",
       "155078                             MLA-T_SHIRTS              0            0   \n",
       "90038                            MLA-COMFORTERS              0            0   \n",
       "66671                            MLA-EYESHADOWS              0            0   \n",
       "19204                           MLA-WAX_WARMERS              0            1   \n",
       "...                                         ...            ...          ...   \n",
       "119879                         MLA-SALTY_SNACKS              0            0   \n",
       "103694                       MLA-PRUNING_SHEARS              1            0   \n",
       "131932                      MLA-MATTRESS_COVERS              0            0   \n",
       "146867                         MLA-SHOWER_HEADS              0            0   \n",
       "121958                          MLA-TELEVISIONS              0            0   \n",
       "\n",
       "        health  is_pdp  ...  xxg yerba  yoga youtube  zapatilla  zapatillas  \\\n",
       "118476    0.88       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "155078    0.75       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "90038     0.70       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "66671     0.87       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "19204     0.77       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "...        ...     ...  ...  ...   ...   ...     ...        ...         ...   \n",
       "119879    0.88       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "103694    1.00       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "131932    0.77       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "146867    0.72       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "121958    0.85       0  ...  0.0   0.0   0.0     0.0        0.0         0.0   \n",
       "\n",
       "       zapato  zapatos  zocalo  zoom  \n",
       "118476    0.0      0.0     0.0   0.0  \n",
       "155078    0.0      0.0     0.0   0.0  \n",
       "90038     0.0      0.0     0.0   0.0  \n",
       "66671     0.0      0.0     0.0   0.0  \n",
       "19204     0.0      0.0     0.0   0.0  \n",
       "...       ...      ...     ...   ...  \n",
       "119879    0.0      0.0     0.0   0.0  \n",
       "103694    0.0      0.0     0.0   0.0  \n",
       "131932    0.0      0.0     0.0   0.0  \n",
       "146867    0.0      0.0     0.0   0.0  \n",
       "121958    0.0      0.0     0.0   0.0  \n",
       "\n",
       "[135570 rows x 1046 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Oversample, repeats into Validation\n",
    "# train_data = train_data.append(train_data[train_data[\"conversion\"] == True].sample(frac=1, replace=True))\n",
    "# train_data = train_data.append(train_data[train_data[\"conversion\"] == True].sample(frac=1, replace=True))\n",
    "# train_data[\"conversion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split X | y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data[\"conversion\"]\n",
    "X_train = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_train = X_train.select_dtypes(include='number')\n",
    "\n",
    "y_test = test_data[\"conversion\"]\n",
    "X_test = test_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_test = X_test.select_dtypes(include='number')\n",
    "\n",
    "del train_data\n",
    "del test_data\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.25, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(model, feature_cols=[], filename=\"submission.csv\"):\n",
    "    if len(feature_cols) == 0:\n",
    "        feature_cols = model.get_booster().feature_names\n",
    "\n",
    "    #feature_cols = xgb4_model.get_booster().feature_names\n",
    "    #model = final_classifier\n",
    "\n",
    "    eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "    # del comp_data\n",
    "\n",
    "    # Predict on the evaluation set\n",
    "    eval_data = eval_data.drop(columns=[\"conversion\"])\n",
    "    eval_data = eval_data.select_dtypes(include='number')\n",
    "    y_preds = model.predict_proba(eval_data[feature_cols])[:, model.classes_ == 1].squeeze()\n",
    "\n",
    "    # Make the submission file\n",
    "    submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "    submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "    submission_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model (Default params) with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1_model = xgb.XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    seed = random_state,\n",
    "    eval_metric = 'auc',\n",
    "    n_jobs=-1,\n",
    "    #base_score=0.74\n",
    ")\n",
    "\n",
    "# xgb1_model.fit(X_train_sub, y_train_sub, eval_set=[(X_val, y_val)], verbose=20)\n",
    "\n",
    "# notify(\"XGB1\", \"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb1_model.predict_proba(X_test)[:, xgb1_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot ROC curve\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, xgb1_model.predict_proba(X_test)[:, xgb1_model.classes_ == 1])\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.5f)' % roc_auc)\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "# plt.xlim([0.0, 1.0])\n",
    "\n",
    "# plt.ylim([0.0, 1.05])\n",
    "\n",
    "# plt.xlabel('False Positive Rate')\n",
    "\n",
    "# plt.ylabel('True Positive Rate')\n",
    "\n",
    "# plt.title('Receiver operating characteristic example')\n",
    "\n",
    "# plt.legend(loc=\"lower right\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# xgb.plot_importance(xgb1_model, max_num_features=20, importance_type=\"gain\", xlabel=\"Gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# xgb.plot_importance(xgb1_model, max_num_features=20, importance_type=\"cover\", xlabel=\"Cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Feature Importance from the classifier xgb1_model\n",
    "# feature_importances = pd.DataFrame(\n",
    "#     xgb1_model.feature_importances_,\n",
    "#     index = X_train.columns,\n",
    "#     columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "# feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add gain column\n",
    "# gains = sorted(xgb1_model.get_booster().get_score(importance_type=\"gain\").items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# gains_pd = pd.DataFrame(gains, columns=[\"feature\", \"gain\"]).set_index(\"feature\").sort_values(\"gain\", ascending=False)\n",
    "\n",
    "# gains_pd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model (Top 20 Gain params) with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb2_model = xgb.XGBClassifier(\n",
    "#     objective = 'binary:logistic',\n",
    "#     seed = random_state,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# reduced_cols = gains_pd.head(20).index\n",
    "\n",
    "# xgb2_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb2_model.predict_proba(X_test)[:, xgb2_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covers = sorted(xgb1_model.get_booster().get_score(importance_type=\"cover\").items(), key=lambda x: x[1], reverse=True)\n",
    "# covers_pd = pd.DataFrame(covers, columns=[\"feature\", \"cover\"]).set_index(\"feature\").sort_values(\"cover\", ascending=False)\n",
    "\n",
    "\n",
    "# xgb_model_covers = xgb.XGBClassifier(\n",
    "#     objective = 'binary:logistic',\n",
    "#     seed = random_state,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# reduced_cols = covers_pd.head(20).index\n",
    "\n",
    "# xgb_model_covers.fit(X_train[reduced_cols], y_train)\n",
    "\n",
    "# roc_auc_score(y_test, xgb_model_covers.predict_proba(X_test[reduced_cols])[:, xgb_model_covers.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb2_model.predict_proba(X_test)[:, xgb2_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# xgb.plot_importance(xgb2_model, max_num_features=20, importance_type=\"gain\", xlabel=\"Gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Importance\n",
    "# fig, ax = plt.subplots(figsize=(5, 20))\n",
    "\n",
    "# xgb.plot_importance(xgb2_model, max_num_features=100, importance_type=\"gain\", xlabel=\"Gain\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Model with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del comp_data\n",
    "# del full_data\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:299: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:301: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:332: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:323: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:427: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:299: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:301: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:332: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:323: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:427: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:299: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:301: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:332: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:323: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:427: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:299: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:301: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:332: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:323: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/Users/nacho/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/data.py:427: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[22:17:10] /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_b2k4a2hea3/croot/xgboost-split_1675457783214/work/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000016ca2b9b4 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n  [bt] (1) 2   libxgboost.dylib                    0x000000016cb3b326 xgboost::gbm::GBTree::ConfigureUpdaters() + 630\n  [bt] (2) 3   libxgboost.dylib                    0x000000016cb35640 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 1136\n  [bt] (3) 4   libxgboost.dylib                    0x000000016cb5888b xgboost::LearnerConfiguration::Configure() + 1211\n  [bt] (4) 5   libxgboost.dylib                    0x000000016cb58b17 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 119\n  [bt] (5) 6   libxgboost.dylib                    0x000000016ca4771a XGBoosterUpdateOneIter + 154\n  [bt] (6) 7   libffi.8.dylib                      0x000000010bed5972 ffi_call_unix64 + 82\n  [bt] (7) 8   ???                                 0x0000000307663600 0x0 + 13009040896\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# params = {'colsample_bytree': 0.9958188825321641, 'gamma': 0.9488078042954764, 'learning_rate': 0.07108927605766976, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 4, 'subsample': 0.8232243201689888}\u001b[39;00m\n\u001b[1;32m      2\u001b[0m xgb4_model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(\n\u001b[1;32m      3\u001b[0m         \u001b[39m# **params,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         objective \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         tree_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m xgb4_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     13\u001b[0m score \u001b[39m=\u001b[39m roc_auc_score(y_test, xgb4_model\u001b[39m.\u001b[39mpredict_proba(X_test)[:, xgb4_model\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m])\n\u001b[1;32m     15\u001b[0m notify(\u001b[39m\"\u001b[39m\u001b[39mXGB4\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDone. Score: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(score))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfmetal/lib/python3.9/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [22:17:10] /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_b2k4a2hea3/croot/xgboost-split_1675457783214/work/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000016ca2b9b4 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n  [bt] (1) 2   libxgboost.dylib                    0x000000016cb3b326 xgboost::gbm::GBTree::ConfigureUpdaters() + 630\n  [bt] (2) 3   libxgboost.dylib                    0x000000016cb35640 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 1136\n  [bt] (3) 4   libxgboost.dylib                    0x000000016cb5888b xgboost::LearnerConfiguration::Configure() + 1211\n  [bt] (4) 5   libxgboost.dylib                    0x000000016cb58b17 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 119\n  [bt] (5) 6   libxgboost.dylib                    0x000000016ca4771a XGBoosterUpdateOneIter + 154\n  [bt] (6) 7   libffi.8.dylib                      0x000000010bed5972 ffi_call_unix64 + 82\n  [bt] (7) 8   ???                                 0x0000000307663600 0x0 + 13009040896\n\n"
     ]
    }
   ],
   "source": [
    "# params = {'colsample_bytree': 0.9958188825321641, 'gamma': 0.9488078042954764, 'learning_rate': 0.07108927605766976, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 4, 'subsample': 0.8232243201689888}\n",
    "xgb4_model = xgb.XGBClassifier(\n",
    "        # **params,\n",
    "        objective = 'binary:logistic',\n",
    "        seed = random_state,\n",
    "        n_jobs=-1,\n",
    "        verbosity=2,\n",
    "        tree_method=\"gpu_hist\",\n",
    ")\n",
    "\n",
    "xgb4_model.fit(X_train, y_train)\n",
    "\n",
    "score = roc_auc_score(y_test, xgb4_model.predict_proba(X_test)[:, xgb4_model.classes_ == 1])\n",
    "\n",
    "notify(\"XGB4\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "create_submission_file(xgb4_model,\n",
    "                       xgb4_model.get_booster().feature_names,\n",
    "                       \"outputs/xgb: {:.5f}.csv\".format(score)\n",
    ")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb4_model.predict_proba(X_test)[:, xgb4_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC on Balanced X_test (Subsampled X_test for conversion == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = new_test_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "new_X_test = new_X_test.select_dtypes(include='number')\n",
    "\n",
    "new_y_test = new_test_data[\"conversion\"]\n",
    "\n",
    "# roc_auc_score(new_y_test, xgb2_model.predict_proba(new_X_test)[:, xgb2_model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion Matrix for xgb2_model on new_test_data\n",
    "\n",
    "# conf_mx = confusion_matrix(new_y_test, xgb2_model.predict(new_X_test))\n",
    "\n",
    "# true_neg, false_pos, false_neg, true_pos = conf_mx.ravel()\n",
    "\n",
    "# true_neg, false_pos, false_neg, true_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xgb3_model = make_pipeline(\\n    SimpleImputer(strategy=\"median\"),\\n    xgb.XGBClassifier(\\n        objective = \\'binary:logistic\\',\\n        seed = random_state,\\n        n_jobs=-1,\\n    )\\n)\\n\\nxgb3_model.fit(X_train, y_train)\\n\\nroc_auc_score(y_test, xgb3_model.predict_proba(X_test)[:, xgb3_model.classes_ == 1]) '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" xgb3_model = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    xgb.XGBClassifier(\n",
    "        objective = 'binary:logistic',\n",
    "        seed = random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    ")\n",
    "\n",
    "xgb3_model.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, xgb3_model.predict_proba(X_test)[:, xgb3_model.classes_ == 1]) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "# rfc.fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(y_test, rfc.predict_proba(X_test)[:, rfc.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier (XGBoost + Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_rfc_xgb = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model)\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# voting_rfc_xgb.fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(y_test, voting_rfc_xgb.predict_proba(X_test)[:, voting_rfc_xgb.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    GradientBoostingClassifier(verbose=2)\n",
    ")\n",
    "\n",
    "# gbc.fit(X_train, y_train)\n",
    "\n",
    "# score = roc_auc_score(y_test, gbc.predict_proba(X_test)[:, gbc.classes_ == 1])\n",
    "\n",
    "# notify(\"GBC\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingClassifier(verbose=2)\n",
    "\n",
    "# hgb.fit(X_train, y_train)\n",
    "\n",
    "# score = roc_auc_score(y_test, hgb.predict_proba(X_test)[:, hgb.classes_ == 1])\n",
    "\n",
    "# notify(\"HGB\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "# abc.fit(X_train, y_train)\n",
    "\n",
    "# score = roc_auc_score(y_test, abc.predict_proba(X_test)[:, abc.classes_ == 1])\n",
    "\n",
    "# notify(\"ABC\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    ExtraTreesClassifier()\n",
    ")\n",
    "\n",
    "# etc.fit(X_train, y_train)\n",
    "\n",
    "# score = roc_auc_score(y_test, etc.predict_proba(X_test)[:, etc.classes_ == 1])\n",
    "\n",
    "# notify(\"ETC\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier Alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_alt = VotingClassifier(\n",
    "    estimators=[\n",
    "        # (\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model),\n",
    "        (\"hgb\", hgb),\n",
    "        (\"abc\", abc),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# voting_alt.fit(X_train, y_train)\n",
    "\n",
    "# score = roc_auc_score(y_test, voting_alt.predict_proba(X_test)[:, voting_alt.classes_ == 1])\n",
    "\n",
    "# notify(\"Voting Alt\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "# create_submission_file(voting_alt,\n",
    "#                        xgb4_model.get_booster().feature_names, \n",
    "#                        \"outputs/submission_voting(rfc, xgb, hgb, abc): {:.5f}.csv\".format(score)\n",
    "# )\n",
    "\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_ra...\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...)),\n",
       "                             (&#x27;hgb&#x27;, HistGradientBoostingClassifier(verbose=2)),\n",
       "                             (&#x27;abc&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                               SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                              (&#x27;adaboostclassifier&#x27;,\n",
       "                                               AdaBoostClassifier())]))],\n",
       "                 n_jobs=-1, voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_ra...\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...)),\n",
       "                             (&#x27;hgb&#x27;, HistGradientBoostingClassifier(verbose=2)),\n",
       "                             (&#x27;abc&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                               SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                              (&#x27;adaboostclassifier&#x27;,\n",
       "                                               AdaBoostClassifier())]))],\n",
       "                 n_jobs=-1, voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>hgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(verbose=2)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>abc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_ra...\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...)),\n",
       "                             ('hgb', HistGradientBoostingClassifier(verbose=2)),\n",
       "                             ('abc',\n",
       "                              Pipeline(steps=[('simpleimputer',\n",
       "                                               SimpleImputer(strategy='median')),\n",
       "                                              ('adaboostclassifier',\n",
       "                                               AdaBoostClassifier())]))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average classifier\n",
    "from sklearn.utils._pprint import _EstimatorPrettyPrinter\n",
    "\n",
    "class AverageClassifier:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.classes_ = models[0].classes_\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.mean([model.predict_proba(X) for model in self.models], axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.mean([model.predict(X) for model in self.models], axis=0)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "\n",
    "    def __repr__(self, N_CHAR_MAX=700):\n",
    "        # N_CHAR_MAX is the (approximate) maximum number of non-blank\n",
    "        # characters to render. We pass it as an optional parameter to ease\n",
    "        # the tests.\n",
    "\n",
    "        # Using _EstimatorPrettyPrinter\n",
    "\n",
    "        pp = _EstimatorPrettyPrinter(\n",
    "            compact=True,\n",
    "            indent=1,\n",
    "            indent_at_name=True,\n",
    "            n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW,\n",
    "        )\n",
    "\n",
    "        repr_ = pp.pformat(self)\n",
    "\n",
    "        return repr_\n",
    "        \n",
    "\n",
    "\n",
    "# average_classifier = AverageClassifier(\n",
    "#     [\n",
    "#         #rfc,\n",
    "#         xgb4_model,\n",
    "#         hgb,\n",
    "#         abc,\n",
    "#         #voting_alt\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # average_classifier.fit(X_train, y_train)\n",
    "\n",
    "# score = roc_auc_score(y_test, average_classifier.predict_proba(X_test)[:, average_classifier.classes_ == 1])\n",
    "\n",
    "# notify(\"AVG\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "# create_submission_file(average_classifier, \n",
    "#                        xgb4_model.get_booster().feature_names, \n",
    "#                        \"outputs/submission_avg(xgb, hgb, abc): {:.5f}.csv\".format(score)\n",
    "# )\n",
    "\n",
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:24:01] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:25:11] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:26:24] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:27:39] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:28:48] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:29:52] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:30:59] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:32:16] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:33:31] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:34:42] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:35:49] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:37:02] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:38:13] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:39:23] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 52 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:40:30] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:41:40] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:42:50] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:44:02] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:45:11] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:46:20] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:47:28] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 52 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:48:36] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:49:41] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 38 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:50:47] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:52:02] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:53:12] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:54:44] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:56:05] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:57:17] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "Binning 3.264 GB of training data: [20:58:22] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:59:23] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[21:00:30] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 34 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[21:01:26] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[21:02:23] INFO: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/tree/updater_prune.cc:98: tree pruning end, 44 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    }
   ],
   "source": [
    "# Stacking Classifier\n",
    "\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=[\n",
    "        #(\"rfc\", rfc),\n",
    "        (\"xgb\", xgb4_model),\n",
    "        (\"hgb\", hgb),\n",
    "        (\"abc\", abc),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    n_jobs=-1,\n",
    "    stack_method=\"predict_proba\",\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "score = roc_auc_score(y_test, stacking_classifier.predict_proba(X_test)[:, stacking_classifier.classes_ == 1])\n",
    "\n",
    "notify(\"STACK\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "create_submission_file(stacking_classifier,\n",
    "                       xgb4_model.get_booster().feature_names, \n",
    "                       \"outputs/submission_stack(xgb, hgb, abc): {:.5f}.csv\".format(score)\n",
    ")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_classifier2 = AverageClassifier([voting_alt, stacking_classifier])\n",
    "\n",
    "# # average_classifier.fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(y_test, average_classifier2.predict_proba(X_test)[:, average_classifier2.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "\n",
    "# logistic_regression = make_pipeline(\n",
    "#     SimpleImputer(strategy=\"median\"),\n",
    "#     LogisticRegression(\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# best_score = 0\n",
    "# best_cut = 0\n",
    "# for i in range(1, 20):\n",
    "\n",
    "#     logistic_regression.fit(X_train[reduced_cols[:i]], y_train)\n",
    "\n",
    "#     score = roc_auc_score(y_test, logistic_regression.predict_proba(X_test[reduced_cols[:i]])[:, logistic_regression.classes_ == 1])\n",
    "\n",
    "#     print(i, score)\n",
    "\n",
    "#     if score > best_score:\n",
    "#         best_score = score\n",
    "#         best_cut = i\n",
    "\n",
    "# best_score, best_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression = make_pipeline(\n",
    "#     SimpleImputer(strategy=\"median\"),\n",
    "#     PolynomialFeatures(degree=2, include_bias=False, interaction_only=True),\n",
    "#     LogisticRegression(\n",
    "#         n_jobs=-1,\n",
    "#         max_iter=1000\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# logistic_regression.fit(X_train[reduced_cols[:3]], y_train)\n",
    "\n",
    "# roc_auc_score(y_test, logistic_regression.predict_proba(X_test[reduced_cols[:3]])[:, logistic_regression.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging_classifier_rfc = make_pipeline(\n",
    "#     SimpleImputer(strategy=\"median\"),\n",
    "#     BaggingClassifier(\n",
    "#         base_estimator=RandomForestClassifier(),\n",
    "#         n_estimators=10,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# bagging_classifier_rfc.fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(y_test, bagging_classifier_rfc.predict_proba(X_test)[:, bagging_classifier_rfc.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging_classifier_logistic = BaggingClassifier(\n",
    "#     estimator=LogisticRegression(\n",
    "#         n_jobs=-1,\n",
    "#         max_iter=1000\n",
    "#     ),\n",
    "#     n_estimators=10,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# bagging_classifier_logistic.fit(X_train[reduced_cols[:best_cut]], y_train)\n",
    "\n",
    "# roc_auc_score(y_test, bagging_classifier_logistic.predict_proba(X_test[reduced_cols[:best_cut]])[:, bagging_classifier_logistic.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:787: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 2 for this parallel run (total 10)...\n",
      "Building estimator 1 of 2 for this parallel run (total 10)...\n",
      "Building estimator 1 of 1 for this parallel run (total 10)...\n",
      "Building estimator 1 of 1 for this parallel run (total 10)...\n",
      "Building estimator 1 of 1 for this parallel run (total 10)...\n",
      "Building estimator 1 of 1 for this parallel run (total 10)...\n",
      "Building estimator 1 of 1 for this parallel run (total 10)...\n",
      "Building estimator 1 of 1 for this parallel run (total 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    8.3s remaining:   24.9s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    8.3s remaining:   13.9s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   8 | elapsed:    8.3s remaining:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    8.3s remaining:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   8 | elapsed:    8.3s remaining:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m bagging_classifier_xgb \u001b[39m=\u001b[39m BaggingClassifier(\n\u001b[1;32m      2\u001b[0m     estimator\u001b[39m=\u001b[39mxgb\u001b[39m.\u001b[39mXGBClassifier(\n\u001b[1;32m      3\u001b[0m         objective \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m bagging_classifier_xgb\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     14\u001b[0m roc_auc_score(y_test, bagging_classifier_xgb\u001b[39m.\u001b[39mpredict_proba(X_test)[:, bagging_classifier_xgb\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py:338\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[1;32m    330\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    331\u001b[0m     X,\n\u001b[1;32m    332\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m )\n\u001b[0;32m--> 338\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_samples, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py:473\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    470\u001b[0m seeds \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39mrandint(MAX_INT, size\u001b[39m=\u001b[39mn_more_estimators)\n\u001b[1;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_seeds \u001b[39m=\u001b[39m seeds\n\u001b[0;32m--> 473\u001b[0m all_results \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parallel_args()\n\u001b[1;32m    475\u001b[0m )(\n\u001b[1;32m    476\u001b[0m     delayed(_parallel_build_estimators)(\n\u001b[1;32m    477\u001b[0m         n_estimators[i],\n\u001b[1;32m    478\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    479\u001b[0m         X,\n\u001b[1;32m    480\u001b[0m         y,\n\u001b[1;32m    481\u001b[0m         sample_weight,\n\u001b[1;32m    482\u001b[0m         seeds[starts[i] : starts[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m]],\n\u001b[1;32m    483\u001b[0m         total_n_estimators,\n\u001b[1;32m    484\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    485\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    487\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(n_jobs)\n\u001b[1;32m    488\u001b[0m )\n\u001b[1;32m    490\u001b[0m \u001b[39m# Reduce\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    492\u001b[0m     itertools\u001b[39m.\u001b[39mchain\u001b[39m.\u001b[39mfrom_iterable(t[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m all_results)\n\u001b[1;32m    493\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coding/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bagging_classifier_xgb = BaggingClassifier(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        objective = 'binary:logistic',\n",
    "        seed = random_state,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1,\n",
    "    verbose=20,\n",
    ")\n",
    "\n",
    "bagging_classifier_xgb.fit(X_train, y_train)\n",
    "\n",
    "score = roc_auc_score(y_test, bagging_classifier_xgb.predict_proba(X_test)[:, bagging_classifier_xgb.classes_ == 1])\n",
    "\n",
    "notify(\"BAGGING XGB\", \"Done. Score: {}\".format(score))\n",
    "\n",
    "create_submission_file(bagging_classifier_xgb,\n",
    "                          xgb4_model.get_booster().feature_names,\n",
    "                            \"outputs/submission_bagging_xgb: {:.5f}.csv\".format(score)\n",
    ")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking_classifier_2 = StackingClassifier(\n",
    "#     estimators=[\n",
    "#         (\"rfc\", rfc),\n",
    "#         (\"xgb\", xgb4_model),\n",
    "#         (\"hgb\", hgb),\n",
    "#         (\"abc\", abc),\n",
    "#         (\"bg_xgb\", bagging_classifier_xgb),\n",
    "#     ],\n",
    "#     final_estimator=LogisticRegression(),\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# stacking_classifier_2.fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(y_test, stacking_classifier_2.predict_proba(X_test)[:, stacking_classifier_2.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_alt_2 = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         (\"rfc\", rfc),\n",
    "#         (\"xgb\", xgb4_model),\n",
    "#         (\"hgb\", hgb),\n",
    "#         (\"abc\", abc),\n",
    "#         (\"bg_xgb\", bagging_classifier_xgb),\n",
    "#     ],\n",
    "#     voting=\"soft\",\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# voting_alt_2.fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(y_test, voting_alt_2.predict_proba(X_test)[:, voting_alt_2.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_classifier_3 = AverageClassifier([voting_alt_2, stacking_classifier_2])\n",
    "\n",
    "# average_classifier_3.fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(y_test, average_classifier_3.predict_proba(X_test)[:, average_classifier_3.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == True].shape[0], y_train[y_train == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #(logistic_regression, \"logistic_regression\"),\n",
    "    (rfc, \"RandomForestClassifier\"),\n",
    "    (xgb1_model, \"xgb1_model\"),\n",
    "    (xgb2_model, \"xgb2_model\"),\n",
    "    (xgb4_model, \"xgb4_model\"), \n",
    "    (voting_rfc_xgb, \"voting_rfc_xgb\"), \n",
    "    #(gbc, \"gbc\"), \n",
    "    (hgb, \"hgb\"),\n",
    "    (abc, \"abc\"), \n",
    "    # (etc, \"etc\"), \n",
    "    (voting_alt, \"voting_alt\"),\n",
    "    # (voting_alt_2, \"voting_alt_2\"),\n",
    "    (stacking_classifier, \"stacking_classifier\"),\n",
    "    # (stacking_classifier_2, \"stacking_classifier_2\"),\n",
    "    (average_classifier, \"average_classifier\"),\n",
    "    (average_classifier2, \"average_classifier2\"),\n",
    "    # (average_classifier_3, \"average_classifier_3\"),\n",
    "    # (bagging_classifier_rfc, \"bagging_classifier_rfc\"),\n",
    "    # (bagging_classifier_logistic, \"bagging_classifier_logistic\"),\n",
    "    (bagging_classifier_xgb, \"bagging_classifier_xgb\"),\n",
    "]\n",
    "\n",
    "model_names = [model[1] for model in models]\n",
    "models = [model[0] for model in models]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# plot_roc_curves(models, model_names, new_X_test, new_y_test, ax=ax)\n",
    "plot_roc_curves(models, model_names, X_test, y_test, ax=ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with Hyperopt\n",
    "if hp_tune:\n",
    "\n",
    "    xgb_space = {\n",
    "        \"max_depth\": hp.choice(\"max_depth\", [2, 4, 8, 16, 32, 64, 128, None]),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.2),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", [10, 50, 100, 200, 500]),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 0, 1),\n",
    "        \"min_child_weight\": hp.choice(\"min_child_weight\", [2, 4, 8, 16, 32, 64, 128]),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    def objective_xgb(params):\n",
    "        global best_score\n",
    "\n",
    "        model = xgb.XGBClassifier(\n",
    "            **params,\n",
    "            objective = 'binary:logistic',\n",
    "            seed = random_state,\n",
    "            n_jobs=-1,\n",
    "            #eval_metric = 'auc',\n",
    "        )\n",
    "        \n",
    "        score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "\n",
    "        #model.fit(X_train_sub, y_train_sub, eval_set=[(X_val, y_val)], verbose=0)\n",
    "        #model.fit(X_train, y_train)\n",
    "        #score = roc_auc_score(y_test, model.predict_proba(X_test)[:, model.classes_ == 1])\n",
    "\n",
    "        # print(f\"Score: {score}\", params)\n",
    "\n",
    "        # if score > best_score:\n",
    "        #     best_score = score\n",
    "        #     print(f\"New best score: {best_score}\")\n",
    "        #     print(params)\n",
    "            \n",
    "        return {\"loss\": 1 - score, \"status\": STATUS_OK}\n",
    "\n",
    "    trials_xgb = Trials()\n",
    "\n",
    "    best_xgb = fmin(\n",
    "        fn=objective_xgb,\n",
    "        space=xgb_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=100,\n",
    "        trials=trials_xgb,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    print(best_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'colsample_bytree': 0.5261530316412195, 'gamma': 0.4666423706737293, 'learning_rate': 0.043284110571295886, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 4, 'subsample': 0.8142370483321494}\n",
    "model = xgb.XGBClassifier(\n",
    "    **p,\n",
    "    objective = 'binary:logistic',\n",
    "    seed = random_state,\n",
    "    n_jobs=-1,\n",
    "    #eval_metric = 'auc',\n",
    ")\n",
    "\n",
    "#score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, model.predict_proba(X_test)[:, model.classes_ == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"is_discount\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_classifier = AverageClassifier([voting_alt_2, stacking_classifier_2])\n",
    "\n",
    "final_classifier = AverageClassifier([voting_alt, stacking_classifier, bagging_classifier_xgb])\n",
    "\n",
    "X_full = full_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_full = X_full.select_dtypes(include='number')\n",
    "\n",
    "y_full = full_data[\"conversion\"]\n",
    "\n",
    "final_classifier.fit(X_full, y_full)\n",
    "\n",
    "# Should be 1, full_data contains test_data \n",
    "roc_auc_score(y_test, final_classifier.predict_proba(X_test)[:, final_classifier.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_full, final_classifier.predict_proba(X_full)[:, final_classifier.classes_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils._pprint import _EstimatorPrettyPrinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dif = set(X_full.columns)\n",
    "\n",
    "for model in models:\n",
    "    # if Pipeline, get last step\n",
    "    if isinstance(model, sklearn.pipeline.Pipeline):\n",
    "        model = model.steps[-1][1]\n",
    "    \n",
    "    # print feature names\n",
    "    if isinstance(model, xgb.XGBClassifier):\n",
    "        print(model.get_booster().feature_names)\n",
    "    elif isinstance(model, VotingClassifier):\n",
    "        for estimator in model.estimators_:\n",
    "            if isinstance(estimator, sklearn.pipeline.Pipeline):\n",
    "                estimator = estimator.steps[-1][1]\n",
    "            print(estimator)\n",
    "            if isinstance(estimator, xgb.XGBClassifier):\n",
    "                print(estimator.get_booster().feature_names)\n",
    "            #elif isinstance(estimator, HistGradientBoostingClassifier):\n",
    "             #   print(estimator.feature_names_)\n",
    "            #elif isinstance(estimator, GradientBoostingClassifier):\n",
    "             #   print(estimator.feature_names_)\n",
    "    elif isinstance(model, StackingClassifier):\n",
    "        for estimator in model.estimators_:\n",
    "            if isinstance(estimator, sklearn.pipeline.Pipeline):\n",
    "                estimator = estimator.steps[-1][1]\n",
    "            print(estimator)\n",
    "            if isinstance(estimator, xgb.XGBClassifier):\n",
    "                print(estimator.get_booster().feature_names)\n",
    "            #elif isinstance(estimator, HistGradientBoostingClassifier):\n",
    "             #   print(estimator.feature_names_)\n",
    "            #elif isinstance(estimator, GradientBoostingClassifier):\n",
    "              #  print(estimator.feature_names_)\n",
    "    #elif isinstance(model, BaggingClassifier):\n",
    "    #    print(model.base_estimator_.get_booster().feature_names)\n",
    "    elif isinstance(model, HistGradientBoostingClassifier):\n",
    "        #print(model.feature_names_)\n",
    "        pass\n",
    "    elif isinstance(model, GradientBoostingClassifier):\n",
    "        # print(model.feature_names_)\n",
    "        pass\n",
    "    elif isinstance(model, RandomForestClassifier):\n",
    "       pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = xgb4_model.get_booster().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_file(final_classifier, feature_cols, \"outputs/submission_avg(bagging(xgb), voting(xgb, hgb, abc), stacking(xgb, hgb, abc)): {:.5f}.csv\".format(score))\n",
    "\n",
    "#del eval_data\n",
    "#del submission_df\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# import pickle\n",
    "\n",
    "# pickle.dump(final_classifier, open(\"los_simuladores_avg(stack(bagging_classifier_xgb(xgb), xgb, hgb, abc), voting(xgb, hgb, abc))_full_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
